Dossier Projet RNCP - ActivMap
Table des Matières
1. Introduction
   1. Contexte du projet
   2. Présentation de l'entreprise FeelObject
   3. Problématique adressée
   4. Vision du produit ActivMap
2. Cahier des Charges
   1. Objectifs SMART
   2. Périmètre fonctionnel
   3. Acteurs du système
   4. Exigences non-fonctionnelles
1. Conception
   1. User Stories
   2. Maquettes / Wireframes
   3. Modèles de Données
      * Modèle Conceptuel de Données (MCD)
      * Modèle Logique de Données (MLD)
      * Modèle Physique de Données (MPD)
1. Architecture Technique
   1. Vue d’ensemble de l’architecture
   2. Architecture Détaillée
   3. Flux de Données
   4. Sécurité
   5. Stratégie de Déploiement
1. Choix des Technologies
   1. Justification Backend : Python/Flask
   2. Justification Frontend : Svelte
   3. Justification Base de Données : PostgreSQL + PostGIS
   4. Justification Conteneurisation : Docker
   5. Justification Serveur Web/Proxy : Nginx
   6. Autres Librairies et Outils
1. Développement / Implémentation
   1. AT1 : Développer une application sécurisée
      * CP1 : Installer et configurer son environnement de travail
      * CP2 : Réaliser des interfaces utilisateur
      * CP3 : Développer des composants métier
      * CP4 : Contribuer à la gestion d’un projet informatique
   2. AT2 : Concevoir et développer une application sécurisée organisée en couches
      * CP8 : Développer des composants d’accès aux données
   3. Description détaillée des fonctionnalités clés
1. Tests
   1. AT3 : Élaborer et mettre en œuvre les composants dans une application de gestion
      * CP9 : Préparer et exécuter les plans de tests unitaires et d’intégration
         * Stratégie de Tests
         * Tests Unitaires (TU)
         * Tests d’Intégration
         * Tests de Sécurité
         * Tests d’Acceptation Utilisateur (UAT)
         * Plans de Tests
1. Déploiement
   1. AT3 : Élaborer et mettre en œuvre les composants dans une application de gestion
      * CP10 : Déployer une application
         * Mise en Place de Docker
         * Configuration Nginx
         * Pipeline CI/CD
         * Gestion des Certificats TLS
         * Déploiement sur VPS
         * Surveillance et Maintenance
         * Contribution à la mise en production
      * CP11 : Accompagner l’utilisateur dans la prise en main de l’application
         * Documentation Utilisateur
         * Support Utilisateur
         * Formation (Optionnel)
1. Bilan et Conclusion
   1. Retour d’Expérience Personnel
   2. Points Forts du Projet / Difficultés Rencontrées
   3. Améliorations Possibles / Perspectives d’Évolution
   4. Conclusion Générale
1. Annexes
   1. Lien vers le code source


________________


Introduction
1. Contexte du projet
Dans un monde où l'accessibilité numérique et physique devient une préoccupation sociétale et réglementaire incontournable, les entreprises qui développent des solutions innovantes pour les personnes en situation de handicap jouent un rôle crucial. La capacité à interagir avec l'environnement et à comprendre l'information spatiale est fondamentale pour l'autonomie et l'inclusion. Cependant, la représentation de cet espace, notamment pour les personnes malvoyantes ou non-voyantes, présente des défis techniques et conceptuels significatifs. Les méthodes traditionnelles de création de supports tactiles, bien qu'utiles, se heurtent souvent à des limitations en termes de temps de production, de coût, de précision et de capacité de mise à jour.


Le projet ActivMap s'inscrit précisément dans ce contexte d'innovation au service de l'accessibilité. Il vise à répondre à un besoin spécifique identifié au sein de l'entreprise FeelObject, un acteur reconnu dans la conception et la fabrication d'objets tactiles. L'objectif principal est de développer une solution logicielle performante pour automatiser une étape clé et chronophage de leur processus de production : la génération de plans 2D vectoriels stylisés à partir de données géographiques. Ces plans constituent la base indispensable pour la modélisation et l'impression 3D d'objets tactiles, tels que des cartes en relief ou des plans de bâtiments.


Actuellement, cette tâche est réalisée manuellement par les designers de FeelObject, un processus laborieux qui non seulement mobilise des ressources précieuses mais introduit également des risques d'incohérence et de lenteur dans la chaîne de production. L'automatisation proposée par ActivMap promet de révolutionner cette étape en offrant rapidité, précision et standardisation, tout en libérant le potentiel créatif des équipes de conception. Ce projet représente donc un enjeu stratégique pour FeelObject, lui permettant d'optimiser ses opérations, d'améliorer la qualité de ses produits et de renforcer sa capacité d'innovation dans le domaine en pleine expansion de l'accessibilité spatiale.
2. Présentation de l'entreprise FeelObject
Fondée en 2018, FeelObject s'est rapidement imposée comme une entreprise pionnière et innovante dans le secteur de l'accessibilité. Sa mission principale est de concevoir et de fabriquer des objets tactiles sur mesure, spécifiquement pensés pour améliorer l'autonomie et l'expérience spatiale des personnes malvoyantes ou non-voyantes. En combinant une approche de design centrée sur l'utilisateur et l'intégration de technologies de pointe, notamment l'impression 3D, FeelObject a su développer une expertise unique et reconnue.


Le cœur de métier de l'entreprise réside dans la transformation de données spatiales complexes – qu'il s'agisse de plans architecturaux, de cartes géographiques ou de modèles urbains – en représentations physiques tangibles et compréhensibles par le toucher. Cette transformation permet aux utilisateurs de se familiariser avec leur environnement, de planifier leurs déplacements et d'accéder à des informations spatiales autrement inaccessibles. Le catalogue de produits de FeelObject témoigne de la diversité de ses applications :


* Plans tactiles de bâtiments : Pour faciliter l'orientation dans des lieux publics complexes comme les musées, les gares, les aéroports ou les bâtiments administratifs.
* Maquettes urbaines tactiles : Offrant une représentation en relief de quartiers, de zones touristiques ou de campus universitaires.
* Cartes géographiques adaptées : Permettant l'exploration tactile de régions, de pays ou de continents, avec des informations clés mises en relief.
* Supports pédagogiques : Outils conçus pour l'apprentissage de la géographie, de la géométrie ou de l'organisation spatiale dans les établissements spécialisés.


L'entreprise, forte de ses 28 collaborateurs, est structurée en plusieurs pôles complémentaires (Recherche & Développement, Design, Production, Commercial). Le pôle "Cartographie & Accessibilité", composé de sept experts, est au cœur du processus de création des objets tactiles et est le principal bénéficiaire visé par le projet ActivMap. FeelObject cultive une démarche collaborative forte, travaillant en étroite relation avec des associations d'usagers, des institutions publiques et des entreprises partenaires pour s'assurer que ses solutions répondent au plus près des besoins réels et évolutifs des utilisateurs finaux. Cette synergie est un gage de pertinence et d'efficacité pour les produits développés.
3. Problématique adressée
Le processus de création d"objets tactiles chez FeelObject, bien qu"innovant dans sa finalité, repose sur une étape intermédiaire critique qui présente aujourd"hui des goulots d"étranglement significatifs. La transformation des données géographiques brutes (issues de sources comme OpenStreetMap ou de relevés spécifiques) en plans 2D vectoriels stylisés, prêts pour la modélisation 3D, est actuellement une tâche essentiellement manuelle réalisée par les designers spécialisés de l"équipe "Cartographie & Accessibilité". Cette approche manuelle, bien que maîtrisée, engendre plusieurs problématiques majeures qui freinent l"efficacité et la capacité de production de l"entreprise :


1. Temps de production excessif : La création manuelle d"un plan stylisé est une opération complexe et minutieuse. Selon la densité d"informations et la taille de la zone à représenter, cette étape peut nécessiter entre 4 et 8 heures de travail par plan. Ce délai considérable impacte directement la réactivité de l"entreprise face aux demandes clients et allonge les cycles de production globaux.


2. Risques d"erreurs et d"imprécisions : Toute intervention manuelle est intrinsèquement sujette aux erreurs humaines. Omissions d"éléments cartographiques importants (bâtiments, voies, points d"intérêt), imprécisions dans le tracé vectoriel, interprétations variables des données sources peuvent survenir. Ces erreurs compromettent la fiabilité et la qualité du produit final tactile et peuvent nécessiter des corrections longues et coûteuses.


3. Manque de standardisation et d"homogénéité : Malgré l"existence de chartes graphiques et de guides de style internes visant à assurer une représentation cohérente, la subjectivité et les variations inhérentes au travail manuel introduisent des différences subtiles mais perceptibles entre les plans produits par différents designers ou à différents moments. Ce manque d"homogénéité peut nuire à l"expérience utilisateur, notamment pour les personnes qui s"habituent à un certain langage tactile.


4. Difficulté des mises à jour : Le monde physique évolue constamment (nouvelles constructions, modifications de voirie, etc.). La mise à jour des plans tactiles existants pour refléter ces changements est particulièrement fastidieuse avec le processus manuel actuel, nécessitant souvent de reprendre une grande partie du travail de stylisation depuis le début.


5. Sous-optimisation des compétences : Le temps précieux que les designers consacrent à cette tâche répétitive de stylisation pourrait être réinvesti dans des activités à plus forte valeur ajoutée, telles que la recherche de nouvelles techniques de représentation tactile, l"amélioration de l"ergonomie des objets ou l"exploration de nouveaux besoins utilisateurs. L"automatisation permettrait de libérer ce potentiel créatif et innovant.


Face à cet ensemble de contraintes, l"automatisation de la génération de plans 2D stylisés apparaît comme une nécessité stratégique pour FeelObject. Il s"agit de développer un outil capable de produire rapidement des plans précis, cohérents, facilement modifiables et conformes aux standards d"accessibilité, afin d"optimiser la chaîne de production et de renforcer la position de leader de l"entreprise.
4. Vision du produit ActivMap
Face aux défis posés par le processus manuel actuel, la vision d"ActivMap est de fournir une solution logicielle intégrée, efficace et évolutive qui transforme la manière dont FeelObject crée ses plans tactiles. ActivMap est envisagé comme une application web interne, spécifiquement conçue pour s'insérer harmonieusement dans le flux de travail et l'écosystème technologique existant de l'entreprise.


Les piliers de cette vision sont les suivants :


* Centralisation et Accessibilité : Offrir une plateforme unique et centralisée, accessible via un navigateur web standard par tous les membres autorisés de l"équipe "Cartographie & Accessibilité". L"interface se veut intuitive et ergonomique, ne nécessitant pas de compétences approfondies en développement ou en systèmes d"information géographique (SIG) pour une utilisation efficace au quotidien.


* Automatisation Intelligente : Le cœur de la solution réside dans sa capacité à automatiser la transformation des données géographiques brutes (coordonnées GPS, fichiers GeoJSON) en plans 2D vectoriels. Cette automatisation s"appuie sur des règles de stylisation prédéfinies et paramétrables, garantissant la conformité avec les standards d"accessibilité (contrastes, épaisseurs de traits, simplification des formes) et les chartes graphiques de FeelObject.


* Flexibilité et Personnalisation : Si l"automatisation est la clé, ActivMap doit également offrir un degré de flexibilité suffisant pour s"adapter aux spécificités de chaque projet. Les utilisateurs pourront choisir parmi différents styles prédéfinis, ajuster certains paramètres (niveau de détail, palette de couleurs, éléments à afficher) et potentiellement créer et sauvegarder leurs propres styles pour des besoins récurrents.


* Intégration Transparente : Les plans générés par ActivMap doivent être directement exploitables par les logiciels de modélisation 3D et de fabrication additive (impression 3D) utilisés en aval par FeelObject. L"export dans des formats standards (comme SVG) et la potentielle intégration avec le CRM de l"entreprise (pour lier les plans aux projets clients) assureront une transition fluide et une traçabilité optimale dans la chaîne de production.


* Évolutivité et Maintenabilité : L"architecture logicielle d"ActivMap sera conçue pour être modulaire et évolutive. Cela permettra d"intégrer facilement de nouvelles fonctionnalités, de supporter de nouvelles sources de données, d"adapter les règles de stylisation aux évolutions des normes ou des besoins, et de simplifier les opérations de maintenance et de mise à jour.


L"ambition ultime d"ActivMap est de réduire drastiquement le temps de production des plans (objectif de 80% de gain de temps), d"éliminer les erreurs liées à la manipulation manuelle, et de garantir une qualité et une cohérence irréprochables des rendus. Au-delà de l"optimisation opérationnelle, cette solution vise à libérer le temps des designers pour des tâches à plus forte valeur ajoutée, stimulant ainsi l"innovation. En contribuant à rendre la production de supports tactiles plus efficiente, ActivMap s"aligne parfaitement avec la mission globale de FeelObject : favoriser l"inclusion et l"autonomie des personnes déficientes visuelles en leur donnant un meilleur accès à l"information spatiale.
Cahier des Charges
Le présent cahier des charges détaille les spécifications fonctionnelles et non-fonctionnelles du projet ActivMap. Il sert de document de référence pour la conception, le développement et la validation de l"application.
1. Objectifs SMART
Les objectifs du projet ActivMap sont définis en suivant la méthodologie SMART (Spécifique, Mesurable, Atteignable, Réaliste, Temporellement défini) afin d"assurer leur clarté et leur suivi tout au long du développement.


Spécifique :


* Développer une application web interne sécurisée permettant aux employés de FeelObject de générer automatiquement des plans 2D vectoriels stylisés à partir de données géographiques (coordonnées latitude/longitude + rayon, ou import de fichiers GeoJSON).
* Intégrer l"application avec le système CRM existant de FeelObject pour lier les cartes générées aux projets clients correspondants.
* Proposer plusieurs styles visuels prédéfinis (ex: sombre, clair, satellite) et permettre leur personnalisation (épaisseur des traits, contrastes, couleurs) tout en garantissant la conformité aux normes d"accessibilité (RGAA).
* Permettre l"export des plans générés dans des formats exploitables par les logiciels de modélisation 3D utilisés par FeelObject (SVG et PNG haute résolution).
* Mettre en place une gestion des utilisateurs basée sur des rôles (EMPLOYE, CHEF, ADMIN) avec des permissions distinctes.


Mesurable :


* Réduire le temps moyen de production d"un plan 2D stylisé d"au moins 80%, passant de 4-8 heures manuellement à moins de 60 minutes (idéalement moins de 5 minutes pour une zone standard) via l"application.
* Éliminer les erreurs humaines liées à l"omission d"éléments ou à l"incohérence de stylisation, visant un taux de conformité de 100% aux règles de style définies.
* Assurer une compatibilité à 100% des formats d"export avec les outils de modélisation 3D cibles.
* Atteindre un taux d"adoption de l"application par au moins 90% des membres de l"équipe "Cartographie & Accessibilité" dans les trois mois suivant sa mise en production.
* Garantir un temps de réponse moyen de l"interface utilisateur inférieur à 2 secondes pour les interactions courantes.
* Assurer une disponibilité de service de 99,9% pendant les heures ouvrées.


Atteignable :


* L"équipe de développement possède les compétences requises dans les technologies choisies (Python/Flask, Svelte, PostgreSQL/PostGIS, Docker).
* Le projet s"appuie sur des sources de données géographiques fiables et accessibles (OpenStreetMap via API Overpass) et des outils géospatiaux éprouvés (PostGIS).
* Le développement suivra une approche itérative (MVP puis phases ultérieures) pour livrer de la valeur progressivement et s"adapter aux retours.
* Une formation et un accompagnement seront prévus pour les utilisateurs finaux.


Réaliste :


* Les ressources nécessaires (temps de développement, infrastructure serveur/BDD) sont identifiées et planifiées.
* Les utilisateurs finaux (designers) seront impliqués activement dans les phases de conception, de test et de validation pour garantir l"adéquation de la solution à leurs besoins.
* Une phase de transition pourra être envisagée où les processus manuel et automatisé coexistent temporairement.
* Le périmètre fonctionnel est découpé en phases (MVP, Phase 2, Phase 3) pour une gestion maîtrisée.


Temporellement défini :


* Le développement de la version MVP (fonctionnalités essentielles) est estimé à 18 semaines, incluant conception, développement backend/frontend, tests et déploiement initial.
   * Phase de conception et prototypage : 4 semaines
   * Développement backend et intégration PostGIS : 6 semaines
   * Développement frontend et intégration CRM (partielle MVP) : 4 semaines
   * Tests et ajustements : 3 semaines
   * Déploiement et formation initiale : 1 semaine
* Les phases ultérieures (fonctionnalités importantes et souhaitables) seront planifiées après évaluation du MVP.
2. Périmètre fonctionnel
Le périmètre fonctionnel d"ActivMap définit l"ensemble des capacités que l"application offrira à ses utilisateurs. Il est structuré en plusieurs phases pour permettre un développement itératif et une livraison progressive de valeur, en commençant par un Produit Minimum Viable (MVP) regroupant les fonctionnalités essentielles.
Fonctionnalités essentielles (MVP - Minimum Viable Product)
Le MVP se concentre sur le cœur de métier de l"application : la génération automatisée de cartes stylisées et leur mise à disposition des utilisateurs.


1. Génération de cartes à partir de coordonnées :


   * Saisie manuelle des coordonnées géographiques (latitude, longitude) du centre de la zone souhaitée.
   * Définition d"un rayon (en mètres, par exemple via un curseur ou un champ numérique, avec des limites raisonnables comme 50m à 1000m) autour du point central pour délimiter la zone de capture des données.
   * Lancement de la génération automatique du plan 2D vectoriel via un bouton dédié.
   * Récupération des données géographiques pertinentes depuis une source externe (API OpenStreetMap Overpass) pour la zone définie.
   * Traitement des données géographiques (filtrage, simplification) et application d"un style visuel par défaut.
   * Affichage d"une prévisualisation interactive de la carte générée dans l"interface utilisateur.


2. Gestion simple des styles :


   * Possibilité de choisir parmi un nombre limité de styles visuels prédéfinis (ex: "Clair", "Sombre", "Contraste élevé RGAA").
   * Options de base pour ajuster certains paramètres du style sélectionné (ex: épaisseur globale des traits).
   * Mise à jour en temps réel de la prévisualisation lors du changement de style ou de paramètre.


3. Export simple :


   * Fonctionnalité d"export de la carte prévisualisée au format SVG (Scalable Vector Graphics), un format vectoriel standard compatible avec les logiciels de design et de modélisation.
   * Nommage automatique et cohérent des fichiers exportés (ex: carte_LAT_LON_RAYON_DATE.svg).


4. Gestion des utilisateurs et authentification :


   * Système d"authentification sécurisé (login/mot de passe) pour accéder à l"application.
   * Gestion de trois rôles distincts (EMPLOYE, CHEF, ADMIN) avec des permissions de base associées (l"EMPLOYE peut générer et exporter).
   * Possibilité pour l"utilisateur de gérer son profil (modification mot de passe).


5. Historique personnel simple :


   * Sauvegarde automatique des métadonnées de chaque génération de carte effectuée par l"utilisateur (coordonnées, rayon, style utilisé, date).
   * Affichage d"une liste chronologique simple de l"historique personnel des générations.
   * Possibilité de recharger les paramètres d"une génération précédente pour en lancer une nouvelle.
Fonctionnalités importantes (Phase 2)
La Phase 2 enrichit le MVP avec des fonctionnalités améliorant la flexibilité, l"intégration et la personnalisation.


1. Import GeoJSON :


   * Possibilité d"importer un fichier au format GeoJSON pour définir la zone d"intérêt (points, lignes, polygones).
   * Validation du format du fichier importé.
   * Extraction automatique des coordonnées et calcul du centre/rayon si nécessaire (pour les polygones).
   * Utilisation de ces données pour la génération de la carte.


2. Export avancé :


   * Export au format PNG (Portable Network Graphics) avec choix de la résolution (DPI) et des dimensions.
   * Options supplémentaires pour l"export SVG (ex: inclusion/exclusion de certaines couches).


3. Personnalisation avancée des styles :


   * Interface permettant de créer et de sauvegarder des styles personnalisés (choix des couleurs par type d"élément OSM, épaisseurs spécifiques, etc.).
   * Partage possible des styles personnalisés au sein d"une équipe (géré par le CHEF).
   * Options d"accessibilité plus fines (ex: choix de palettes de couleurs spécifiques pour différents types de déficiences visuelles).


4. Intégration CRM :


   * Liaison de l"application ActivMap avec le CRM de FeelObject (via API si disponible).
   * Possibilité d"associer une génération de carte à un projet ou un client spécifique dans le CRM.
   * Envoi potentiel des fichiers générés vers le dossier du projet dans le CRM.


5. Fonctionnalités collaboratives (Rôle CHEF) :


   * Visualisation de l"historique des générations de toute l"équipe.
   * Gestion des styles personnalisés pour l"équipe.
   * Tableau de bord simple avec statistiques d"utilisation de l"équipe.
Fonctionnalités souhaitables (Phase 3 ou ultérieure)
Ces fonctionnalités représentent des améliorations potentielles pour l"avenir, à prioriser en fonction des retours utilisateurs et des besoins de l"entreprise.


1. Édition manuelle post-génération :


   * Outils simples pour ajouter des annotations textuelles ou graphiques sur la carte générée.
   * Possibilité de modifier ou supprimer certains éléments vectoriels du plan.


2. Automatisation et traitement par lots :


   * Génération de cartes en série à partir d"une liste de coordonnées ou de fichiers GeoJSON.
   * Planification de tâches de génération récurrentes.
   * Exposition d"une API pour permettre à d"autres systèmes internes de déclencher des générations de cartes.


3. Analyse et rapports avancés (Rôle ADMIN) :


   * Statistiques détaillées sur l"utilisation de l"application (temps de génération moyen, styles les plus utilisés, zones les plus cartographiées).
   * Rapports personnalisables.


4. Gestion avancée des données sources :


   * Possibilité de choisir ou de combiner différentes sources de données (OSM, données cadastrales, etc.).
   * Gestion des mises à jour des données sources et notification en cas d"impact sur des cartes existantes.
3. Acteurs du système
ActivMap est une application interne destinée à être utilisée par différents profils au sein de FeelObject, ainsi qu"à interagir avec un système externe (le CRM). Chaque acteur a des besoins, des responsabilités et des droits d"accès spécifiques.
Acteur 1 : EMPLOYE
Il s"agit de l"utilisateur principal et quotidien de l"application. Typiquement, ce rôle est attribué aux designers et aux membres de l"équipe "Cartographie & Accessibilité" qui sont chargés de la création des plans 2D.


* Profil type :
   * Possède des compétences en design et une compréhension des enjeux de l"accessibilité, mais pas nécessairement des compétences avancées en cartographie numérique ou en développement.
   * Utilise l"application de manière régulière (quotidienne ou hebdomadaire) pour produire les plans nécessaires aux projets en cours.
   * A besoin d"une interface claire, intuitive et efficace pour accomplir ses tâches rapidement et sans friction.
* Besoins et Permissions clés (MVP et au-delà) :
   * Générer des cartes en fournissant des coordonnées/rayon ou en important un fichier GeoJSON.
   * Choisir et appliquer des styles visuels prédéfinis.
   * Ajuster les paramètres de base des styles.
   * Prévisualiser le rendu de la carte.
   * Exporter les cartes aux formats SVG et PNG.
   * Consulter son historique personnel de générations.
   * Gérer ses préférences de profil (mot de passe, style par défaut).
Acteur 2 : CHEF
Ce rôle correspond au responsable d"équipe ou au chef de projet qui supervise le travail des EMPLOYEs et assure la coordination et la qualité des livrables cartographiques.


* Profil type :
   * A une bonne vision d"ensemble des projets et des exigences cartographiques associées.
   * Utilise l"application pour la validation, la coordination et le suivi de l"activité de son équipe.
   * A besoin d"outils de supervision, de gestion de la qualité et de collaboration.
* Besoins et Permissions clés (principalement Phase 2 et au-delà) :
   * Toutes les permissions de l"EMPLOYE.
   * Consulter l"historique des générations de tous les membres de son équipe.
   * Créer, modifier et gérer des styles visuels personnalisés partagés au sein de l"équipe.
   * Accéder à des statistiques d"utilisation de base pour l"équipe.
   * (Phase 3) Assigner des tâches de génération spécifiques aux membres de l"équipe.
   * (Phase 3) Valider ou demander des modifications sur les cartes générées par l"équipe.
Acteur 3 : ADMIN
L"administrateur système est responsable de la configuration technique, de la maintenance et de la gestion globale de l"application ActivMap.


* Profil type :
   * Possède des compétences techniques avancées en administration système et potentiellement en développement ou bases de données.
   * Intervient de manière ponctuelle pour la configuration initiale, les mises à jour, la gestion des accès et la résolution de problèmes techniques.
   * A besoin d"outils d"administration complets et d"accès aux logs et aux paramètres système.
* Besoins et Permissions clés :
   * Toutes les permissions du CHEF.
   * Gérer les comptes utilisateurs (création, modification, suppression, attribution des rôles).
   * Configurer les paramètres généraux de l"application (connexion BDD, API externes, limites, etc.).
   * Définir les styles visuels globaux par défaut.
   * Accéder aux logs système détaillés et aux statistiques d"utilisation avancées.
   * Gérer les sauvegardes et les restaurations de la base de données.
   * Effectuer les mises à jour de l"application.
Acteur 4 : Système Externe (CRM FeelObject)
Le système de gestion de la relation client (CRM) utilisé par FeelObject est un acteur non-humain qui interagit avec ActivMap, principalement pour l"intégration des cartes dans le contexte des projets clients.


* Interactions clés (principalement Phase 2) :
   * ActivMap peut potentiellement récupérer des informations sur les projets depuis le CRM (via API).
   * ActivMap peut envoyer les cartes générées (ou des liens vers celles-ci) au CRM pour les associer aux fiches projet correspondantes.
   * Une synchronisation (au moins partielle) des utilisateurs et des projets pourrait être envisagée pour simplifier la gestion.
4. Exigences non-fonctionnelles
Au-delà des fonctionnalités spécifiques attendues, le succès et l"adoption d"ActivMap dépendent également du respect d"un ensemble d"exigences non-fonctionnelles qui définissent la qualité globale du service, sa robustesse, sa sécurité et son intégration dans l"environnement de FeelObject. Ces exigences sont cruciales pour garantir une expérience utilisateur satisfaisante et une exploitation pérenne de l"application.
Performance
L"application doit être réactive et efficace pour ne pas ralentir le travail des utilisateurs.


* Temps de génération des cartes : Le temps écoulé entre la demande de génération (clic sur "Générer") et l"affichage de la prévisualisation pour une zone standard (ex: rayon de 150m dans une zone urbaine dense) ne doit pas excéder 30 secondes dans 95% des cas. L"objectif cible est inférieur à 15 secondes.
* Temps de chargement de l"interface : Le temps de chargement initial de l"application et des principales vues (tableau de bord, historique) doit être inférieur à 3 secondes.
* Réactivité de l"interface : Les interactions courantes (sélection de style, ajustement de paramètres, navigation) doivent procurer une sensation de fluidité, avec des réponses visuelles quasi instantanées (inférieures à 500ms).
* Charge concurrente : Le système doit pouvoir traiter sans dégradation notable des performances au moins 10 générations de cartes simultanées lancées par différents utilisateurs. L"architecture doit être pensée pour supporter une montée en charge (scalabilité).
* Optimisation des requêtes : Les requêtes vers la base de données PostGIS et l"API OpenStreetMap Overpass doivent être optimisées pour minimiser la latence et la consommation de ressources serveur.
Disponibilité et Fiabilité
L"application doit être accessible et fonctionner de manière stable pendant les heures de travail.


* Taux de disponibilité : L"application doit être disponible au moins 99,5% du temps pendant les heures ouvrées de FeelObject (ex: 8h-19h, du lundi au vendredi).
* Sauvegardes : Des sauvegardes automatiques et régulières (au minimum quotidiennes) de la base de données (configurations, historique, styles) doivent être mises en place, avec une politique de rétention définie (ex: 7 jours glissants).
* Gestion des erreurs : Les erreurs potentielles (ex: échec de connexion à l"API OSM, erreur de traitement des données) doivent être gérées de manière robuste, en informant l"utilisateur clairement et en évitant les plantages de l"application. Un mécanisme de reprise sur erreur pour les générations longues pourrait être envisagé.
* Journalisation (Logging) : Un système de journalisation détaillé doit enregistrer les événements importants, les erreurs et les avertissements pour faciliter le diagnostic et la maintenance.
Sécurité
La sécurité est primordiale pour protéger les données et l"intégrité du système.


* Authentification : L"accès à l"application doit être protégé par un système d"authentification robuste (identifiant unique et mot de passe complexe). Une politique de gestion des mots de passe (longueur minimale, renouvellement périodique) doit être appliquée.
* Autorisation (RBAC) : Le contrôle d"accès basé sur les rôles (EMPLOYE, CHEF, ADMIN) doit être strictement appliqué pour limiter les actions possibles en fonction du profil de l"utilisateur connecté.
* Chiffrement : Toutes les communications entre le navigateur de l"utilisateur et le serveur doivent être chiffrées via HTTPS (TLS).
* Protection contre les vulnérabilités web : L"application doit être protégée contre les attaques web courantes identifiées par l"OWASP Top 10, notamment les injections SQL, le Cross-Site Scripting (XSS), et le Cross-Site Request Forgery (CSRF).
* Sécurité des dépendances : Les dépendances logicielles (librairies Python, packages Node.js) doivent être maintenues à jour pour corriger les failles de sécurité connues.
* Protection des données : Les données sensibles (ex: mots de passe hachés) doivent être stockées de manière sécurisée. La conformité avec le RGPD doit être assurée si des données personnelles sont traitées.
* (Optionnel) Rate Limiting : Mettre en place des limitations sur le nombre de requêtes API (générations, authentifications) pour prévenir les abus et les attaques par déni de service.
Accessibilité
Étant donné la mission de FeelObject, l"application ActivMap elle-même doit être exemplaire en matière d"accessibilité numérique.


* Conformité RGAA : L"interface utilisateur doit viser la conformité avec le Référentiel Général d"Amélioration de l"Accessibilité (RGAA) au niveau AA.
* Navigation clavier : Toutes les fonctionnalités doivent être accessibles et utilisables via le clavier uniquement.
* Compatibilité lecteurs d"écran : L"application doit être compatible avec les principaux lecteurs d"écran (NVDA, JAWS, VoiceOver) grâce à une structure HTML sémantique et l"utilisation d"attributs ARIA appropriés.
* Contrastes : Les contrastes de couleurs entre le texte et l"arrière-plan doivent respecter les ratios minimaux définis par le RGAA. Des thèmes à contraste élevé doivent être proposés.
* Alternatives textuelles : Toutes les images et icônes porteuses d"information doivent avoir des alternatives textuelles pertinentes.
Utilisabilité
L"application doit être facile à prendre en main et agréable à utiliser.


* Intuitivité : L"interface doit être logique et facile à comprendre, même pour des utilisateurs n"ayant pas une grande expérience des outils cartographiques.
* Cohérence : La terminologie, la disposition des éléments et le comportement des interactions doivent être cohérents à travers toute l"application et, si possible, avec les autres outils internes de FeelObject (comme le CRM).
* Feedback utilisateur : L"application doit fournir un retour visuel clair et immédiat suite aux actions de l"utilisateur (ex: indicateur de chargement pendant la génération, message de succès après export).
* Aide et documentation : Une aide contextuelle (infobulles) et potentiellement une documentation utilisateur simple doivent être disponibles.
Maintenabilité
Le code et l"architecture doivent faciliter les évolutions futures et la correction de bugs.


* Qualité du code : Le code source (backend et frontend) doit être clair, modulaire, commenté et respecter les bonnes pratiques et conventions de style des langages utilisés (PEP 8 pour Python, etc.).
* Tests automatisés : Une couverture de tests unitaires et d"intégration significative (objectif > 70%) doit être mise en place pour garantir la non-régression lors des modifications.
* Documentation technique : Une documentation décrivant l"architecture, les API, le modèle de données et les procédures de déploiement doit être maintenue à jour.
* Gestion des dépendances : Les dépendances doivent être clairement listées et gérées (ex: requirements.txt, package.json) pour faciliter l"installation et les mises à jour.
Scalabilité
L"architecture doit pouvoir s"adapter à une augmentation future du nombre d"utilisateurs ou du volume de données.


* Architecture découplée : Privilégier une architecture où les composants (frontend, backend, base de données) sont relativement indépendants pour permettre une mise à l"échelle sélective.
* Base de données : La conception de la base de données et l"indexation doivent anticiper une croissance du volume de l"historique et des styles.
* Traitement asynchrone : Pour les tâches potentiellement longues comme la génération de cartes complexes, envisager des mécanismes de traitement asynchrone (ex: Celery) pour ne pas bloquer l"interface utilisateur.
Compatibilité
L"application doit fonctionner correctement dans l"environnement technique de FeelObject.


* Navigateurs : L"application web doit être compatible avec les dernières versions des principaux navigateurs utilisés dans l"entreprise (Chrome, Firefox, Edge, Safari).
* Formats d"export : Les fichiers SVG et PNG générés doivent être compatibles avec les versions des logiciels de modélisation 3D utilisés par FeelObject.
* Intégration CRM : L"intégration (Phase 2) doit être compatible avec la version et l"API du CRM utilisé par FeelObject.
Conception
Cette section détaille la conception de l"application ActivMap, en commençant par la traduction des besoins fonctionnels en User Stories, qui serviront de base au développement.
1. User Stories (Récits Utilisateurs)
Les User Stories décrivent les fonctionnalités du point de vue des différents acteurs du système (EMPLOYE, CHEF, ADMIN). Elles suivent le format standard : "En tant que [Rôle], je veux [Action], afin de [Bénéfice]". Chaque User Story est accompagnée de critères d"acceptation qui précisent les conditions à remplir pour considérer la fonctionnalité comme terminée, ainsi qu"une estimation de priorité et de complexité.
Rôle : EMPLOYE
L"EMPLOYE est l"utilisateur principal, chargé de la génération des cartes.


US-E01 : Génération de carte simple par coordonnées


* En tant qu" EMPLOYE,
* Je veux pouvoir générer une carte stylisée en saisissant des coordonnées géographiques (latitude, longitude) et un rayon,
* Afin de créer rapidement une représentation visuelle d"une zone spécifique pour un projet.
* Critères d"acceptation :
   * L"interface propose des champs dédiés pour la latitude, la longitude et le rayon (ex: 50m à 1000m).
   * Un bouton "Générer" déclenche le processus.
   * Une prévisualisation de la carte s"affiche après la génération (temps cible < 30s pour 150m de rayon).
   * La carte générée utilise les données OpenStreetMap correspondant à la zone.
   * Un style visuel par défaut est appliqué.
* Priorité : Haute (MVP)
* Complexité : Moyenne


US-E02 : Import de fichier GeoJSON


* En tant qu" EMPLOYE,
* Je veux pouvoir importer un fichier GeoJSON contenant des points ou des polygones,
* Afin de générer des cartes pour des zones aux formes complexes ou prédéfinies.
* Critères d"acceptation :
   * L"interface permet de sélectionner ou glisser-déposer un fichier .geojson.
   * Le système valide le format du fichier avant traitement.
   * Les coordonnées sont extraites automatiquement.
   * Pour un polygone, le centre et le rayon englobant sont calculés pour la génération.
   * Un message d"erreur clair est affiché si le fichier est invalide.
* Priorité : Moyenne (Phase 2)
* Complexité : Élevée


US-E03 : Choix et personnalisation simple du style visuel


* En tant qu" EMPLOYE,
* Je veux pouvoir choisir parmi des styles visuels prédéfinis et ajuster quelques paramètres de base,
* Afin d" adapter l"apparence de la carte aux besoins du projet ou aux préférences visuelles.
* Critères d"acceptation :
   * Une liste déroulante ou des vignettes permettent de choisir un style (ex: Clair, Sombre, RGAA).
   * Des contrôles simples (curseurs, champs) permettent d"ajuster l"épaisseur des traits ou le contraste global.
   * La prévisualisation se met à jour en temps réel lors des changements.
   * Un style "RGAA" garantit les contrastes et éléments nécessaires à l"accessibilité.
* Priorité : Haute (MVP)
* Complexité : Moyenne


US-E04 : Export de la carte générée


* En tant qu" EMPLOYE,
* Je veux pouvoir exporter la carte affichée aux formats SVG et PNG,
* Afin de pouvoir l"utiliser dans les logiciels de modélisation 3D ou d"autres outils.
* Critères d"acceptation :
   * Des boutons "Exporter SVG" et "Exporter PNG" sont disponibles.
   * L"export SVG génère un fichier vectoriel propre.
   * L"export PNG permet de choisir la résolution (DPI) et génère un fichier image de haute qualité.
   * Les fichiers sont nommés de manière cohérente (ex: activmap_lat_lon_rayon_date.svg).
   * Une notification confirme le succès de l"export et le téléchargement démarre.
* Priorité : Haute (MVP)
* Complexité : Basse


US-E05 : Consultation de l"historique personnel


* En tant qu" EMPLOYE,
* Je veux pouvoir consulter l"historique de mes générations de cartes,
* Afin de retrouver facilement mes travaux précédents et réutiliser leurs paramètres.
* Critères d"acceptation :
   * Une section "Historique" liste les cartes générées par l"utilisateur connecté.
   * Chaque entrée affiche une miniature, les coordonnées/rayon, le style et la date.
   * Un bouton permet de recharger les paramètres d"une ancienne génération dans l"interface principale.
   * L"historique est conservé pour une durée définie (ex: 6 mois).
* Priorité : Moyenne (MVP)
* Complexité : Basse


US-E06 : Gestion du profil utilisateur


* En tant qu" EMPLOYE,
* Je veux pouvoir modifier mon mot de passe et définir mes préférences,
* Afin de sécuriser mon compte et personnaliser mon expérience.
* Critères d"acceptation :
   * Une page "Profil" permet de changer le mot de passe.
   * Des options permettent de définir un style ou un rayon par défaut.
   * Les préférences sont sauvegardées et appliquées lors des sessions suivantes.
* Priorité : Basse (MVP)
* Complexité : Basse
Rôle : CHEF
Le CHEF supervise l"équipe et gère la qualité et la cohérence des productions.


US-C01 : Supervision de l"activité de l"équipe


* En tant que CHEF,
* Je veux pouvoir visualiser l"historique des générations de cartes de mon équipe,
* Afin de suivre l"avancement des projets et la charge de travail.
* Critères d"acceptation :
   * Un tableau de bord affiche l"activité récente de l"équipe.
   * L"historique complet des générations de l"équipe est accessible.
   * Des filtres permettent de trier par membre, date ou projet (si intégration CRM).
   * Des indicateurs simples (nombre de cartes, temps moyen) sont visibles.
* Priorité : Haute (Phase 2)
* Complexité : Moyenne


US-C02 : Gestion des styles d"équipe


* En tant que CHEF,
* Je veux pouvoir créer et gérer des styles visuels personnalisés partagés avec mon équipe,
* Afin de garantir la cohérence graphique des cartes produites pour un même client ou projet.
* Critères d"acceptation :
   * Une interface permet de créer/modifier des styles (couleurs par élément, épaisseurs, etc.).
   * Les styles créés sont disponibles dans la liste de choix pour tous les membres de l"équipe.
   * Possibilité de définir un style comme "recommandé" ou "par défaut" pour l"équipe.
* Priorité : Moyenne (Phase 2)
* Complexité : Moyenne


US-C03 : Validation des cartes (Optionnel - Phase 3)


* En tant que CHEF,
* Je veux pouvoir mettre en place un flux de validation pour les cartes générées par mon équipe,
* Afin de garantir leur qualité et conformité avant utilisation.
* Critères d"acceptation :
   * Les cartes générées par les EMPLOYEs peuvent être soumises à validation.
   * Une interface liste les cartes en attente de validation.
   * Le CHEF peut approuver la carte ou demander des modifications avec des commentaires.
   * Le statut de la carte (validée, en attente, modification demandée) est visible.
* Priorité : Basse (Phase 3)
* Complexité : Moyenne
Rôle : ADMIN
L"ADMIN gère la configuration globale et les accès à l"application.


US-A01 : Gestion des utilisateurs et des rôles


* En tant qu" ADMIN,
* Je veux pouvoir créer, modifier, désactiver/activer les comptes utilisateurs et leur attribuer des rôles (EMPLOYE, CHEF, ADMIN),
* Afin de gérer les accès à l"application de manière sécurisée.
* Critères d"acceptation :
   * Une interface d"administration liste tous les utilisateurs.
   * Des formulaires permettent la création et l"édition des comptes (nom, email, rôle).
   * Possibilité de réinitialiser les mots de passe.
   * Les actions d"administration sont journalisées.
* Priorité : Haute (MVP)
* Complexité : Basse


US-A02 : Configuration des paramètres système


* En tant qu" ADMIN,
* Je veux pouvoir configurer les paramètres généraux de l"application (ex: URL de l"API OSM, limites de rayon, politique de rétention de l"historique),
* Afin d" adapter le fonctionnement de l"application à l"environnement et aux politiques de l"entreprise.
* Critères d"acceptation :
   * Une section de configuration permet d"ajuster les paramètres clés.
   * Les modifications sont prises en compte par l"application.
   * Possibilité de restaurer les paramètres par défaut.
* Priorité : Moyenne (MVP/Phase 2)
* Complexité : Moyenne


US-A03 : Monitoring et consultation des logs


* En tant qu" ADMIN,
* Je veux pouvoir consulter les logs d"erreurs et les métriques d"utilisation de l"application,
* Afin de surveiller la santé du système, diagnostiquer les problèmes et comprendre l"usage.
* Critères d"acceptation :
   * Accès à une interface affichant les logs d"erreurs et d"événements importants.
   * Tableau de bord avec indicateurs clés (nombre d"utilisateurs actifs, nombre de générations, temps de réponse moyen).
   * Options de filtrage et de recherche dans les logs.
* Priorité : Moyenne (Phase 2)
* Complexité : Élevée


US-A04 : Gestion des sauvegardes


* En tant qu" ADMIN,
* Je veux pouvoir configurer et superviser les sauvegardes automatiques de la base de données,
* Afin d" assurer la récupération des données en cas d"incident.
* Critères d"acceptation :
   * Configuration de la fréquence et de la destination des sauvegardes.
   * Possibilité de déclencher une sauvegarde manuelle.
   * Consultation du statut des sauvegardes récentes.
   * Procédure de restauration documentée et testée.
* Priorité : Haute (MVP)
* Complexité : Moyenne (dépend de l"infrastructure)
2. Maquettes / Wireframes (Description UI/UX)
Bien qu"aucun fichier de maquette formelle (type Figma, Sketch ou images de wireframes) n"ait été fourni ou identifié dans le dépôt GitHub du projet, la conception de l"interface utilisateur (UI) et de l"expérience utilisateur (UX) peut être déduite des fonctionnalités décrites, des user stories et des exigences non-fonctionnelles, notamment en termes d"utilisabilité et d"accessibilité.


L"objectif est de proposer une interface web épurée, professionnelle et efficace, permettant aux utilisateurs (principalement les EMPLOYEs) de réaliser leurs tâches de génération de cartes rapidement et sans ambiguïté, tout en offrant aux CHEFs et ADMINs les outils nécessaires à leurs fonctions de supervision et de gestion.
Principes Généraux de Conception UI/UX
* Simplicité et Clarté : L"interface doit être intuitive, minimisant le nombre d"étapes pour réaliser une action courante comme la génération d"une carte. Les libellés doivent être clairs et non techniques.
* Cohérence : L"apparence et le comportement des éléments (boutons, champs de formulaire, menus) doivent être cohérents à travers toute l"application et si possible alignés avec d"autres outils internes de FeelObject (CRM).
* Feedback Immédiat : L"utilisateur doit être informé de l"état du système (ex: indicateur de chargement pendant la génération, messages de succès ou d"erreur clairs).
* Accessibilité (RGAA) : La conception doit intégrer dès le départ les principes d"accessibilité : navigation clavier, compatibilité lecteurs d"écran, contrastes suffisants, alternatives textuelles.
* Responsive Design (Priorité Desktop) : Bien que l"usage principal soit sur ordinateur de bureau, l"interface doit s"adapter correctement aux différentes tailles d"écran, sans toutefois nécessiter une optimisation poussée pour mobile dans un premier temps.
Description des Écrans Principaux (Conceptuelle)
1. Page de Connexion :


   * Interface simple avec champs pour l"identifiant (email ou nom d"utilisateur) et le mot de passe.
   * Lien "Mot de passe oublié" (fonctionnalité potentielle future).
   * Logo de FeelObject ou d"ActivMap.


2. Tableau de Bord Principal (EMPLOYE/CHEF) :


   * Zone de Génération :
      * Formulaire principal pour la génération de cartes.
      * Champs pour entrer la latitude et la longitude (avec potentiellement une aide à la saisie ou une mini-carte interactive pour sélectionner le point).
      * Curseur ou champ numérique pour définir le rayon.
      * Option pour importer un fichier GeoJSON (bouton ou zone de glisser-déposer - Phase 2).
      * Liste déroulante ou vignettes pour sélectionner le style visuel (styles prédéfinis et styles d"équipe pour le CHEF).
      * Bouton "Générer la carte".
   * Zone de Prévisualisation :
      * Espace principal affichant la carte générée.
      * Contrôles de zoom et de déplacement sur la carte.
      * Options d"ajustement rapide du style (si applicables, ex: épaisseur de trait).
      * Boutons "Exporter SVG" et "Exporter PNG".
   * Menu de Navigation :
      * Accès aux différentes sections : Génération (actuelle), Historique, Profil, Administration (si ADMIN), Gestion équipe (si CHEF).
      * Bouton de déconnexion.


3. Page Historique :


   * Liste tabulaire ou grille des générations précédentes de l"utilisateur (ou de l"équipe pour le CHEF).
   * Chaque entrée affiche : miniature, date, coordonnées/rayon, style utilisé.
   * Options de filtrage (par date, style) et de recherche.
   * Bouton "Recharger les paramètres" pour chaque entrée.
   * Pagination si la liste est longue.


4. Page Profil :


   * Formulaire pour modifier le mot de passe.
   * Options pour définir les préférences par défaut (style, rayon).


5. Section Administration (ADMIN) :


   * Gestion des Utilisateurs : Tableau listant les utilisateurs avec leur rôle. Boutons pour ajouter, modifier, activer/désactiver.
   * Configuration Système : Formulaire avec les différents paramètres configurables (limites, API, rétention).
   * Logs & Monitoring : Interface d"affichage des logs système et des métriques d"utilisation (tableaux, graphiques).
   * Gestion des Sauvegardes : Statut des sauvegardes, configuration, déclenchement manuel.


6. Section Gestion Équipe (CHEF) :


   * Gestion des Styles d"Équipe : Interface pour créer/modifier les styles partagés.
   * Tableau de Bord Équipe : Visualisation de l"activité et des statistiques de l"équipe (complète US-C01).


Cette description conceptuelle sert de guide pour le développement frontend. La réalisation effective s"appuiera sur un framework moderne comme Svelte, permettant de créer une interface réactive et modulaire, en utilisant une librairie de composants UI (comme Bootstrap, Tailwind CSS avec des composants pré-stylés, ou une librairie Svelte spécifique) pour assurer la cohérence et accélérer le développement, tout en respectant les exigences d"accessibilité.
3. Modèles de Données
La structuration des données est essentielle pour le bon fonctionnement et la pérennité de l"application ActivMap. Nous allons définir cette structure à travers trois niveaux de modélisation : Conceptuel (MCD), Logique (MLD) et Physique (MPD), ce dernier étant spécifique à la technologie de base de données choisie (PostgreSQL avec l"extension PostGIS).
Modèle Conceptuel de Données (MCD)
Le MCD représente les entités principales du domaine métier et leurs relations, indépendamment de toute technologie. Il permet de valider la compréhension des besoins fonctionnels.


Entités principales :


* UTILISATEUR : Représente une personne physique interagissant avec l"application.
   * Attributs : Identifiant Utilisateur (PK), Nom, Email, Mot de passe (haché), Identifiant Rôle (FK)
* ROLE : Définit les niveaux de permission dans l"application.
   * Attributs : Identifiant Rôle (PK), Nom du Rôle (ex: "EMPLOYE", "CHEF", "ADMIN")
* GENERATION_CARTE : Représente une instance de génération de carte demandée par un utilisateur.
   * Attributs : Identifiant Génération (PK), Date/Heure Création, Latitude (centre), Longitude (centre), Rayon, Données GeoJSON (optionnel), Statut (ex: "En cours", "Terminée", "Erreur"), Identifiant Utilisateur (FK), Identifiant Style (FK)
* STYLE_VISUEL : Définit l"apparence d"une carte générée.
   * Attributs : Identifiant Style (PK), Nom du Style, Description, Paramètres de style (ex: JSON), Est Prédéfini (Booléen), Est Style Équipe (Booléen), Identifiant Créateur (FK, nullable pour prédéfini)
* EXPORT_CARTE : Trace un fichier de carte exporté à partir d"une génération.
   * Attributs : Identifiant Export (PK), Date/Heure Export, Format (SVG/PNG), Résolution (pour PNG), Chemin Fichier ou URL, Identifiant Génération (FK)
* (Phase 2+) PROJET_CRM : Représente un projet externe auquel une carte peut être liée.
   * Attributs : Identifiant Projet CRM (PK), Nom Projet, Identifiant Externe CRM
* (Phase 3) TACHE_GENERATION : Représente une tâche de génération assignée.
   * Attributs : Identifiant Tâche (PK), Date Assignation, Date Échéance, Statut Tâche, Paramètres Génération (JSON), Identifiant Assignateur (FK), Identifiant Assigné (FK)
* (Phase 3) VALIDATION_CARTE : Représente le processus de validation d"une carte.
   * Attributs : Identifiant Validation (PK), Date Soumission, Date Validation, Statut Validation (ex: "En attente", "Approuvée", "Modif demandée"), Commentaires, Identifiant Génération (FK), Identifiant Validateur (FK, nullable)


Relations principales :


* Un UTILISATEUR possède un et un seul ROLE.
* Un ROLE est attribué à un ou plusieurs UTILISATEURs.
* Un UTILISATEUR demande zéro ou plusieurs GENERATION_CARTEs.
* Une GENERATION_CARTE est demandée par un et un seul UTILISATEUR.
* Une GENERATION_CARTE utilise un et un seul STYLE_VISUEL.
* Un STYLE_VISUEL est utilisé par zéro ou plusieurs GENERATION_CARTEs.
* Un UTILISATEUR (CHEF ou ADMIN) peut créer zéro ou plusieurs STYLE_VISUELs (personnalisés ou d"équipe).
* Un STYLE_VISUEL (non prédéfini) est créé par un et un seul UTILISATEUR.
* Une GENERATION_CARTE peut donner lieu à zéro ou plusieurs EXPORT_CARTEs.
* Un EXPORT_CARTE provient de une et une seule GENERATION_CARTE.
* (Phase 2+) Une GENERATION_CARTE peut être associée à zéro ou un PROJET_CRM.
* (Phase 3) Un UTILISATEUR (CHEF) assigne zéro ou plusieurs TACHE_GENERATIONs.
* (Phase 3) Une TACHE_GENERATION est assignée par un et un seul UTILISATEUR (CHEF).
* (Phase 3) Une TACHE_GENERATION est assignée à un et un seul UTILISATEUR (EMPLOYE).
* (Phase 3) Une GENERATION_CARTE peut nécessiter zéro ou une VALIDATION_CARTE.
* (Phase 3) Une VALIDATION_CARTE concerne une et une seule GENERATION_CARTE.
* (Phase 3) Une VALIDATION_CARTE est effectuée par zéro ou un UTILISATEUR (CHEF).


Ce modèle conceptuel servira de base pour dériver le modèle logique.
Modèle Logique de Données (MLD)
Le MLD transforme le MCD en un modèle relationnel, plus proche de l"implémentation en base de données. Les entités deviennent des tables, les attributs des colonnes, et les relations sont matérialisées par des clés étrangères.


Tables et Colonnes :


* roles


   * role_id (PK, INT, auto-incrémenté)
   * nom_role (VARCHAR(50), unique, non nul) - Ex: "EMPLOYE", "CHEF", "ADMIN"


* utilisateurs


   * utilisateur_id (PK, INT, auto-incrémenté)
   * nom_utilisateur (VARCHAR(100), non nul)
   * email (VARCHAR(255), unique, non nul)
   * mot_de_passe_hash (VARCHAR(255), non nul)
   * role_id (FK -> roles.role_id, INT, non nul)
   * preferences_defaut (JSON, nullable) - Stocke les préférences comme le style ou rayon par défaut
   * date_creation (TIMESTAMP, non nul, défaut CURRENT_TIMESTAMP)
   * est_actif (BOOLEAN, non nul, défaut TRUE)


* styles_visuels


   * style_id (PK, INT, auto-incrémenté)
   * nom_style (VARCHAR(100), non nul)
   * description (TEXT, nullable)
   * parametres_style (JSON, non nul) - Contient la définition du style (couleurs, épaisseurs, etc.)
   * est_predefini (BOOLEAN, non nul, défaut FALSE)
   * est_style_equipe (BOOLEAN, non nul, défaut FALSE)
   * createur_id (FK -> utilisateurs.utilisateur_id, INT, nullable) - Nul si prédéfini
   * date_creation (TIMESTAMP, non nul, défaut CURRENT_TIMESTAMP)


* generations_cartes


   * generation_id (PK, INT, auto-incrémenté)
   * date_creation (TIMESTAMP, non nul, défaut CURRENT_TIMESTAMP)
   * latitude_centre (DECIMAL(9,6), non nul)
   * longitude_centre (DECIMAL(9,6), non nul)
   * rayon_metres (INT, non nul)
   * geojson_source (TEXT, nullable) - Stocke le GeoJSON importé si utilisé
   * statut_generation (VARCHAR(50), non nul, défaut "Terminée") - Ex: "En cours", "Terminée", "Erreur"
   * message_statut (TEXT, nullable) - Pour les erreurs
   * utilisateur_id (FK -> utilisateurs.utilisateur_id, INT, non nul)
   * style_id (FK -> styles_visuels.style_id, INT, non nul)
   * projet_crm_id (FK -> projets_crm.projet_crm_id, INT, nullable) - (Phase 2+)


* exports_cartes


   * export_id (PK, INT, auto-incrémenté)
   * date_export (TIMESTAMP, non nul, défaut CURRENT_TIMESTAMP)
   * format_export (VARCHAR(10), non nul) - "SVG", "PNG"
   * resolution_dpi (INT, nullable) - Pour PNG
   * chemin_fichier (VARCHAR(512), nullable) - Ou URL si stocké en externe
   * generation_id (FK -> generations_cartes.generation_id, INT, non nul)


* (Phase 2+) projets_crm


   * projet_crm_id (PK, INT, auto-incrémenté)
   * nom_projet (VARCHAR(255), non nul)
   * identifiant_externe_crm (VARCHAR(100), unique, nullable)


* (Phase 3) taches_generation


   * tache_id (PK, INT, auto-incrémenté)
   * date_assignation (TIMESTAMP, non nul, défaut CURRENT_TIMESTAMP)
   * date_echeance (TIMESTAMP, nullable)
   * statut_tache (VARCHAR(50), non nul, défaut "A faire") - Ex: "A faire", "En cours", "Terminée"
   * parametres_generation (JSON, non nul) - Contient lat, lon, rayon, style_id, etc.
   * assignateur_id (FK -> utilisateurs.utilisateur_id, INT, non nul) - Doit être un CHEF
   * assigne_id (FK -> utilisateurs.utilisateur_id, INT, non nul) - Doit être un EMPLOYE
   * generation_resultante_id (FK -> generations_cartes.generation_id, INT, nullable) - Liée une fois la tâche terminée


* (Phase 3) validations_cartes


   * validation_id (PK, INT, auto-incrémenté)
   * date_soumission (TIMESTAMP, non nul, défaut CURRENT_TIMESTAMP)
   * date_validation (TIMESTAMP, nullable)
   * statut_validation (VARCHAR(50), non nul, défaut "En attente") - Ex: "En attente", "Approuvée", "Modif demandée"
   * commentaires_validation (TEXT, nullable)
   * generation_id (FK -> generations_cartes.generation_id, INT, unique, non nul) - Une seule validation par génération
   * validateur_id (FK -> utilisateurs.utilisateur_id, INT, nullable) - Qui a validé (un CHEF)


Contraintes d"intégrité et remarques :


* Les clés primaires (PK) sont typiquement des entiers auto-incrémentés.
* Les clés étrangères (FK) assurent la cohérence référentielle entre les tables.
* Des contraintes UNIQUE sont ajoutées sur les champs qui doivent être uniques (ex: email utilisateur, nom_role).
* Des contraintes NOT NULL sont appliquées aux champs obligatoires.
* Des valeurs par défaut (DEFAULT) sont utilisées pour simplifier les insertions (ex: date de création, statut initial).
* Le type JSON est utilisé pour stocker des données structurées mais flexibles (paramètres de style, préférences, paramètres de tâche).
* Les types DECIMAL sont utilisés pour les coordonnées géographiques pour une précision suffisante.
* Des index seront nécessaires sur les clés étrangères et potentiellement sur d"autres colonnes fréquemment utilisées dans les recherches (ex: date_creation, utilisateur_id dans generations_cartes).


Ce MLD fournit une structure claire pour la création de la base de données PostgreSQL.
Modèle Physique de Données (MPD) - PostgreSQL/PostGIS
Le MPD traduit le MLD en instructions SQL spécifiques pour créer les tables et les contraintes dans le SGBD cible, ici PostgreSQL avec son extension géospatiale PostGIS. Il précise les types de données exacts, les index, et les contraintes spécifiques à PostgreSQL.


-- Activer l\"extension PostGIS si ce n\"est pas déjà fait


-- CREATE EXTENSION IF NOT EXISTS postgis;


-- Table des Rôles


CREATE TABLE roles (


    role_id SERIAL PRIMARY KEY,


    nom_role VARCHAR(50) UNIQUE NOT NULL


);


-- Insertion des rôles de base


INSERT INTO roles (nom_role) VALUES (\"EMPLOYE\"), (\"CHEF\"), (\"ADMIN\");


-- Table des Utilisateurs


CREATE TABLE utilisateurs (


    utilisateur_id SERIAL PRIMARY KEY,


    nom_utilisateur VARCHAR(100) NOT NULL,


    email VARCHAR(255) UNIQUE NOT NULL,


    mot_de_passe_hash VARCHAR(255) NOT NULL, -- Stocker un hash sécurisé (ex: bcrypt)


    role_id INT NOT NULL REFERENCES roles(role_id),


    preferences_defaut JSONB NULL, -- Utilisation de JSONB pour de meilleures performances


    date_creation TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,


    est_actif BOOLEAN NOT NULL DEFAULT TRUE


);


-- Index sur l\"email pour des recherches rapides


CREATE INDEX idx_utilisateurs_email ON utilisateurs(email);


-- Index sur role_id


CREATE INDEX idx_utilisateurs_role_id ON utilisateurs(role_id);


-- Table des Styles Visuels


CREATE TABLE styles_visuels (


    style_id SERIAL PRIMARY KEY,


    nom_style VARCHAR(100) NOT NULL,


    description TEXT NULL,


    parametres_style JSONB NOT NULL, -- JSONB est généralement préféré


    est_predefini BOOLEAN NOT NULL DEFAULT FALSE,


    est_style_equipe BOOLEAN NOT NULL DEFAULT FALSE,


    createur_id INT NULL REFERENCES utilisateurs(utilisateur_id) ON DELETE SET NULL, -- Si l\"utilisateur est supprimé, le style n\"est pas supprimé mais le créateur devient NULL


    date_creation TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP


);


-- Index sur createur_id


CREATE INDEX idx_styles_visuels_createur_id ON styles_visuels(createur_id);


-- Table des Générations de Cartes


CREATE TABLE generations_cartes (


    generation_id SERIAL PRIMARY KEY,


    date_creation TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,


    latitude_centre DECIMAL(9,6) NOT NULL,


    longitude_centre DECIMAL(9,6) NOT NULL,


    -- Colonne géométrique pour le point central (optionnel mais utile pour requêtes spatiales)


    -- centre_geom GEOMETRY(Point, 4326) NULL, -- SRID 4326 pour WGS 84 (lat/lon)


    rayon_metres INT NOT NULL CHECK (rayon_metres > 0),


    geojson_source TEXT NULL,


    statut_generation VARCHAR(50) NOT NULL DEFAULT \"Terminée\",


    message_statut TEXT NULL,


    utilisateur_id INT NOT NULL REFERENCES utilisateurs(utilisateur_id) ON DELETE CASCADE, -- Si l\"utilisateur est supprimé, ses générations aussi


    style_id INT NOT NULL REFERENCES styles_visuels(style_id) ON DELETE RESTRICT, -- Empêche la suppression d\"un style utilisé


    projet_crm_id INT NULL -- Référence à une table projets_crm si elle existe (Phase 2+)


    -- Ajout d\"une contrainte CHECK pour le statut si nécessaire


    -- CONSTRAINT chk_statut_generation CHECK (statut_generation IN (\"En cours\", \"Terminée\", \"Erreur\"))


);


-- Index sur utilisateur_id et date_creation pour l\"historique


CREATE INDEX idx_generations_cartes_utilisateur_date ON generations_cartes(utilisateur_id, date_creation DESC);


-- Index sur style_id


CREATE INDEX idx_generations_cartes_style_id ON generations_cartes(style_id);


-- Index spatial sur le centre (si la colonne centre_geom est ajoutée)


-- CREATE INDEX idx_generations_cartes_centre_geom ON generations_cartes USING GIST (centre_geom);


-- Table des Exports de Cartes


CREATE TABLE exports_cartes (


    export_id SERIAL PRIMARY KEY,


    date_export TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,


    format_export VARCHAR(10) NOT NULL CHECK (format_export IN (\"SVG\", \"PNG\")),


    resolution_dpi INT NULL CHECK (resolution_dpi IS NULL OR resolution_dpi > 0),


    chemin_fichier VARCHAR(512) NULL,


    generation_id INT NOT NULL REFERENCES generations_cartes(generation_id) ON DELETE CASCADE -- Si la génération est supprimée, ses exports aussi


);


-- Index sur generation_id pour retrouver les exports d\"une génération


CREATE INDEX idx_exports_cartes_generation_id ON exports_cartes(generation_id);


-- Tables optionnelles pour les phases ultérieures --


-- (Phase 2+) Table des Projets CRM (Exemple simplifié)


-- CREATE TABLE projets_crm (


--     projet_crm_id SERIAL PRIMARY KEY,


--     nom_projet VARCHAR(255) NOT NULL,


--     identifiant_externe_crm VARCHAR(100) UNIQUE NULL


-- );


-- ALTER TABLE generations_cartes ADD CONSTRAINT fk_generations_cartes_projet_crm FOREIGN KEY (projet_crm_id) REFERENCES projets_crm(projet_crm_id) ON DELETE SET NULL;


-- CREATE INDEX idx_generations_cartes_projet_crm_id ON generations_cartes(projet_crm_id);


-- (Phase 3) Table des Tâches de Génération


-- CREATE TABLE taches_generation (


--     tache_id SERIAL PRIMARY KEY,


--     date_assignation TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,


--     date_echeance TIMESTAMPTZ NULL,


--     statut_tache VARCHAR(50) NOT NULL DEFAULT \"A faire\" CHECK (statut_tache IN (\"A faire\", \"En cours\", \"Terminée\", \"Annulée\")),


--     parametres_generation JSONB NOT NULL,


--     assignateur_id INT NOT NULL REFERENCES utilisateurs(utilisateur_id) ON DELETE CASCADE,


--     assigne_id INT NOT NULL REFERENCES utilisateurs(utilisateur_id) ON DELETE CASCADE,


--     generation_resultante_id INT NULL UNIQUE REFERENCES generations_cartes(generation_id) ON DELETE SET NULL -- Une tâche ne produit qu\"une génération


-- );


-- CREATE INDEX idx_taches_generation_assigne_statut ON taches_generation(assigne_id, statut_tache);


-- CREATE INDEX idx_taches_generation_assignateur_id ON taches_generation(assignateur_id);


-- (Phase 3) Table des Validations de Cartes


-- CREATE TABLE validations_cartes (


--     validation_id SERIAL PRIMARY KEY,


--     date_soumission TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,


--     date_validation TIMESTAMPTZ NULL,


--     statut_validation VARCHAR(50) NOT NULL DEFAULT \"En attente\" CHECK (statut_validation IN (\"En attente\", \"Approuvée\", \"Modif demandée\")),


--     commentaires_validation TEXT NULL,


--     generation_id INT UNIQUE NOT NULL REFERENCES generations_cartes(generation_id) ON DELETE CASCADE,


--     validateur_id INT NULL REFERENCES utilisateurs(utilisateur_id) ON DELETE SET NULL


-- );


-- CREATE INDEX idx_validations_cartes_statut ON validations_cartes(statut_validation);


-- CREATE INDEX idx_validations_cartes_validateur_id ON validations_cartes(validateur_id);


Choix techniques et justifications :


* PostgreSQL : SGBD relationnel robuste, open-source, performant et largement utilisé, offrant une bonne gestion de la concurrence et des fonctionnalités avancées.
* PostGIS : Extension géospatiale de référence pour PostgreSQL, indispensable si des traitements ou requêtes spatiales plus complexes étaient envisagés à l"avenir (calculs de distance, intersections, etc.). Même si le MPD ci-dessus ne l"utilise pas directement (pas de type GEOMETRY pour simplifier), son activation est recommandée pour l"écosystème.
* SERIAL : Type PostgreSQL pour les clés primaires auto-incrémentées.
* VARCHAR(n) : Pour les chaînes de caractères de longueur variable mais limitée.
* TEXT : Pour les chaînes de caractères de longueur potentiellement importante (description, GeoJSON, commentaires).
* INT : Pour les identifiants et nombres entiers.
* DECIMAL(p, s) : Pour les coordonnées géographiques, offrant une précision fixe contrairement aux types flottants.
* BOOLEAN : Pour les indicateurs vrai/faux.
* JSONB : Type binaire pour stocker des données JSON. Préférable à JSON pour l"indexation et les performances en lecture/écriture.
* TIMESTAMPTZ : Type de date/heure avec fuseau horaire, recommandé pour stocker les timestamps de manière non ambiguë.
* REFERENCES table(colonne) : Déclaration des clés étrangères.
* ON DELETE CASCADE / SET NULL / RESTRICT : Définition du comportement lors de la suppression d"une ligne référencée. CASCADE supprime les lignes dépendantes, SET NULL met la clé étrangère à NULL, RESTRICT empêche la suppression si des lignes dépendent.
* UNIQUE : Contrainte d"unicité.
* NOT NULL : Contrainte de non-nullité.
* DEFAULT : Valeur par défaut si non fournie à l"insertion.
* CHECK : Contrainte de validation sur les valeurs possibles d"une colonne.
* INDEX : Création d"index pour accélérer les recherches sur les colonnes fréquemment utilisées dans les clauses WHERE ou JOIN.


Ce MPD fournit les instructions SQL nécessaires pour créer la structure de base de données initiale du projet ActivMap.
Architecture Technique
L"architecture technique d"ActivMap est conçue pour être robuste, évolutive et maintenable, en s"appuyant sur des technologies modernes et éprouvées. Elle est basée sur une approche microservices conteneurisée avec Docker, facilitant le développement, le déploiement et la gestion des différents composants.
1. Vue d"ensemble de l"architecture
L"architecture globale peut être représentée comme suit (description textuelle d"un diagramme conceptuel) :


* Utilisateur (Navigateur Web) : Interagit avec l"application via une interface web.
* Proxy Inverse (Nginx) : Point d"entrée unique pour les requêtes HTTP/HTTPS. Il assure le routage vers le frontend ou le backend, la terminaison SSL et potentiellement la mise en cache statique et la limitation de débit.
* Frontend (Svelte) : Application monopage (SPA) responsable de l"interface utilisateur. Elle communique avec le backend via des appels API RESTful.
* Backend (API Flask) : Application Python/Flask exposant une API RESTful. Elle gère la logique métier, l"authentification, les interactions avec la base de données, le cache, et orchestre le processus de génération de cartes.
* Moteur de Génération de Cartes : Logique spécifique (probablement intégrée au backend ou appelée par celui-ci) qui interroge l"API OpenStreetMap (Overpass), traite les données géographiques, applique les styles et génère les fichiers SVG/PNG.
* Base de Données (PostgreSQL/PostGIS) : Stocke toutes les données persistantes de l"application (utilisateurs, rôles, styles, historique des générations, etc.). L"extension PostGIS est disponible pour d"éventuelles fonctionnalités géospatiales avancées.
* Cache (Redis) : Utilisé pour stocker les sessions utilisateur, mettre en cache des données fréquemment accédées (ex: styles, résultats de requêtes OSM) et potentiellement gérer une file d"attente pour les tâches asynchrones (si Celery est utilisé pour la génération de cartes).
* API Externe (OpenStreetMap - Overpass API) : Source de données géographiques interrogée par le moteur de génération.
* (Optionnel) CRM FeelObject : Système externe avec lequel le backend peut interagir via API pour lier les générations aux projets.


Le fichier docker-compose.yml présent dans le dépôt GitHub confirme l"utilisation de ces composants principaux (backend Flask, frontend Svelte via un serveur de développement Node.js, base de données PostgreSQL, cache Redis, proxy Nginx) et définit comment ils sont orchestrés via Docker.


Flux typique (Génération de carte) :


1. L"utilisateur saisit les coordonnées/rayon et clique sur "Générer" dans l"interface Svelte.
2. Le frontend envoie une requête POST à l"API Flask via Nginx.
3. Le backend Flask reçoit la requête, valide les paramètres et l"authentification (via session Redis ou token JWT).
4. Le backend lance le processus de génération : interroge l"API Overpass, traite les données, récupère le style depuis PostgreSQL, génère le SVG/PNG.
5. (Optionnel) Le backend peut mettre en cache les données OSM ou le résultat.
6. Le backend stocke les métadonnées de la génération dans PostgreSQL.
7. Le backend renvoie une réponse au frontend (ex: URL du fichier généré ou données pour prévisualisation).
8. Le frontend affiche la prévisualisation ou propose le téléchargement.
2. Architecture Détaillée
Cette section approfondit la description des composants clés de l"architecture technique d"ActivMap.
Couche Frontend (Svelte)
* Technologie : Svelte est un compilateur JavaScript moderne qui transforme le code déclaratif des composants en code JavaScript impératif optimisé. Il est choisi pour sa performance, sa simplicité et sa taille réduite de bundle final.
* Rôle : Responsable de toute l"interface utilisateur présentée dans le navigateur. C"est une Application Monopage (SPA) qui charge une seule page HTML initiale et met à jour dynamiquement le contenu via JavaScript.
* Structure : L"application frontend est structurée en composants réutilisables (ex: formulaire de génération, prévisualisation de carte, liste d"historique, éléments d"interface utilisateur). SvelteKit pourrait être utilisé pour gérer le routage, le rendu côté serveur (SSR) initial (si nécessaire pour le SEO ou la performance perçue au premier chargement, bien que moins critique pour une application interne) et la génération de site statique (moins pertinent ici).
* Communication : Interagit exclusivement avec le backend via des requêtes HTTP asynchrones (typiquement fetch ou une librairie comme axios) vers l"API RESTful exposée par Flask. Les données sont échangées au format JSON.
* Gestion de l"état : L"état global de l"application (ex: utilisateur connecté, style sélectionné, carte en cours de prévisualisation) est géré par les mécanismes intégrés de Svelte (stores) ou une librairie dédiée si la complexité augmente.
* Cartographie : L"affichage interactif de la carte dans la zone de prévisualisation utilise une librairie JavaScript de cartographie comme Leaflet ou MapLibre GL JS. Cette librairie est responsable du rendu des fonds de carte (si nécessaire) et surtout de l"affichage des données vectorielles (SVG ou GeoJSON) générées par le backend.
* Développement : Le fichier docker-compose.yml montre un service frontend utilisant Node.js et npm run dev, typique d"un environnement de développement Svelte avec rechargement à chaud (hot-reloading).
Couche Backend (API Flask)
* Technologie : Flask est un micro-framework Python léger et flexible, idéal pour construire des API RESTful. Il est choisi pour sa simplicité, son écosystème riche (extensions) et la maîtrise de Python par l"équipe.
* Rôle : Cœur logique de l"application. Il expose une API RESTful sécurisée consommée par le frontend. Il gère :
   * L"authentification et l"autorisation des utilisateurs (ex: via JWT ou sessions).
   * La validation des données reçues du frontend.
   * L"interaction avec la base de données (via un ORM comme SQLAlchemy ou directement avec des requêtes SQL).
   * L"orchestration du processus de génération de cartes.
   * La communication avec les services externes (API Overpass, potentiellement CRM).
   * La gestion du cache (Redis).
* Structure : L"application Flask est organisée en modules (Blueprints) pour séparer les différentes fonctionnalités (ex: authentification, gestion des générations, gestion des styles, administration). Elle suit les bonnes pratiques de développement Flask (structure de projet, gestion des configurations, etc.).
* API RESTful : Les points d"accès (endpoints) sont définis pour chaque ressource (ex: /api/auth/login, /api/generations, /api/styles, /api/users). Les méthodes HTTP (GET, POST, PUT, DELETE) sont utilisées conformément aux conventions REST.
* ORM/Base de données : SQLAlchemy est un choix courant avec Flask pour interagir avec la base de données PostgreSQL. Il permet de mapper les modèles de données Python aux tables de la base de données et de gérer les transactions.
* Développement : Le service backend dans docker-compose.yml utilise l"image Python, installe les dépendances et lance l"application Flask avec flask run --host=0.0.0.0 --reload, indiquant un environnement de développement.
Base de Données (PostgreSQL + PostGIS)
* Technologie : PostgreSQL est un SGBD relationnel open-source puissant et fiable. L"extension PostGIS ajoute des capacités de stockage et d"interrogation de données géospatiales.
* Rôle : Assure la persistance des données de l"application (utilisateurs, rôles, styles, historique, etc.) de manière structurée et fiable.
* Modèle : Implémente le Modèle Physique de Données (MPD) défini précédemment, avec ses tables, colonnes, types de données, clés primaires/étrangères, index et contraintes.
* Accès : Le backend Flask communique avec la base de données via une connexion TCP/IP, en utilisant les identifiants définis dans les variables d"environnement (DATABASE_URL).
* PostGIS : Bien que non explicitement utilisé dans le MPD de base pour les types GEOMETRY, sa présence permettrait d"ajouter facilement des fonctionnalités géospatiales avancées si nécessaire (ex: rechercher les générations dans un rayon donné, calculer des intersections).
* Gestion : Le service db dans docker-compose.yml utilise l"image officielle postgres:14-alpine, configure les variables d"environnement pour l"utilisateur et la base de données, et monte un volume nommé (postgres_data) pour assurer la persistance des données même si le conteneur est recréé.
Moteur de Génération de Cartes
* Rôle : Composant (probablement une partie du backend Flask) responsable de la transformation des données brutes d"OpenStreetMap en un plan stylisé exportable.
* Processus :
   1. Récupération des données OSM : Interroge l"API Overpass avec une requête spécifiant la zone géographique (bounding box ou cercle défini par lat/lon/rayon) et les types d"éléments OSM à récupérer (routes, bâtiments, points d"intérêt, etc.).
   2. Traitement des données : Filtre, nettoie et simplifie potentiellement les données GeoJSON reçues d"Overpass.
   3. Application du style : Utilise les paramètres du style visuel sélectionné (récupéré depuis la base de données) pour définir l"apparence des différents éléments (couleurs, épaisseurs de trait, icônes, etc.).
   4. Génération du rendu : Utilise une librairie Python pour générer le fichier final :
      * SVG : Des librairies comme svgwrite ou la manipulation directe de XML peuvent être utilisées pour créer le fichier SVG vectoriel.
      * PNG : Des librairies comme Pillow (pour le dessin basique) ou des outils plus spécialisés comme Mapnik (plus complexe mais puissant) ou CairoSVG (pour convertir le SVG généré en PNG) pourraient être employées.
* Intégration : Cette logique peut être implémentée dans des fonctions ou classes dédiées au sein du backend Flask. Pour les générations potentiellement longues, ce processus pourrait être délégué à une tâche asynchrone (ex: via Celery et Redis) pour ne pas bloquer la requête API principale.
Autres Composants
* Proxy Inverse (Nginx) : Le service proxy dans docker-compose.yml utilise l"image Nginx. Il écoute sur les ports 80 et 443 et route les requêtes : celles commençant par /api vers le backend Flask (port 5000), et les autres vers le serveur de développement frontend (port 8080 dans le conteneur, mappé sur 3000 sur l"hôte). Il gère également les certificats SSL/TLS montés depuis le volume ./certs.
* Cache (Redis) : Le service redis utilise l"image Redis officielle. Il est accessible par le backend Flask pour stocker des données volatiles comme les sessions utilisateur, les résultats mis en cache ou les messages pour une file d"attente Celery. Un volume nommé (redis_data) assure la persistance si Redis est configuré pour cela.
3. Flux de Données
Comprendre les flux de données principaux au sein de l"architecture ActivMap est essentiel pour visualiser comment l"information circule entre les différents composants lors des opérations clés.
Flux 1 : Authentification Utilisateur
1. Utilisateur -> Navigateur : Saisit l"identifiant et le mot de passe sur la page de connexion.
2. Navigateur (Frontend Svelte) -> Proxy (Nginx) : Envoie une requête POST vers /api/auth/login avec les identifiants en JSON dans le corps de la requête.
3. Proxy (Nginx) -> Backend (API Flask) : Transmet la requête au service backend.
4. Backend (API Flask) -> Base de Données (PostgreSQL) : Récupère l"utilisateur correspondant à l"identifiant fourni.
5. Base de Données (PostgreSQL) -> Backend (API Flask) : Retourne les informations de l"utilisateur, y compris le hash du mot de passe.
6. Backend (API Flask) : Vérifie si l"utilisateur existe et si le mot de passe fourni correspond au hash stocké (en utilisant une fonction de hachage sécurisée comme bcrypt).
7. Si authentification réussie :
   * Backend (API Flask) -> Cache (Redis) : Crée une session utilisateur ou génère un token JWT (JSON Web Token) et le stocke potentiellement dans Redis (pour la session) ou le renvoie directement au client (pour JWT).
   * Backend (API Flask) -> Proxy (Nginx) : Renvoie une réponse de succès (ex: 200 OK) avec les informations de l"utilisateur (sans le mot de passe) et le token/cookie de session.
8. Proxy (Nginx) -> Navigateur (Frontend Svelte) : Transmet la réponse.
9. Navigateur (Frontend Svelte) : Stocke le token/cookie de session et redirige l"utilisateur vers le tableau de bord, mettant à jour l"état de l"application pour indiquer que l"utilisateur est connecté.
10. Si authentification échouée :
   * Backend (API Flask) -> Proxy (Nginx) : Renvoie une réponse d"erreur (ex: 401 Unauthorized).
   * Proxy (Nginx) -> Navigateur (Frontend Svelte) : Transmet la réponse d"erreur.
   * Navigateur (Frontend Svelte) : Affiche un message d"erreur à l"utilisateur.
Flux 2 : Génération d"une Carte par Coordonnées (Utilisateur connecté)
1. Utilisateur -> Navigateur (Frontend Svelte) : Saisit latitude, longitude, rayon, choisit un style et clique sur "Générer".
2. Navigateur (Frontend Svelte) -> Proxy (Nginx) : Envoie une requête POST vers /api/generations avec les paramètres (lat, lon, rayon, style_id) et le token/cookie de session dans les en-têtes ou le corps.
3. Proxy (Nginx) -> Backend (API Flask) : Transmet la requête au backend.
4. Backend (API Flask) : Valide le token/cookie de session (potentiellement via Redis) et les paramètres de la requête. Vérifie les permissions de l"utilisateur.
5. Backend (API Flask) -> API Externe (Overpass API) : Envoie une requête HTTP GET ou POST à l"API Overpass avec la requête spatiale pour récupérer les données OSM de la zone définie.
6. API Externe (Overpass API) -> Backend (API Flask) : Renvoie les données géographiques (généralement en GeoJSON).
7. Backend (API Flask) -> Base de Données (PostgreSQL) : Récupère les détails du style_id demandé.
8. Base de Données (PostgreSQL) -> Backend (API Flask) : Renvoie les paramètres du style.
9. Backend (API Flask - Moteur de Génération) : Traite les données OSM, applique les paramètres de style, et génère le fichier de carte (ex: SVG).
10. Backend (API Flask) -> Base de Données (PostgreSQL) : Insère une nouvelle ligne dans la table generations_cartes avec les informations de la génération (utilisateur_id, lat, lon, rayon, style_id, statut="Terminée").
11. Base de Données (PostgreSQL) -> Backend (API Flask) : Confirme l"insertion et retourne l"ID de la nouvelle génération.
12. Backend (API Flask) -> Proxy (Nginx) : Renvoie une réponse de succès (ex: 201 Created ou 200 OK) contenant les informations de la génération (ID, métadonnées) et potentiellement le contenu SVG ou un lien vers celui-ci.
13. Proxy (Nginx) -> Navigateur (Frontend Svelte) : Transmet la réponse.
14. Navigateur (Frontend Svelte) : Met à jour l"interface pour afficher la prévisualisation de la carte (en utilisant le SVG reçu ou en le chargeant depuis un lien) et active les boutons d"export.
Flux 3 : Export d"une Carte (SVG)
1. Utilisateur -> Navigateur (Frontend Svelte) : Clique sur le bouton "Exporter SVG" pour une carte prévisualisée.
2. Navigateur (Frontend Svelte) -> Proxy (Nginx) : Envoie une requête GET vers /api/generations/{generation_id}/export?format=svg (ou une requête POST si des paramètres d"export sont nécessaires), incluant le token/cookie de session.
3. Proxy (Nginx) -> Backend (API Flask) : Transmet la requête.
4. Backend (API Flask) : Valide la session, récupère l"ID de la génération, vérifie les permissions.
5. Backend (API Flask) -> Base de Données (PostgreSQL) : Récupère les détails de la génération (si nécessaire pour régénérer le fichier ou trouver son emplacement).
6. Backend (API Flask) : Localise ou régénère le fichier SVG correspondant à la generation_id.
7. Backend (API Flask) -> Base de Données (PostgreSQL) : Insère une nouvelle ligne dans la table exports_cartes pour tracer cet export.
8. Backend (API Flask) -> Proxy (Nginx) : Renvoie une réponse HTTP avec le contenu du fichier SVG, en définissant les en-têtes appropriés (Content-Type: image/svg+xml, Content-Disposition: attachment; filename="...") pour déclencher le téléchargement côté navigateur.
9. Proxy (Nginx) -> Navigateur (Frontend Svelte) : Transmet la réponse.
10. Navigateur : Propose à l"utilisateur d"enregistrer le fichier SVG.


Ces flux illustrent les interactions typiques. D"autres flux existent pour la gestion des styles, des utilisateurs, de l"historique, etc., mais suivent des schémas similaires d"interaction entre le frontend, le backend, la base de données et potentiellement le cache ou des API externes.
4. Sécurité
La sécurité est une préoccupation majeure pour ActivMap, une application interne manipulant potentiellement des données liées aux projets de FeelObject. L"architecture et les choix technologiques intègrent plusieurs couches de protection pour garantir la confidentialité, l"intégrité et la disponibilité des données et du service.
Sécurité Périmétrique et Réseau
* Proxy Inverse (Nginx) : Agit comme un point d"entrée unique et contrôlé. Il peut être configuré pour filtrer les requêtes malveillantes basiques, gérer les connexions et masquer l"architecture interne.
* HTTPS/TLS : Toutes les communications entre le navigateur de l"utilisateur et le serveur (via Nginx) sont chiffrées à l"aide de certificats SSL/TLS (visibles dans la configuration Nginx du docker-compose.yml qui monte un volume ./certs). Cela empêche l"écoute clandestine et l"altération des données en transit.
* Pare-feu : Bien que non géré directement par l"application, l"infrastructure d"hébergement (VPS ou cloud) doit être configurée avec un pare-feu limitant les ports ouverts aux seuls ports nécessaires (80 et 443 pour Nginx).
Sécurité Applicative (Backend - Flask)
* Authentification Robuste :
   * Utilisation d"un système d"identifiant unique (email) et de mot de passe.
   * Stockage sécurisé des mots de passe : les mots de passe ne sont jamais stockés en clair, mais sous forme de hashs cryptographiques forts et salés (ex: en utilisant bcrypt avec Flask-Bcrypt).
   * Gestion de session sécurisée (si utilisation de sessions Flask) ou utilisation de tokens JWT signés avec une clé secrète forte (JWT_SECRET_KEY visible dans le docker-compose.yml, à changer impérativement en production).
* Autorisation (Contrôle d"accès basé sur les rôles - RBAC) :
   * Chaque endpoint de l"API Flask vérifie le rôle de l"utilisateur authentifié (via sa session ou son token JWT) avant d"autoriser l"action demandée.
   * Des décorateurs Flask peuvent être utilisés pour simplifier l"implémentation de ces vérifications (ex: @role_required(\"ADMIN\")).
* Validation des Entrées :
   * Toutes les données provenant du client (corps de requête, paramètres d"URL, en-têtes) sont systématiquement validées et nettoyées côté backend avant d"être utilisées.
   * Des librairies comme Marshmallow ou Pydantic peuvent être utilisées avec Flask pour définir des schémas de validation stricts.
* Protection contre les Vulnérabilités OWASP Top 10 :
   * Injection (SQL, etc.) : L"utilisation d"un ORM comme SQLAlchemy avec des requêtes paramétrées prévient nativement la plupart des injections SQL. Toute requête SQL directe doit être évitée ou construite avec une extrême prudence.
   * Cross-Site Scripting (XSS) : Le frontend Svelte, s"il est correctement utilisé, échappe par défaut les données affichées dans le DOM. Côté backend, les API renvoient du JSON, limitant les risques directs, mais il faut s"assurer de ne pas générer de HTML ou de script côté serveur de manière non sécurisée. L"utilisation d"en-têtes HTTP de sécurité (Content-Security-Policy, X-Content-Type-Options) est recommandée.
   * Cross-Site Request Forgery (CSRF) : Si l"authentification repose sur les cookies de session, Flask-WTF ou des mécanismes similaires doivent être utilisés pour générer et valider des tokens CSRF pour toutes les requêtes modifiant l"état (POST, PUT, DELETE).
   * Autres vulnérabilités : Configuration sécurisée des composants, gestion des dépendances (mises à jour régulières pour corriger les failles connues), journalisation appropriée pour détecter les activités suspectes.
* Gestion des Secrets : Les clés secrètes (clé JWT, clés d"API externes, mot de passe BDD) ne doivent jamais être codées en dur dans le code source. Elles sont gérées via des variables d"environnement (comme vu dans docker-compose.yml avec env_file et environment) ou un système de gestion de secrets dédié en production.
* Limitation de Débit (Rate Limiting) :
   * Implémentée au niveau du proxy Nginx ou directement dans l"application Flask (ex: avec Flask-Limiter et Redis) pour prévenir les abus et les attaques par force brute sur l"authentification ou les endpoints coûteux.
   * Le commit rate_limits visible dans l"historique GitHub suggère qu"une réflexion ou une implémentation a été faite à ce sujet.
Sécurité Frontend (Svelte)
* Gestion des Tokens/Sessions : Stockage sécurisé des tokens JWT (ex: localStorage ou sessionStorage, avec les précautions d"usage contre XSS) ou gestion appropriée des cookies de session (HttpOnly, Secure).
* Validation Côté Client : Bien que la validation principale doive toujours être côté serveur, une validation initiale côté client améliore l"UX et réduit la charge serveur, mais ne doit jamais être considérée comme une mesure de sécurité suffisante.
* Dépendances : Maintien à jour des dépendances JavaScript (npm audit).
Sécurité de la Base de Données (PostgreSQL)
* Accès Restreint : Le serveur PostgreSQL n"est pas exposé directement sur internet mais uniquement accessible depuis le réseau interne Docker par le service backend.
* Authentification Forte : Utilisation d"un utilisateur dédié (postgres dans l"exemple, mais un utilisateur applicatif spécifique serait mieux) avec un mot de passe fort, géré via les variables d"environnement.
* Permissions Minimales : L"utilisateur applicatif ne devrait avoir que les permissions strictement nécessaires sur les tables (SELECT, INSERT, UPDATE, DELETE) et non des droits d"administration.
* Sauvegardes Sécurisées : Les sauvegardes doivent être stockées dans un endroit sécurisé et potentiellement chiffrées.
Sécurité du Déploiement (Docker)
* Images Officielles et Minimales : Utilisation d"images Docker officielles et si possible minimales (ex: alpine) pour réduire la surface d"attaque.
* Utilisateurs Non-Root : Exécution des processus dans les conteneurs avec des utilisateurs non-privilégiés lorsque possible.
* Secrets Docker : En production, utiliser les mécanismes de gestion des secrets de Docker Swarm ou Kubernetes plutôt que des variables d"environnement simples.
* Scan de Vulnérabilités : Utilisation d"outils pour scanner les images Docker à la recherche de vulnérabilités connues.


En combinant ces différentes mesures à chaque niveau de l"architecture, ActivMap vise à établir une posture de sécurité solide, adaptée aux risques d"une application web interne.
5. Stratégie de Déploiement
La stratégie de déploiement d"ActivMap vise à mettre en production l"application de manière fiable, reproductible et sécurisée, en tirant parti de la conteneurisation Docker définie dans le projet.
Environnements
Au minimum, deux environnements sont nécessaires :


1. Développement : L"environnement local de chaque développeur, utilisant docker-compose.yml pour lancer tous les services (backend, frontend avec rechargement à chaud, BDD, Redis, proxy). Cet environnement est optimisé pour la rapidité de développement et le débogage.
2. Production : L"environnement cible où l"application sera accessible aux utilisateurs finaux (EMPLOYEs, CHEFs, ADMINs de FeelObject). Cet environnement doit être stable, sécurisé et performant.


Un environnement de Staging ou de Pré-production, répliquant au plus près l"environnement de production, est fortement recommandé pour tester les nouvelles versions avant leur déploiement final.
Infrastructure Cible (Production)
L"infrastructure la plus simple et courante pour une application de cette taille serait :


* Serveur(s) Hôte(s) : Un ou plusieurs serveurs privés virtuels (VPS) ou instances cloud (chez OVH, Scaleway, AWS, GCP, Azure...) sous Linux (ex: Ubuntu, Debian).
* Docker Engine & Docker Compose : Installés sur le(s) serveur(s) hôte(s) pour exécuter les conteneurs définis.
* Serveur de Base de Données : Peut être un conteneur PostgreSQL géré via Docker Compose (comme en développement, mais avec des configurations de production pour la performance et les sauvegardes) ou, pour plus de robustesse et de facilité de gestion, un service de base de données managé proposé par le fournisseur cloud.
* Serveur Cache : Peut être un conteneur Redis géré via Docker Compose ou un service managé.
* Stockage des Fichiers Générés : Les fichiers SVG/PNG exportés pourraient être stockés :
   * Sur un volume Docker persistant monté dans le conteneur backend/proxy.
   * Sur un système de stockage objet (comme AWS S3, OVH Object Storage) si le volume devient important ou si une haute disponibilité est requise. Le backend générerait alors des URL pré-signées pour le téléchargement.
Processus de Déploiement
Le déploiement en production implique plusieurs étapes :


1. Build des Images Docker de Production :
   * Backend : Utiliser un Dockerfile de production qui installe uniquement les dépendances nécessaires (pas les dépendances de développement), copie le code applicatif, et utilise un serveur WSGI de production (comme Gunicorn ou uWSGI) pour lancer l"application Flask (plutôt que le serveur de développement Flask).
   * Frontend : Utiliser un Dockerfile de production multi-étapes. Une première étape utilise Node.js pour builder l"application Svelte (npm run build), générant des fichiers statiques optimisés (HTML, CSS, JS). Une seconde étape copie ces fichiers statiques dans une image Nginx légère qui servira uniquement à les distribuer.
2. Configuration de Production : Créer un fichier docker-compose.prod.yml (ou un fichier similaire) qui :
   * Utilise les images Docker de production buildées à l"étape précédente.
   * Configure les variables d"environnement spécifiques à la production (URL de la BDD, clés secrètes fortes, désactivation du mode debug).
   * Configure Nginx pour servir les fichiers statiques du frontend buildé et pour gérer HTTPS avec les certificats de production (potentiellement via Let"s Encrypt).
   * Configure les volumes persistants pour la base de données, Redis et éventuellement les fichiers générés.
   * Configure les stratégies de redémarrage (restart: always).
3. Déploiement sur le Serveur :
   * Copier le fichier docker-compose.prod.yml et les fichiers de configuration nécessaires (ex: nginx.conf de production) sur le serveur cible.
   * (Si les images ne sont pas sur un registre) Transférer les images Docker buildées sur le serveur (via docker save/docker load ou un registre Docker privé/public).
   * Se connecter au serveur et exécuter docker-compose -f docker-compose.prod.yml up -d pour démarrer tous les services en arrière-plan.
4. Mises à Jour :
   * Builder les nouvelles images de production.
   * Transférer les nouvelles images sur le serveur.
   * Exécuter docker-compose -f docker-compose.prod.yml pull (si utilisation d"un registre) puis docker-compose -f docker-compose.prod.yml up -d --remove-orphans pour mettre à jour les services en utilisant les nouvelles images. Docker Compose recrée uniquement les conteneurs dont l"image a changé.
   * Gérer les migrations de base de données si le schéma a évolué (ex: via Flask-Migrate/Alembic).
Automatisation (CI/CD)
Pour améliorer la fiabilité et la fréquence des déploiements, un pipeline d"Intégration Continue et de Déploiement Continu (CI/CD) peut être mis en place (ex: avec GitHub Actions, GitLab CI, Jenkins) :


1. Intégration Continue (CI) : À chaque push sur la branche principale (ou une branche de release) :
   * Exécution des tests automatisés (backend et frontend).
   * Analyse statique du code (linting).
   * Build des images Docker de production.
   * (Optionnel) Push des images vers un registre Docker.
2. Déploiement Continu (CD) : Après le succès de la CI (automatiquement ou manuellement) :
   * Connexion sécurisée au serveur de production.
   * Récupération des dernières images depuis le registre (ou transfert).
   * Exécution des commandes docker-compose pour mettre à jour l"application.
   * Exécution des migrations de base de données.


Cette stratégie basée sur Docker et Docker Compose offre une bonne flexibilité et reproductibilité pour le déploiement d"ActivMap, tout en permettant une évolution future vers des orchestrateurs plus complexes comme Kubernetes si les besoins en scalabilité augmentent significativement.
Choix des Technologies
Le développement d"ActivMap repose sur un ensemble de technologies choisies pour leur adéquation avec les besoins du projet, leur maturité, leur performance et l"expertise potentielle au sein de l"équipe de FeelObject. L"architecture conteneurisée avec Docker permet également une certaine flexibilité si des ajustements technologiques s"avéraient nécessaires à l"avenir.
1. Justification Backend : Python / Flask
Le choix de Python comme langage principal pour le backend, associé au micro-framework Flask, est motivé par plusieurs facteurs clés, confirmés par la structure observée dans le dépôt GitHub et le fichier docker-compose.yml.


* Simplicité et Rapidité de Développement : Python est réputé pour sa syntaxe claire et concise, ce qui accélère le processus de développement et facilite la maintenance du code. Flask, en tant que micro-framework, suit cette philosophie en offrant un noyau minimaliste mais extensible. Il permet de démarrer rapidement un projet d"API sans imposer une structure rigide, ce qui est idéal pour un projet comme ActivMap où la flexibilité est appréciable.
* Écosystème Riche : Python bénéficie d"un vaste écosystème de bibliothèques tierces via PyPI. Pour ActivMap, cela inclut des outils essentiels comme :
   * SQLAlchemy : Un ORM puissant pour interagir avec la base de données PostgreSQL.
   * Flask-RESTful / Flask-Smorest / Marshmallow / Pydantic : Pour construire facilement des API RESTful et valider les données.
   * Flask-Login / Flask-JWT-Extended : Pour gérer l"authentification et les sessions/tokens.
   * Requests : Pour interagir avec l"API externe Overpass.
   * Bibliothèques géospatiales : Des bibliothèques comme Shapely, Fiona, GeoPandas (bien que potentiellement lourdes) ou des outils plus spécifiques pourraient être utilisées pour le traitement des données GeoJSON ou l"interaction avec PostGIS.
   * Bibliothèques de génération d"images/SVG : Pillow, svgwrite, CairoSVG pour la création des exports.
   * Flask-Migrate (Alembic) : Pour gérer les migrations de schéma de base de données.
   * Flask-Limiter : Pour la limitation de débit.
* Performance : Bien que Python soit un langage interprété, Flask, combiné à un serveur WSGI performant comme Gunicorn ou uWSGI en production, offre des performances tout à fait suffisantes pour les besoins d"une application interne comme ActivMap. Les opérations potentiellement longues (génération de cartes) peuvent être optimisées ou rendues asynchrones.
* Maturité et Communauté : Python et Flask sont des technologies matures, largement adoptées, avec une documentation abondante et une communauté active. Cela garantit un bon support, des mises à jour régulières et la disponibilité de ressources pour résoudre les problèmes.
* Compétences : Python est un langage très populaire et souvent maîtrisé par les développeurs, ce qui facilite l"intégration de nouveaux membres dans l"équipe ou la maintenance future de l"application.
* Intégration avec la Data Science / Géomatique : L"écosystème Python est particulièrement fort dans les domaines de l"analyse de données et du traitement géospatial, ce qui pourrait ouvrir des perspectives intéressantes pour des évolutions futures d"ActivMap.


En résumé, Python et Flask constituent un choix solide et pragmatique pour le backend d"ActivMap, offrant un bon équilibre entre rapidité de développement, flexibilité, performance et accès à un écosystème riche.
2. Justification Frontend : Svelte
Le choix de Svelte pour le développement de l"interface utilisateur (frontend) d"ActivMap, tel qu"indiqué par la présence d"un service frontend basé sur svelte-app dans le docker-compose.yml, est pertinent et présente plusieurs avantages significatifs pour ce type de projet.


* Performance et Taille Réduite : Contrairement aux frameworks traditionnels comme React ou Vue qui effectuent une partie importante de leur travail dans le navigateur (via un Virtual DOM), Svelte est un compilateur. Il déplace ce travail en amont, lors de la phase de build, pour générer du code JavaScript impératif hautement optimisé et très léger. Il en résulte des applications plus rapides au démarrage, plus réactives et avec une empreinte mémoire plus faible, ce qui est bénéfique même pour une application interne.
* Simplicité et Productivité : La syntaxe de Svelte est conçue pour être proche du HTML, CSS et JavaScript standard, réduisant la courbe d"apprentissage. L"écriture de composants est souvent plus concise qu"avec d"autres frameworks. La gestion de l"état réactif est intégrée de manière élégante et simple, sans nécessiter de concepts complexes ou de boilerplate excessif, ce qui améliore la productivité des développeurs.
* Réactivité Native : La réactivité est au cœur de Svelte. Les mises à jour du DOM sont gérées de manière chirurgicale et efficace par le code compilé, sans la surcharge d"un Virtual DOM, conduisant à une excellente performance pour les interfaces interactives comme celle d"ActivMap (prévisualisation de carte, formulaires dynamiques).
* Bundling et Optimisation : Svelte intègre nativement des fonctionnalités comme le "scoped CSS" (le style d"un composant n"affecte pas les autres) et facilite le "tree-shaking" (élimination du code non utilisé), contribuant à la légèreté des bundles finaux.
* Écosystème Grandissant : Bien que plus jeune que React ou Vue, l"écosystème Svelte est en pleine croissance. SvelteKit, le framework applicatif officiel construit sur Svelte, offre des solutions intégrées pour le routage, le rendu côté serveur (SSR), la génération de sites statiques (SSG), et la gestion des endpoints d"API, bien que pour ActivMap, une SPA simple soit probablement suffisante.
* Intégration Facile avec les Librairies JavaScript : Svelte s"intègre sans problème avec les librairies JavaScript existantes, comme les librairies de cartographie (Leaflet, MapLibre GL JS) nécessaires pour la prévisualisation.


Pour une application comme ActivMap, où l"interactivité et la réactivité de l"interface sont importantes (manipulation de formulaires, affichage de cartes), mais où la complexité globale reste maîtrisée, Svelte offre un excellent compromis entre performance, simplicité de développement et maintenabilité. Son approche par compilation le distingue et en fait un choix moderne et efficace pour construire des interfaces web performantes.
3. Justification Base de Données : PostgreSQL + PostGIS
Le choix de PostgreSQL comme système de gestion de base de données relationnelle (SGBDR) pour ActivMap, confirmé par le service db utilisant l"image postgres:14-alpine dans docker-compose.yml, est un choix standard et judicieux pour de nombreuses applications web, y compris celle-ci.


* Robustesse et Fiabilité : PostgreSQL est reconnu pour sa robustesse, sa conformité aux standards SQL et sa fiabilité éprouvée en production depuis de nombreuses années. Il assure l"intégrité des données grâce à une gestion transactionnelle ACID (Atomicité, Cohérence, Isolation, Durabilité).
* Open Source et Communauté Active : Étant un projet open-source mature, PostgreSQL bénéficie d"une large communauté, d"une documentation complète et d"évolutions constantes. Il n"implique aucun coût de licence.
* Fonctionnalités Avancées : PostgreSQL offre un riche ensemble de fonctionnalités qui vont au-delà du SQL standard, incluant des types de données avancés (JSONB, Array, etc.), des fonctions et opérateurs complexes, l"indexation avancée (GIN, GiST), la réplication, etc. Le support du type JSONB est particulièrement utile pour stocker les paramètres de style ou les préférences utilisateur de manière flexible mais indexable.
* Performance et Scalabilité : PostgreSQL offre d"excellentes performances pour une large gamme de charges de travail et peut être configuré pour monter en charge (scalabilité verticale et horizontale via la réplication).
* Extension PostGIS : C"est l"argument décisif pour une application manipulant des données géographiques, même de manière simple comme ActivMap. PostGIS transforme PostgreSQL en une base de données géospatiale puissante, ajoutant des types de données géométriques (GEOMETRY, GEOGRAPHY), des index spatiaux (R-Tree via GiST) et une multitude de fonctions pour l"analyse et la manipulation spatiale. Bien que le MPD initial n"utilise pas directement les types PostGIS pour simplifier, l"activation de l"extension (souvent incluse dans les images Docker PostgreSQL dédiées ou facilement ajoutable) ouvre la porte à des évolutions futures beaucoup plus simplement (ex: recherche de cartes par proximité, analyse de densité, etc.).
* Intégration avec l"Écosystème Python/Flask : PostgreSQL est parfaitement supporté par l"écosystème Python, notamment via l"ORM SQLAlchemy et des drivers comme psycopg2. L"intégration dans une application Flask est donc aisée.


En conclusion, PostgreSQL est un choix fiable et performant. L"ajout potentiel de PostGIS, même s"il n"est pas exploité au maximum initialement, rend ce choix particulièrement pertinent pour une application à caractère géographique comme ActivMap, offrant une base solide pour les besoins actuels et une grande capacité d"évolution future.
4. Justification Conteneurisation : Docker
L"utilisation de Docker et Docker Compose pour la conteneurisation de l"application ActivMap, clairement établie par la présence des fichiers Dockerfile, docker-compose.yml et DOCKER_GUIDE.md dans le dépôt GitHub, est un choix stratégique majeur qui apporte de nombreux avantages tout au long du cycle de vie du projet.


* Isolation des Environnements : Docker permet d"encapsuler chaque service (backend Flask, frontend Svelte, base de données PostgreSQL, cache Redis, proxy Nginx) dans son propre conteneur isolé. Chaque conteneur embarque l"application et toutes ses dépendances (bibliothèques système, runtimes spécifiques comme Python ou Node.js). Cela garantit que l"application fonctionne de manière identique quel que soit l"environnement hôte (machine du développeur, serveur de staging, serveur de production), éliminant le classique problème du "ça marche sur ma machine".
* Reproductibilité et Cohérence : Les Dockerfile décrivent de manière explicite et versionnable comment construire l"image de chaque service. Le fichier docker-compose.yml décrit comment ces services interagissent (réseau, volumes, variables d"environnement). Cela assure une configuration cohérente et reproductible de l"ensemble de l"application à travers les différents environnements et pour tous les membres de l"équipe.
* Simplification de la Configuration Développeur : Un nouveau développeur rejoignant le projet n"a besoin que d"installer Docker et Docker Compose sur sa machine. Une simple commande (docker-compose up) suffit ensuite pour lancer l"intégralité de l"application avec toutes ses dépendances, sans avoir à installer manuellement Python, Node.js, PostgreSQL, Redis, Nginx et à gérer les conflits de versions potentiels.
* Gestion des Dépendances Simplifiée : Chaque conteneur gère ses propres dépendances. Le backend peut utiliser une version spécifique de Python et de ses bibliothèques, tandis que le frontend utilise une version spécifique de Node.js, sans risque d"interférence.
* Déploiement Facilité et Standardisé : La conteneurisation simplifie grandement le processus de déploiement. Au lieu de provisionner et configurer manuellement chaque service sur le serveur de production, il suffit de déployer les images Docker et d"orchestrer leur lancement via Docker Compose (ou un orchestrateur plus avancé comme Kubernetes). Les mises à jour consistent à déployer de nouvelles versions des images.
* Scalabilité : Bien que Docker Compose soit plus adapté à un déploiement sur un seul hôte, l"architecture conteneurisée facilite la transition vers des orchestrateurs comme Docker Swarm ou Kubernetes si un besoin de scalabilité horizontale (lancer plusieurs instances d"un service) apparaît.
* Utilisation Efficace des Ressources : Les conteneurs sont plus légers que les machines virtuelles traditionnelles car ils partagent le noyau du système d"exploitation hôte. Ils démarrent plus rapidement et consomment moins de ressources (CPU, RAM, disque).
* Écosystème Mature : Docker est la plateforme de conteneurisation leader du marché, avec un écosystème très riche (Docker Hub pour les images, outils de monitoring, de sécurité, etc.) et une large communauté.


Pour ActivMap, qui est une application multi-composants (frontend, backend, BDD, cache, proxy), la conteneurisation avec Docker apporte une valeur ajoutée considérable en termes de cohérence, de reproductibilité, de simplification du développement et du déploiement. C"est un choix moderne et aligné avec les bonnes pratiques actuelles du développement logiciel.
5. Justification Serveur Web / Proxy Inverse : Nginx
L"utilisation de Nginx comme serveur web et proxy inverse, tel que défini par le service proxy dans le fichier docker-compose.yml, est un choix standard et très performant pour les applications web modernes comme ActivMap.


* Haute Performance et Faible Consommation de Ressources : Nginx est réputé pour son architecture événementielle (asynchrone et non bloquante) qui lui permet de gérer un grand nombre de connexions simultanées avec une consommation de ressources (CPU, RAM) très faible, bien inférieure à celle de serveurs plus anciens comme Apache en mode prefork. C"est idéal pour servir de point d"entrée à l"application.
* Excellent Serveur de Fichiers Statiques : Nginx est extrêmement efficace pour servir des fichiers statiques (HTML, CSS, JavaScript, images). Dans l"architecture d"ActivMap, il est configuré (dans un déploiement de production) pour servir directement les fichiers buildés du frontend Svelte, déchargeant ainsi le backend applicatif de cette tâche.
* Proxy Inverse Robuste : Sa fonction principale dans cette architecture est celle de proxy inverse. Il reçoit toutes les requêtes entrantes sur les ports 80 (HTTP) et 443 (HTTPS) et les route intelligemment vers les services backend appropriés :
   * Les requêtes d"API (ex: /api/...) sont transmises au backend Flask (tournant sur le port 5000 dans son conteneur).
   * Les autres requêtes sont dirigées vers le serveur frontend (serveur de développement Node.js sur le port 8080 en dev, ou servies statiquement par Nginx lui-même en prod). Cela permet de masquer l"architecture interne, de centraliser la gestion des accès et d"ajouter une couche de sécurité.
* Terminaison SSL/TLS : Nginx est couramment utilisé pour gérer le chiffrement HTTPS. Il peut prendre en charge les certificats SSL/TLS (comme indiqué par le montage du volume ./certs dans docker-compose.yml) et déchiffrer les requêtes avant de les transmettre aux services backend en HTTP simple sur le réseau interne Docker. Cela simplifie la configuration SSL des services applicatifs.
* Load Balancing (Répartition de Charge) : Si l"application nécessitait de lancer plusieurs instances du backend Flask pour la scalabilité, Nginx pourrait facilement être configuré pour répartir la charge entre ces instances.
* Mise en Cache : Nginx dispose de mécanismes de mise en cache performants qui pourraient être utilisés pour mettre en cache les réponses d"API fréquentes ou les fichiers statiques, réduisant ainsi la charge sur les services backend et améliorant les temps de réponse.
* Limitation de Débit et Sécurité : Nginx offre des modules pour implémenter la limitation de débit (rate limiting) au niveau du proxy, bloquer des adresses IP malveillantes, ou ajouter des en-têtes de sécurité HTTP.
* Configuration Flexible : La configuration de Nginx, bien que parfois verbeuse, est très puissante et permet de définir des règles de routage, de réécriture d"URL et de gestion des requêtes très fines.
* Maturité et Communauté : Comme PostgreSQL et Docker, Nginx est une technologie open-source extrêmement mature, stable, largement documentée et soutenue par une vaste communauté.


Pour ActivMap, Nginx remplit parfaitement son rôle de point d"entrée unique, sécurisé et performant, assurant le routage des requêtes, la gestion HTTPS et le service efficace des fichiers statiques du frontend. C"est un composant essentiel et bien choisi pour cette architecture.
6. Autres Librairies et Outils Pertinents
Au-delà des choix majeurs pour le backend, le frontend, la base de données et l"infrastructure, plusieurs autres librairies et outils jouent un rôle important dans le développement, la qualité et la maintenabilité d"ActivMap.
Backend (Python/Flask)
* SQLAlchemy : ORM (Object-Relational Mapper) incontournable pour interagir avec PostgreSQL de manière orientée objet, simplifiant les requêtes et la manipulation des données.
* Flask-Migrate (basé sur Alembic) : Outil essentiel pour gérer les migrations de schéma de base de données. Il permet de versionner les modifications du modèle de données et de les appliquer de manière contrôlée aux différents environnements (développement, staging, production).
* Gunicorn / uWSGI : Serveurs WSGI (Web Server Gateway Interface) robustes et performants, nécessaires pour exécuter l"application Flask en production (contrairement au serveur de développement intégré à Flask).
* Requests : Librairie standard de facto pour effectuer des requêtes HTTP en Python, utilisée ici pour interroger l"API Overpass.
* Flask-Bcrypt / Werkzeug Security Helpers : Pour le hachage sécurisé des mots de passe.
* Flask-JWT-Extended / itsdangerous : Pour la gestion des tokens d"authentification JWT ou des tokens sécurisés en général.
* Flask-Limiter : Pour implémenter la limitation de débit sur les endpoints de l"API, souvent en conjonction avec Redis.
* Pillow : Librairie de manipulation d"images, potentiellement utilisée pour la génération ou le post-traitement des exports PNG.
* svgwrite / xml.etree.ElementTree : Pour la génération programmatique des fichiers SVG.
* Celery (Optionnel) : Framework de file d"attente de tâches distribuées. Pourrait être ajouté si la génération de cartes s"avère trop longue pour être traitée de manière synchrone, utilisant Redis ou RabbitMQ comme broker de messages.
* Pytest : Framework de test populaire pour écrire et exécuter les tests unitaires et d"intégration du backend.
* Flake8 / Black / isort : Outils de linting et de formatage du code pour garantir la qualité et la cohérence du code Python.
Frontend (Svelte)
* SvelteKit (Optionnel mais recommandé) : Framework applicatif officiel pour Svelte, fournissant le routage, le SSR, la gestion des layouts, etc. Même pour une SPA, il structure le projet.
* Vite : Outil de build frontend extrêmement rapide utilisé par défaut avec SvelteKit, offrant un serveur de développement performant avec HMR (Hot Module Replacement).
* Leaflet / MapLibre GL JS : Librairies JavaScript de cartographie interactive pour afficher la prévisualisation de la carte dans le navigateur.
* Axios / Fetch API : Pour effectuer les requêtes HTTP vers l"API backend.
* TypeScript (Optionnel) : Peut être utilisé avec Svelte pour ajouter un typage statique au code frontend, améliorant la robustesse et la maintenabilité pour les projets plus importants.
* Vitest / Playwright / Cypress : Frameworks pour les tests unitaires, d"intégration et end-to-end du frontend.
* ESLint / Prettier : Outils de linting et de formatage pour le code JavaScript/TypeScript et Svelte.
Outils Généraux et Infrastructure
* Git : Système de contrôle de version distribué, essentiel pour le suivi des modifications du code source et la collaboration (utilisé via GitHub dans ce projet).
* Docker / Docker Compose : Outils de conteneurisation et d"orchestration locale, comme justifié précédemment.
* Nginx : Serveur web et proxy inverse, comme justifié précédemment.
* Redis : Base de données clé-valeur en mémoire, utilisée pour le cache (sessions, données API) et potentiellement comme broker pour Celery.
* Overpass API : API externe permettant d"interroger la base de données OpenStreetMap.
* Let"s Encrypt / Certbot : Pour obtenir et renouveler automatiquement les certificats SSL/TLS gratuits nécessaires à HTTPS en production.
* Outils CI/CD (GitHub Actions, etc.) : Pour automatiser les tests, le build et le déploiement.


Le choix judicieux et l"intégration de ces différentes librairies et outils contribuent à construire une application ActivMap fonctionnelle, performante, sécurisée et maintenable.
Développement / Implémentation
Cette section détaille le processus de développement et d"implémentation de l"application ActivMap, en mettant en lumière les compétences mises en œuvre conformément au référentiel RNCP Concepteur Développeur d"Applications. Elle couvre les activités types AT1 (Développer une application sécurisée) et AT2 (Concevoir et développer une application multicouche).
AT1 : Développer une application sécurisée
Le développement d"ActivMap a été mené avec une attention constante portée à la sécurité, dès les premières étapes de configuration de l"environnement jusqu"à l"implémentation des fonctionnalités et au déploiement.
CP1 : Installer et configurer son environnement de travail en fonction du projet
La mise en place d"un environnement de développement stable, reproductible et isolé est la première étape cruciale pour garantir un développement efficace et sécurisé. Pour ActivMap, cela a été réalisé grâce à l"adoption de Docker et Docker Compose.


Utilisation de Docker et Docker Compose :


* Isolation : Comme détaillé dans la section sur les choix technologiques, Docker permet d"isoler chaque service (backend, frontend, base de données, cache, proxy) dans son propre conteneur. Cela évite les conflits de dépendances entre les services ou avec le système d"exploitation de l"hôte et assure que l"environnement de développement reflète fidèlement l"environnement de production.
* Reproductibilité : Le fichier docker-compose.yml décrit l"ensemble des services, leurs images de base, les ports exposés, les volumes pour le code source et les données persistantes, les variables d"environnement et les dépendances entre services. Associé aux Dockerfile (un pour le backend, un pour le frontend), il permet à tout développeur de recréer l"environnement complet avec une seule commande (docker-compose up). Cette reproductibilité est essentielle pour la collaboration et pour éviter les erreurs liées à des configurations d"environnement différentes.
* Configuration Centralisée : Le docker-compose.yml centralise la configuration de base de l"environnement de développement. Il définit comment les services communiquent entre eux via le réseau Docker interne, comment le code source local est monté dans les conteneurs pour permettre le développement itératif (avec rechargement à chaud pour Flask et Svelte), et comment les données persistantes (base de données, cache) sont gérées via des volumes nommés.


Gestion des Dépendances :


* Backend (Python/Flask) : Les dépendances Python sont définies dans un fichier requirements.txt (ou un fichier similaire comme Pipfile ou pyproject.toml). Le Dockerfile du backend utilise pip install -r requirements.txt pour installer ces dépendances à l"intérieur de l"image Docker. Cela garantit que tous les environnements (développement, CI, production) utilisent exactement les mêmes versions des bibliothèques Python, réduisant les risques d"incompatibilité ou de failles de sécurité liées à des versions obsolètes.
* Frontend (Node.js/Svelte) : Les dépendances JavaScript sont gérées via le fichier package.json et le gestionnaire de paquets npm (ou yarn). Le Dockerfile du frontend (ou la configuration du service dans docker-compose.yml pour l"environnement de développement) utilise npm install pour installer les dépendances définies dans package.json et package-lock.json (qui fixe les versions exactes). Là encore, cela assure la cohérence des dépendances frontend à travers les environnements.


Configuration Spécifique au Projet :


* Variables d"Environnement : Les configurations spécifiques qui varient entre les environnements (ex: clés d"API, URL de base de données, clés secrètes, mode debug) sont gérées via des variables d"environnement. Le fichier docker-compose.yml permet de les injecter dans les conteneurs, souvent en référençant un fichier .env local (qui doit être exclu du contrôle de version via .gitignore pour des raisons de sécurité).
* Volumes : Des volumes sont utilisés pour monter le code source local dans les conteneurs (./:/app pour le backend, ./frontend/svelte-app:/app pour le frontend), permettant aux modifications faites localement d"être immédiatement reflétées dans l"application en cours d"exécution dans Docker, facilitant ainsi le développement itératif. Des volumes nommés (postgres_data, redis_data) sont utilisés pour la persistance des données de la base de données et du cache.


En résumé, l"environnement de travail pour ActivMap a été soigneusement configuré en utilisant Docker et Docker Compose pour assurer l"isolation, la reproductibilité et la cohérence. La gestion rigoureuse des dépendances via requirements.txt et package.json et l"utilisation de variables d"environnement pour la configuration contribuent à un processus de développement plus fiable et sécurisé, en minimisant les risques liés à l"environnement lui-même.
CP2 : Réaliser des interfaces utilisateur statiques et dynamiques, sécurisées et respectant les principes d"accessibilité
Le développement de l"interface utilisateur (UI) d"ActivMap avec Svelte a été centré sur la création d"une expérience utilisateur fluide, intuitive et accessible, tout en assurant une communication sécurisée avec le backend. Cette compétence couvre la réalisation des maquettes statiques (structure HTML/CSS) et leur dynamisation via Svelte, l"intégration avec l"API backend, et la prise en compte des normes d"accessibilité (RGAA).


Développement Basé sur les Composants (Svelte) :


* Modularité : L"interface a été décomposée en composants Svelte réutilisables (.svelte files). Par exemple : un composant GenerationForm pour le formulaire de saisie des coordonnées et du rayon, un composant MapPreview pour afficher la carte générée, un composant StyleSelector pour le choix du style, un composant HistoryList pour afficher l"historique, etc. Cette approche modulaire facilite le développement, les tests et la maintenance.
* Structure des Composants : Chaque composant Svelte encapsule sa structure HTML (<template>), son style CSS (<style>) et sa logique JavaScript (<script>). Le CSS est "scopé" par défaut, évitant les conflits de style entre composants.
* Props et Events : Les composants communiquent entre eux via des "props" (propriétés passées d"un parent à un enfant) et des "events" (événements émis par un enfant vers un parent). Par exemple, GenerationForm émet un événement generate avec les paramètres lorsque l"utilisateur clique sur le bouton, et le composant parent écoute cet événement pour déclencher l"appel API.


Réalisation des Interfaces Statiques et Dynamiques :


* Structure HTML Sémantique : La structure HTML de base de chaque composant a été écrite en utilisant des balises sémantiques (ex: <nav>, <main>, <aside>, <form>, <button>, <input>) pour améliorer l"accessibilité et le référencement (bien que moins critique pour une application interne).
* Stylisation CSS : Le style a été appliqué via CSS, soit directement dans les balises <style> des composants, soit en utilisant une approche plus globale comme Tailwind CSS ou une librairie de composants UI (ex: Bootstrap, Carbon Components for Svelte) pour assurer la cohérence visuelle et accélérer le développement. Le choix d"une librairie de composants pré-stylés aide également à garantir une base d"accessibilité.
* Réactivité Svelte : La dynamisation de l"interface repose sur la réactivité native de Svelte. Les variables déclarées dans le bloc <script> sont réactives par défaut. Lorsque leur valeur change (ex: suite à une saisie utilisateur ou à la réception de données de l"API), Svelte met à jour automatiquement et efficacement le DOM. Des directives Svelte comme bind:value sont utilisées pour lier les valeurs des champs de formulaire aux variables JavaScript, et des blocs logiques ({#if}, {#each}) permettent d"afficher conditionnellement des éléments ou d"itérer sur des listes (ex: pour afficher l"historique).
* Gestion de l"État : Pour l"état partagé entre plusieurs composants (ex: informations de l"utilisateur connecté, style sélectionné globalement), les "stores" Svelte (writable, readable, derived) ont été utilisés. Ils fournissent un moyen simple et efficace de gérer l"état global de l"application de manière réactive.


Intégration avec l"API Backend :


* Appels Asynchrones : La communication avec l"API Flask se fait via des requêtes HTTP asynchrones, typiquement en utilisant l"API fetch native du navigateur ou une librairie comme axios. Ces appels sont effectués dans la logique JavaScript des composants (ex: lors de la soumission d"un formulaire, au montage du composant pour récupérer des données initiales).
* Gestion des États de Chargement et d"Erreur : Les interfaces prennent en compte les états intermédiaires des appels API. Des indicateurs de chargement (spinners, messages) sont affichés pendant l"attente de la réponse, et des messages d"erreur clairs sont présentés à l"utilisateur en cas d"échec de la requête.
* Sécurité (Tokens/Cookies) : Le frontend gère le stockage sécurisé et l"envoi systématique du token d"authentification (JWT) ou du cookie de session avec chaque requête vers les endpoints protégés de l"API.


Respect des Principes d"Accessibilité (RGAA) :


L"accessibilité a été une préoccupation lors du développement de l"UI, visant une conformité au moins partielle avec le Référentiel Général d"Amélioration de l"Accessibilité (RGAA).


* Structure Sémantique : Utilisation correcte des balises HTML pour donner du sens au contenu.
* Navigation Clavier : Assurer que tous les éléments interactifs (liens, boutons, champs de formulaire) sont accessibles et utilisables via le clavier seul, avec un ordre de tabulation logique et un indicateur de focus visible.
* Contrastes : Choix de combinaisons de couleurs pour le texte et l"arrière-plan offrant un contraste suffisant (conformément aux ratios WCAG/RGAA), notamment pour le style "RGAA" prédéfini.
* Alternatives Textuelles : Fournir des alternatives textuelles pertinentes pour les images non décoratives (attribut alt).
* Libellés Explicites : Associer explicitement des libellés (<label>) aux champs de formulaire (<input>, <select>, <textarea>) via l"attribut for.
* ARIA (Accessible Rich Internet Applications) : Utilisation prudente des attributs ARIA si nécessaire pour améliorer l"accessibilité des composants dynamiques ou personnalisés, en complément d"une structure HTML sémantique.
* Tests d"Accessibilité : Utilisation d"outils automatiques (ex: extensions de navigateur comme Axe DevTools, Lighthouse) et de tests manuels (navigation clavier, lecteurs d"écran basiques) pour identifier et corriger les problèmes d"accessibilité courants.


En intégrant ces pratiques, le développement des interfaces utilisateur d"ActivMap avec Svelte a permis de créer une application non seulement fonctionnelle et réactive, mais aussi plus accessible et sécurisée pour tous les utilisateurs.
CP3 : Développer des composants métier et des composants d"accès aux données organisés en couches
Le développement du backend Flask d"ActivMap implique la création de composants métier responsables de l"implémentation de la logique applicative et de composants d"accès aux données pour interagir avec la base de données PostgreSQL. L"organisation en couches est essentielle pour assurer la maintenabilité, la testabilité et l"évolutivité de l"application.


Organisation en Couches (Conceptuelle) :


Bien qu"un micro-framework comme Flask n"impose pas une structure stricte, une organisation logique en couches est suivie :


1. Couche Présentation/API (Routes Flask) : Définit les endpoints de l"API RESTful (@app.route ou via Flask-RESTful/Blueprints). Elle est responsable de :
   * Recevoir les requêtes HTTP.
   * Valider les données entrantes (souvent délégué à des schémas Marshmallow/Pydantic).
   * Gérer l"authentification et l"autorisation (via décorateurs ou middleware).
   * Orchestrer l"appel aux services métier appropriés.
   * Formater les réponses HTTP (JSON) et gérer les codes de statut.
2. Couche Métier/Service : Contient la logique applicative principale. Elle est indépendante du protocole HTTP et de la manière dont les données sont stockées. Elle est responsable de :
   * Implémenter les cas d"utilisation définis par les User Stories (ex: generer_carte, creer_utilisateur, exporter_svg).
   * Coordonner les interactions avec la couche d"accès aux données.
   * Effectuer des calculs ou des transformations de données.
   * Interagir avec des services externes (ex: API Overpass).
   * Cette couche peut être implémentée sous forme de fonctions, de classes de service, etc.
3. Couche d"Accès aux Données (DAL - Data Access Layer) : Responsable de toutes les interactions avec la base de données. Elle abstrait les détails de l"implémentation de la base de données du reste de l"application. Elle est responsable de :
   * Exécuter les requêtes CRUD (Create, Read, Update, Delete) sur la base de données.
   * Utiliser l"ORM (SQLAlchemy) pour mapper les objets Python aux tables de la base de données.
   * Gérer les sessions et les transactions de base de données.
   * Cette couche est souvent matérialisée par les modèles SQLAlchemy eux-mêmes et potentiellement par des classes "Repository" qui encapsulent les requêtes spécifiques.


Développement des Composants Métier (Exemples) :


* Logique de Génération de Cartes :
   * Un service ou un ensemble de fonctions (map_generator_service.py) prend en entrée les paramètres (lat, lon, rayon, style_id).
   * Il appelle une fonction de la couche d"accès aux données pour récupérer les détails du style.
   * Il interroge l"API Overpass (via un module client dédié overpass_client.py).
   * Il traite les données GeoJSON reçues.
   * Il utilise une librairie (ex: svg_renderer.py) pour appliquer le style et générer le SVG.
   * Il appelle une fonction de la couche d"accès aux données pour sauvegarder les métadonnées de la génération.
   * Il retourne le résultat (SVG ou chemin/URL) à la couche API.
* Gestion des Utilisateurs :
   * Un service user_service.py expose des fonctions comme create_user, get_user_by_email, update_password.
   * create_user prend les données utilisateur, hache le mot de passe (via un module security.py), et appelle la couche d"accès aux données pour insérer le nouvel utilisateur.
   * get_user_by_email appelle la couche d"accès aux données pour récupérer un utilisateur.
* Gestion des Styles :
   * Un service style_service.py gère la création, la récupération, la mise à jour et la suppression des styles visuels, en interagissant avec la couche d"accès aux données.


Développement des Composants d"Accès aux Données (Exemples avec SQLAlchemy) :


* Modèles SQLAlchemy (models.py) : Définition des classes Python (User, Generation, Style, etc.) qui héritent de db.Model (si utilisation de Flask-SQLAlchemy) et correspondent aux tables de la base de données définies dans le MLD/MPD. Ces classes contiennent les définitions des colonnes et des relations.
* Opérations CRUD :
   * Création : new_user = User(...), db.session.add(new_user), db.session.commit()
   * Lecture : user = User.query.filter_by(email=email).first(), styles = Style.query.filter_by(est_predefini=True).all()
   * Mise à jour : user = User.query.get(user_id), user.nom_utilisateur = new_name, db.session.commit()
   * Suppression : user = User.query.get(user_id), db.session.delete(user), db.session.commit()
* Gestion des Sessions : Flask-SQLAlchemy gère généralement la portée de la session de base de données par requête.
* Requêtes Complexes : Pour des requêtes plus complexes impliquant des jointures, des agrégations ou des fonctions spécifiques à PostgreSQL/PostGIS, SQLAlchemy offre une API flexible pour construire ces requêtes.
* Référentiel (Repository Pattern - Optionnel) : Pour des applications plus complexes, le pattern Repository peut être utilisé pour encapsuler davantage la logique d"accès aux données. Une classe UserRepository pourrait exposer des méthodes comme find_by_email(email) ou get_active_users(), cachant les détails de l"implémentation SQLAlchemy.


En structurant le backend de cette manière, le développement des composants métier et d"accès aux données est organisé, découplé et plus facile à tester. Chaque couche a une responsabilité claire, ce qui améliore la maintenabilité et permet de faire évoluer l"application plus sereinement.
CP4 : Contribuer à la gestion d"un projet informatique
Bien que le développement d"ActivMap ait été mené principalement par un seul développeur (dans le cadre de ce projet de certification), la contribution à la gestion de projet reste une compétence essentielle, appliquée même dans ce contexte individuel à travers la planification, le suivi et l"utilisation d"outils adaptés.


Planification et Suivi :


* Découpage Initial : Le projet a débuté par une phase d"analyse des besoins (basée sur la demande initiale de FeelObject et les exigences du titre RNCP) et une définition du périmètre fonctionnel (MVP, Phase 2, etc.), matérialisée dans le cahier des charges et les User Stories. Ce découpage initial a permis d"établir une feuille de route globale.
* Priorisation : Les fonctionnalités (User Stories) ont été priorisées (Haute, Moyenne, Basse) pour se concentrer sur le Minimum Viable Product (MVP) tout en gardant une vision des évolutions futures. La complexité a également été estimée pour anticiper l"effort de développement.
* Suivi de l"Avancement : Bien qu"il n"y ait pas eu d"outil de gestion de projet formel type Jira ou Trello (ce qui serait typique en équipe), le suivi de l"avancement a pu être réalisé via :
   * Gestion des Tâches Personnelle : Utilisation d"une liste de tâches (to-do list) ou d"un outil simple pour suivre les fonctionnalités à développer, les bugs à corriger et les étapes de rédaction du dossier.
   * Versionnement Git : Le dépôt GitHub sert non seulement à stocker le code, mais aussi à tracer l"historique des développements. Les messages de commit, s"ils sont clairs et descriptifs, permettent de suivre les modifications apportées et les fonctionnalités implémentées.
   * Branches Git : L"utilisation de branches (comme la branche détails mentionnée) permet d"isoler le développement de nouvelles fonctionnalités ou de refactorisations importantes avant de les intégrer à la branche principale, contribuant à la stabilité du code.


Méthodologie :


* Approche Itérative/Incrémentale : Le développement semble avoir suivi une approche itérative, en commençant par les fonctionnalités clés du MVP (génération simple, export, authentification de base) et en prévoyant des améliorations ou des fonctionnalités supplémentaires pour des phases ultérieures (import GeoJSON, gestion des styles d"équipe, etc.). Cette approche permet d"obtenir rapidement un produit fonctionnel et de l"améliorer progressivement.
* Inspiration Agile : Bien qu"une méthodologie Agile complète (Scrum, Kanban) soit difficile à appliquer seul, certains principes ont pu être adoptés : focus sur la livraison de valeur (fonctionnalités utiles), adaptation aux changements (ajustements suite à des difficultés techniques ou à une meilleure compréhension des besoins), et développement itératif.


Outils de Collaboration et de Gestion de Code :


* Git et GitHub : L"utilisation de Git pour le versionnement et de GitHub comme plateforme d"hébergement est fondamentale. GitHub facilite :
   * Le stockage centralisé et sécurisé du code.
   * Le suivi des modifications (historique des commits).
   * La gestion des branches pour le développement parallèle ou l"isolation des fonctionnalités.
   * La documentation du projet (via le README.md et potentiellement le Wiki GitHub).
   * (En équipe) La revue de code via les Pull Requests, la gestion des Issues pour le suivi des bugs et des demandes de fonctionnalités.
* Communication : Dans un contexte individuel, la communication est moins formelle, mais la clarté des messages de commit, la documentation du code (commentaires, docstrings) et la structuration du projet restent importantes pour la maintenabilité future.


Documentation :


* README.md : Le fichier README.md à la racine du projet GitHub est essentiel pour présenter le projet, expliquer son objectif, et fournir les instructions d"installation et d"utilisation (notamment pour l"environnement Docker).
* DOCKER_GUIDE.md : La présence de ce fichier spécifique montre une volonté de documenter le processus de mise en place de l"environnement Docker, ce qui est une bonne pratique de gestion de projet.
* Commentaires et Docstrings : Une documentation adéquate au sein du code (commentaires expliquant les parties complexes, docstrings pour les fonctions et classes Python) est cruciale pour la compréhension et la maintenance.
* Dossier RNCP : La rédaction de ce dossier lui-même est une forme de contribution à la gestion de projet, car elle nécessite de structurer, documenter et justifier les choix techniques et fonctionnels.


Même en travaillant seul, l"application de principes de planification, de suivi, l"utilisation d"outils comme Git/GitHub et Docker, et la production d"une documentation claire démontrent une contribution active à la gestion du projet informatique ActivMap, assurant une meilleure organisation et facilitant sa compréhension et sa potentielle reprise par d"autres.
AT2 : Concevoir et développer une application sécurisée organisée en couches
Cette activité type se concentre sur la capacité à structurer l"application en couches distinctes (présentation, métier, accès aux données) pour améliorer la modularité, la maintenabilité et la sécurité. Les compétences CP5, CP6, et CP7 (Conception) ont déjà été abordées dans les sections précédentes (User Stories, Maquettes, Modèles de données, Architecture). Nous allons ici nous focaliser sur la compétence CP8, qui concerne spécifiquement l"implémentation de la couche d"accès aux données dans cette architecture multicouche.
CP8 : Développer des composants d"accès aux données
Le développement des composants d"accès aux données pour ActivMap consiste à créer la couche logicielle qui interagit directement avec la base de données PostgreSQL, en utilisant principalement l"ORM SQLAlchemy. Cette couche abstrait les opérations de base de données du reste de l"application (couche métier et API), garantissant un découplage et une meilleure organisation du code.


Utilisation de SQLAlchemy comme ORM :


* Mapping Objet-Relationnel : SQLAlchemy permet de définir des classes Python (les modèles, ex: User, Generation, Style) qui correspondent directement aux tables de la base de données. Les attributs de ces classes représentent les colonnes des tables. Cela permet aux développeurs de manipuler les données de la base sous forme d"objets Python, ce qui est plus intuitif et moins sujet aux erreurs que l"écriture de requêtes SQL brutes.
* Définition des Modèles (models.py) : Un fichier central (ou un module) models.py contient la définition de toutes les classes de modèles SQLAlchemy, héritant généralement d"une classe de base fournie par Flask-SQLAlchemy (db.Model). Ces définitions incluent les types de colonnes (db.Column(db.Integer, primary_key=True), db.Column(db.String(100), nullable=False), etc.) et les relations entre les modèles (db.relationship, db.ForeignKey).


# Exemple simplifié dans models.py


from app import db # Supposant une initialisation Flask-SQLAlchemy


class Role(db.Model):


    __tablename__ = \"roles\"


    role_id = db.Column(db.Integer, primary_key=True)


    nom_role = db.Column(db.String(50), unique=True, nullable=False)


    utilisateurs = db.relationship(\"User\", backref=\"role\", lazy=True)


class User(db.Model):


    __tablename__ = \"utilisateurs\"


    utilisateur_id = db.Column(db.Integer, primary_key=True)


    nom_utilisateur = db.Column(db.String(100), nullable=False)


    email = db.Column(db.String(255), unique=True, nullable=False)


    mot_de_passe_hash = db.Column(db.String(255), nullable=False)


    role_id = db.Column(db.Integer, db.ForeignKey(\"roles.role_id\"), nullable=False)


    generations = db.relationship(\"Generation\", backref=\"auteur\", lazy=True)


    # ... autres colonnes et relations


* Gestion des Sessions : SQLAlchemy fonctionne avec un concept de "Session", qui agit comme une unité de travail pour interagir avec la base de données. Flask-SQLAlchemy simplifie cela en gérant automatiquement la portée de la session, la liant généralement au contexte de la requête HTTP. Les opérations (ajout, modification, suppression d"objets) sont enregistrées dans la session, puis persistées en base de données lors d"un db.session.commit().


Implémentation des Opérations CRUD :


Les composants d"accès aux données implémentent les opérations fondamentales de création, lecture, mise à jour et suppression pour chaque modèle.


* Création (Create) : Instanciation d"un nouvel objet modèle, ajout à la session (db.session.add()), et commit (db.session.commit()).
* Lecture (Read) : Utilisation de l"API de requêtes de SQLAlchemy (Model.query) pour récupérer des objets. Cela inclut :
   * Récupération par clé primaire : User.query.get(user_id)
   * Filtrage : User.query.filter_by(email=email).first(), Generation.query.filter(Generation.date_creation > date_limite).all()
   * Tri : Generation.query.order_by(Generation.date_creation.desc()).limit(10).all()
   * Jointures (implicites via les relations ou explicites via join()) : db.session.query(User, Role).join(Role).filter(Role.nom_role == \"EMPLOYE\").all()
* Mise à jour (Update) : Récupération d"un objet existant, modification de ses attributs, et commit (db.session.commit()). SQLAlchemy détecte les modifications et génère la requête UPDATE appropriée.
* Suppression (Delete) : Récupération d"un objet existant, suppression de la session (db.session.delete()), et commit (db.session.commit()). Les contraintes de clé étrangère (ex: ON DELETE CASCADE) définies au niveau de la base de données sont respectées.


Abstraction de l"Accès aux Données :


Pour renforcer l"organisation en couches, la logique d"accès aux données peut être encapsulée :


* Dans les Services Métier (Simple) : Pour des applications plus simples, la couche métier peut directement utiliser les modèles SQLAlchemy et la session db.session pour effectuer les opérations CRUD.
* Via le Pattern Repository (Plus Structuré) : Création de classes Repository (ex: UserRepository, GenerationRepository) qui exposent des méthodes spécifiques au domaine (ex: UserRepository.find_by_email(email), GenerationRepository.get_recent_by_user(user_id, limit=10)). Ces méthodes contiennent la logique de requête SQLAlchemy, cachant ainsi complètement l"ORM de la couche métier. Cela améliore la testabilité (on peut mocker les repositories) et facilite le changement potentiel d"ORM ou de source de données à l"avenir.


Interactions Spécifiques (PostGIS - si utilisé) :


Si des fonctionnalités PostGIS étaient implémentées (ex: stockage de géométries, requêtes spatiales), la couche d"accès aux données utiliserait les extensions fournies par GeoAlchemy 2. Cela permettrait de manipuler les types de données géométriques et d"utiliser les fonctions spatiales directement via l"API SQLAlchemy (ex: func.ST_Distance(), func.ST_Intersects()).


Sécurité et Performance :


* Prévention des Injections SQL : L"utilisation de l"ORM SQLAlchemy prévient nativement les injections SQL car les valeurs sont traitées comme des paramètres et non concaténées directement dans les chaînes de requêtes.
* Gestion des Connexions : SQLAlchemy gère un pool de connexions à la base de données pour réutiliser les connexions et améliorer les performances.
* Optimisation des Requêtes : L"utilisation appropriée des options de chargement de SQLAlchemy (lazy=\"joined\", lazy=\"subquery\", options(joinedload(...))) est importante pour éviter le problème N+1 et optimiser les performances lors de l"accès aux données liées.


En développant des composants d"accès aux données clairs, bien définis et découplés du reste de l"application à l"aide de SQLAlchemy, ActivMap bénéficie d"une base solide pour la persistance et la manipulation de ses données, conformément aux principes d"une architecture en couches.
Description détaillée des fonctionnalités clés
Cette section décrit plus en détail l"implémentation de certaines fonctionnalités clés d"ActivMap, en reliant les concepts de conception et d"architecture aux aspects pratiques du développement.


1. Génération de Cartes Stylisées :


C"est la fonctionnalité centrale d"ActivMap. Son implémentation implique plusieurs étapes coordonnées principalement par le backend Flask :


* Interface Utilisateur (Frontend Svelte) : Le composant GenerationForm permet à l"utilisateur de saisir la latitude, la longitude et le rayon. Des validations côté client (format des nombres, plage du rayon) sont effectuées pour un retour immédiat. Le composant StyleSelector permet de choisir un style parmi ceux récupérés depuis l"API. Lors du clic sur "Générer", les données sont envoyées à l"endpoint /api/generations.
* Réception et Validation (Backend Flask) : L"endpoint Flask reçoit les paramètres, valide leur type et leur cohérence (ex: coordonnées valides, rayon dans les limites autorisées). Il vérifie l"authentification de l"utilisateur.
* Récupération des Données OSM (Backend Flask) : Le backend construit une requête pour l"API Overpass basée sur les coordonnées et le rayon. La bibliothèque requests est utilisée pour envoyer cette requête à l"URL configurée de l"API Overpass. La réponse (généralement GeoJSON) est récupérée.
* Traitement des Données et Style (Backend Flask) : Les données GeoJSON sont potentiellement nettoyées ou simplifiées. Les paramètres du style sélectionné sont récupérés depuis la base de données (via SQLAlchemy). Une logique spécifique (dans un module dédié) parcourt les données OSM et, en fonction des paramètres de style (couleurs, épaisseurs pour les routes, bâtiments, etc.), génère une représentation intermédiaire ou directement le fichier final.
* Génération SVG/PNG (Backend Flask) :
   * SVG : Utilisation de svgwrite ou de la manipulation XML pour créer un fichier SVG structuré, où chaque élément géographique OSM est traduit en élément SVG (<path>, <circle>, etc.) avec les attributs de style appropriés.
   * PNG : Si l"export PNG est demandé, le SVG généré peut être converti en PNG à la résolution souhaitée en utilisant une librairie comme CairoSVG ou une approche basée sur un navigateur headless (plus complexe).
* Persistance et Réponse (Backend Flask) : Les métadonnées de la génération (ID, utilisateur, paramètres, date) sont sauvegardées en base de données via SQLAlchemy. Le backend renvoie ensuite une réponse au frontend, contenant soit le SVG généré directement (pour la prévisualisation), soit des informations sur la génération (ID) et potentiellement un lien vers le fichier si stocké séparément.
* Prévisualisation (Frontend Svelte) : Le composant MapPreview reçoit le SVG (ou charge l"image via un lien) et l"affiche. Des librairies comme panzoom pourraient être utilisées pour ajouter des fonctionnalités de zoom et de déplacement sur le SVG affiché.
* Export (Frontend/Backend) : Le clic sur "Exporter" déclenche une requête vers un endpoint spécifique (ex: /api/generations/{id}/export?format=svg). Le backend localise/régénère le fichier demandé et le renvoie avec les en-têtes Content-Disposition: attachment pour lancer le téléchargement.


2. Interface Utilisateur (UI/UX) :


L"objectif est une interface claire, réactive et accessible.


* Composants Svelte : L"UI est construite avec des composants Svelte modulaires et réactifs.
* Réactivité : Les changements d"état (saisie utilisateur, sélection de style, réception de données) entraînent des mises à jour automatiques et fluides de l"interface grâce à Svelte.
* Feedback Utilisateur : Des indicateurs visuels (états de chargement, messages de succès/erreur clairs et non intrusifs) sont utilisés pour informer l"utilisateur de ce qui se passe.
* Accessibilité (RGAA) : Implémentation des bonnes pratiques : HTML sémantique, navigation clavier, contrastes suffisants (notamment via un style dédié), libellés de formulaire corrects, focus visible. Des tests réguliers (automatiques et manuels) sont nécessaires pour valider la conformité.
* Cohérence Visuelle : Utilisation potentielle d"une librairie de composants UI ou d"un système de design tokens pour assurer une apparence cohérente à travers l"application.


3. Gestion des Utilisateurs et des Rôles :


La sécurité repose sur une gestion rigoureuse des accès.


* Authentification (Backend Flask) :
   * Endpoint /api/auth/login recevant email/mot de passe.
   * Récupération de l"utilisateur via SQLAlchemy (User.query.filter_by(email=...)).
   * Vérification du mot de passe haché avec `bcrypt.check_password_hash()$.
   * Si succès, génération d"un token JWT signé (avec Flask-JWT-Extended) contenant l"ID utilisateur et son rôle, et renvoi au client.
* Protection des Endpoints (Backend Flask) : Utilisation du décorateur @jwt_required de Flask-JWT-Extended sur tous les endpoints nécessitant une authentification. Des décorateurs personnalisés (@role_required(...)) peuvent être ajoutés pour vérifier le rôle extrait du token JWT.
* Gestion des Utilisateurs (ADMIN - Backend/Frontend) :
   * Endpoints API dédiés (ex: /api/admin/users) protégés par @role_required(\"ADMIN\") pour lister, créer, modifier (rôle, statut actif/inactif), supprimer des utilisateurs.
   * Interface frontend correspondante (dans une section Administration) permettant à l"ADMIN d"effectuer ces actions via des formulaires et des tableaux.
   * La création d"utilisateur implique le hachage du mot de passe initial avant sauvegarde.
* Gestion du Profil (Utilisateur connecté - Backend/Frontend) :
   * Endpoint API (ex: /api/profile/password) permettant à l"utilisateur authentifié de changer son propre mot de passe (nécessite l"ancien mot de passe pour vérification).
   * Interface frontend correspondante.


4. Historique des Générations :


Permet aux utilisateurs de retrouver leurs travaux.


* Interface Utilisateur (Frontend Svelte) : Une page "Historique" effectue un appel GET à /api/generations (ou un endpoint similaire avec filtres potentiels).
* Récupération des Données (Backend Flask) : L"endpoint récupère l"ID de l"utilisateur depuis le token JWT. Il utilise SQLAlchemy pour requêter la table generations_cartes, en filtrant par utilisateur_id et en triant par date (order_by(Generation.date_creation.desc())). La pagination est implémentée si nécessaire.
* Affichage (Frontend Svelte) : Les données reçues (liste des générations avec leurs métadonnées) sont affichées dans un tableau ou une grille ({#each generations as gen}). Chaque élément peut inclure une miniature (si générée/stockée) et un bouton "Recharger les paramètres".
* Rechargement des Paramètres (Frontend) : Le clic sur le bouton remplit les champs du formulaire de génération (GenerationForm) avec les paramètres (lat, lon, rayon, style_id) de la génération sélectionnée, permettant à l"utilisateur de relancer une génération similaire.


5. Sécurité (Mise en œuvre) :


La sécurité est intégrée à plusieurs niveaux :


* HTTPS : Géré par Nginx en production, assurant le chiffrement des communications.
* Authentification : Via JWT avec hachage sécurisé des mots de passe (bcrypt).
* Autorisation : Vérification systématique des rôles via décorateurs Flask pour l"accès aux endpoints sensibles (administration, gestion d"équipe).
* Validation des Entrées : Validation systématique côté backend (Flask) de toutes les données provenant du client pour prévenir les injections et les erreurs.
* Protection CSRF : Si utilisation de cookies de session, mise en place de tokens CSRF (via Flask-WTF par exemple).
* En-têtes de Sécurité HTTP : Configuration de Nginx ou Flask pour ajouter des en-têtes comme Content-Security-Policy, X-Content-Type-Options, Strict-Transport-Security.
* Gestion des Secrets : Utilisation de variables d"environnement pour les clés secrètes, non commitées dans le code source.
* Dépendances à Jour : Surveillance et mise à jour régulière des dépendances (Python et Node.js) pour corriger les failles connues.


Cette description détaillée montre comment les différentes briques technologiques et architecturales sont assemblées pour réaliser les fonctionnalités clés d"ActivMap de manière fonctionnelle, organisée et sécurisée.
Tests
La mise en place d"une stratégie de tests robuste est indispensable pour garantir la qualité, la fiabilité et la non-régression de l"application ActivMap au fur et à mesure de son développement et de ses évolutions. Cette section décrit l"approche de test envisagée, couvrant différents niveaux et types de tests, conformément à l"activité type AT3 (Élaborer et mettre en œuvre les composants dans une application de gestion) et plus spécifiquement la compétence CP9 (Préparer et exécuter les plans de tests unitaires et d"intégration).
AT3 : Élaborer et mettre en œuvre les composants dans une application de gestion
CP9 : Préparer et exécuter les plans de tests unitaires et d"intégration
Stratégie de Tests
La stratégie de tests pour ActivMap repose sur la pyramide des tests, privilégiant une base solide de tests unitaires rapides et peu coûteux, complétée par des tests d"intégration et, dans une moindre mesure (car plus coûteux à mettre en œuvre et à maintenir), des tests end-to-end.


1. Tests Unitaires (TU) :


* Objectif : Vérifier le bon fonctionnement de petites unités de code isolées (fonctions, méthodes de classe) indépendamment du reste de l"application.
* Périmètre :
   * Backend (Python/Flask) : Fonctions utilitaires, logique métier pure dans les services (ex: calculs, transformations de données simples), validation de schémas (Marshmallow/Pydantic), fonctions de sécurité (hachage de mot de passe), logique simple dans les modèles SQLAlchemy (si existante).
   * Frontend (Svelte) : Fonctions utilitaires JavaScript, logique simple dans les stores Svelte, rendu de base de composants avec différentes props (tests de snapshots).
* Outils :
   * Backend : pytest (framework de test), pytest-mock (pour mocker les dépendances externes comme les appels API ou la base de données).
   * Frontend : Vitest (framework de test rapide compatible avec Vite), Svelte Testing Library (pour tester les composants Svelte de manière orientée utilisateur).
* Exécution : Automatisée, idéalement à chaque commit ou dans le pipeline de CI. Ils doivent être rapides à exécuter.
* Couverture : Viser une couverture élevée des fonctions critiques et de la logique complexe.


2. Tests d"Intégration :


* Objectif : Vérifier que plusieurs composants ou modules interagissent correctement entre eux.
* Périmètre :
   * Backend (Python/Flask) :
      * Interaction entre la couche API (routes Flask) et la couche métier/service.
      * Interaction entre la couche métier/service et la couche d"accès aux données (avec une base de données de test).
      * Interaction avec le cache Redis.
      * Tests des endpoints de l"API : envoyer des requêtes HTTP simulées (via le client de test Flask ou pytest-flask) et vérifier les réponses (code de statut, contenu JSON, effets de bord en base de données).
   * Frontend (Svelte) :
      * Interaction entre plusieurs composants Svelte (ex: formulaire soumettant des données à un composant parent qui appelle l"API).
      * Interaction entre les composants et les stores Svelte.
* Outils :
   * Backend : pytest, client de test Flask, base de données de test (ex: PostgreSQL dans un conteneur Docker dédié aux tests, potentiellement avec des données pré-chargées ou réinitialisée entre les tests).
   * Frontend : Vitest, Svelte Testing Library.
* Exécution : Automatisée, dans le pipeline de CI. Moins fréquents que les TU car plus lents.
* Couverture : Se concentrer sur les interactions critiques entre les couches et les modules.


3. Tests End-to-End (E2E) / Tests d"Acceptation :


* Objectif : Simuler le parcours complet d"un utilisateur dans l"application réelle (ou quasi-réelle) pour valider les scénarios fonctionnels majeurs du point de vue de l"utilisateur.
* Périmètre : Scénarios clés définis dans les User Stories :
   * Connexion d"un utilisateur.
   * Génération d"une carte par coordonnées et vérification de la prévisualisation.
   * Export de la carte générée (vérification du téléchargement).
   * Consultation de l"historique.
   * (Si ADMIN) Création d"un nouvel utilisateur.
* Outils : Frameworks de test E2E comme Playwright ou Cypress. Ces outils pilotent un vrai navigateur pour interagir avec l"interface utilisateur.
* Exécution : Automatisée, mais généralement moins fréquente (ex: avant une release) car ils sont les plus lents et les plus fragiles (sensibles aux changements d"UI).
* Environnement : Nécessite une instance complète de l"application (frontend, backend, BDD, etc.) dans un environnement de test dédié (staging ou un environnement Docker spécifique aux tests E2E).
* Couverture : Se concentrer sur les flux utilisateurs les plus critiques (happy paths).


4. Tests Manuels / Exploratoires :


* Objectif : Découvrir des bugs non couverts par les tests automatisés, évaluer l"utilisabilité et l"expérience utilisateur globale.
* Périmètre : Exploration libre de l"application, tests des cas limites, vérification de l"accessibilité avec des outils spécifiques ou des lecteurs d"écran.
* Exécution : Manuelle, effectuée par le développeur, un testeur ou même des utilisateurs pilotes avant une mise en production.


Intégration dans le Processus de Développement :


* Développement Guidé par les Tests (TDD - Test-Driven Development) : Peut être appliqué, notamment pour les tests unitaires : écrire un test qui échoue, écrire le code minimum pour faire passer le test, puis refactoriser.
* Intégration Continue (CI) : Le pipeline de CI (ex: GitHub Actions) est configuré pour exécuter automatiquement les tests unitaires et d"intégration à chaque push ou Pull Request. Un build échoue si les tests ne passent pas, empêchant l"intégration de code défectueux.
* Revue de Code : Les tests (en particulier unitaires) font partie intégrante du code et doivent être inclus dans les revues de code (si travail en équipe) pour s"assurer de leur pertinence et de leur qualité.


Cette stratégie multi-niveaux vise à fournir une confiance élevée dans la qualité et la stabilité d"ActivMap, en détectant les régressions le plus tôt possible dans le cycle de développement.
Tests Unitaires (TU)
Les tests unitaires constituent la base de la pyramide des tests pour ActivMap. Ils sont conçus pour être rapides, isolés et fiables, permettant de vérifier le comportement correct de petites unités de code sans dépendre du reste de l"application ou de services externes (base de données, API Overpass).


Backend (Python/Flask avec Pytest) :


* Objectif : Tester les fonctions utilitaires, la logique métier pure dans les services, la validation des schémas, et les méthodes simples des modèles qui ne nécessitent pas d"accès à la base de données.
* Isolation (Mocking) : La clé des tests unitaires est l"isolation. La bibliothèque pytest-mock (ou unittest.mock intégré à Python) est utilisée pour remplacer les dépendances externes par des objets "mock" ou "stub". Par exemple :
   * Lors du test d"une fonction de service qui appelle l"API Overpass, l"appel à requests.get est mocké pour retourner une réponse GeoJSON prédéfinie, sans effectuer de véritable appel réseau.
   * Lors du test d"une fonction métier qui utilise un modèle SQLAlchemy pour une logique simple (ex: une méthode de formatage sur le modèle Generation), l"objet modèle est instancié directement sans interaction avec la base de données.
   * Lors du test d"une fonction de la couche API qui appelle un service métier, le service métier est mocké pour vérifier que la route appelle le bon service avec les bons arguments, sans exécuter la logique métier elle-même.
* Structure des Tests : Les tests sont organisés dans un répertoire tests/ (ou similaire) à la racine du projet backend. Les fichiers de test suivent la convention de nommage test_*.py ou *_test.py. Pytest découvre et exécute automatiquement ces tests.
* Exemple Générique (Test d"une fonction utilitaire) :


# dans utils.py


def format_coordinates(lat, lon):


    return f"({lat:.4f}, {lon:.4f})"


# dans tests/test_utils.py


from app.utils import format_coordinates


def test_format_coordinates():


    assert format_coordinates(48.8566, 2.3522) == "(48.8566, 2.3522)"


    assert format_coordinates(-33.8688, 151.2093) == "(-33.8688, 151.2093)"


* Exemple Générique (Test d"une fonction métier avec Mock) :


# dans services/map_service.py


from app.clients import overpass_client


def get_osm_data(lat, lon, radius):


    # ... logique pour construire la query Overpass ...


    try:


        data = overpass_client.fetch_data(query)


        # ... traitement ...


        return processed_data


    except Exception as e:


        # ... gestion erreur ...


        return None


# dans tests/services/test_map_service.py


from app.services import map_service


def test_get_osm_data_success(mocker): # mocker vient de pytest-mock


    # Mock de la dépendance externe (client Overpass)


    mock_fetch = mocker.patch(\"app.clients.overpass_client.fetch_data\")


    mock_fetch.return_value = {\"type\": \"FeatureCollection\", \"features\": []} # Exemple de retour


    result = map_service.get_osm_data(45.0, 1.0, 500)


    mock_fetch.assert_called_once() # Vérifie que le mock a été appelé


    assert result is not None


    # ... autres assertions sur le résultat traité ...


def test_get_osm_data_failure(mocker):


    mock_fetch = mocker.patch(\"app.clients.overpass_client.fetch_data\")


    mock_fetch.side_effect = Exception(\"Network Error\") # Simule une exception


    result = map_service.get_osm_data(45.0, 1.0, 500)


    mock_fetch.assert_called_once()


    assert result is None


Frontend (Svelte avec Vitest) :


* Objectif : Tester les fonctions utilitaires JavaScript, la logique des stores Svelte, et le rendu de base des composants avec différentes props.
* Isolation : Les appels API sont systématiquement mockés (ex: en utilisant des librairies comme msw (Mock Service Worker) ou en mockant directement fetch/axios). Les stores complexes peuvent être testés isolément ou avec des mocks pour leurs dépendances.
* Tests de Composants : Svelte Testing Library permet de monter des composants Svelte dans un environnement de test (utilisant jsdom pour simuler le DOM) et d"interagir avec eux comme le ferait un utilisateur (recherche d"éléments par texte, rôle, etc., simulation de clics, de saisies). On vérifie ensuite que le rendu est correct ou que les bons événements sont émis.
* Exemple Générique (Test d"un store Svelte) :


// dans stores/styleStore.js


import { writable } from \"svelte/store\";


export const selectedStyleId = writable(null);


export const defaultStyleId = 1;


export function resetStyle() {


  selectedStyleId.set(defaultStyleId);


}


// dans tests/stores/styleStore.test.js


import { get } from \"svelte/store\";


import { selectedStyleId, defaultStyleId, resetStyle } from \"$lib/stores/styleStore\";


import { describe, it, expect, beforeEach } from \"vitest\";


describe(\"styleStore\", () => {


  beforeEach(() => {


    // Reset state before each test


    selectedStyleId.set(null);


  });


  it(\"should have a default value of null\", () => {


    expect(get(selectedStyleId)).toBeNull();


  });


  it(\"resetStyle should set selectedStyleId to defaultStyleId\", () => {


    resetStyle();


    expect(get(selectedStyleId)).toBe(defaultStyleId);


  });


});


* Exemple Générique (Test d"un composant Svelte) :


// dans components/SimpleButton.svelte


<script>


  export let label = \"Click Me\";


  export let disabled = false;


</script>


<button {disabled} on:click>{label}</button>


// dans tests/components/SimpleButton.test.js


import { render, fireEvent } from \"@testing-library/svelte\";


import SimpleButton from \"$lib/components/SimpleButton.svelte\";


import { describe, it, expect, vi } from \"vitest\";


describe(\"SimpleButton\", () => {


  it(\"renders with default label and is enabled\", () => {


    const { getByText } = render(SimpleButton);


    const button = getByText(\"Click Me\");


    expect(button).toBeInTheDocument();


    expect(button).not.toBeDisabled();


  });


  it(\"renders with custom label and is disabled\", () => {


    const { getByText } = render(SimpleButton, { props: { label: \"Submit\", disabled: true } });


    const button = getByText(\"Submit\");


    expect(button).toBeInTheDocument();


    expect(button).toBeDisabled();


  });


  it(\"fires click event when clicked\", async () => {


    const { getByText, component } = render(SimpleButton);


    const button = getByText(\"Click Me\");


    const mockClickHandler = vi.fn();


    component.$on(\"click\", mockClickHandler);


    await fireEvent.click(button);


    expect(mockClickHandler).toHaveBeenCalledTimes(1);


  });


});


L"exécution régulière de ces tests unitaires permet de détecter rapidement les régressions au niveau le plus bas, de faciliter le refactoring en donnant confiance dans la non-rupture du code existant, et de servir de documentation vivante pour le comportement attendu de chaque unité de code.
Tests d"Intégration
Les tests d"intégration dans ActivMap visent à vérifier que les différentes parties de l"application (couches backend, interaction backend-frontend, interaction avec la base de données ou le cache) fonctionnent correctement ensemble. Ils sont plus complexes et plus lents que les tests unitaires car ils impliquent souvent de véritables interactions entre composants, mais ils sont essentiels pour détecter les problèmes aux interfaces entre les modules.


Backend (Python/Flask avec Pytest) :


* Objectif : Tester l"interaction entre les routes Flask, les services métier et la couche d"accès aux données, ainsi que l"interaction avec la base de données réelle (de test) et potentiellement le cache Redis.
* Environnement de Test :
   * Client de Test Flask : Pytest, via des plugins comme pytest-flask, fournit un client de test qui permet d"envoyer des requêtes HTTP simulées aux endpoints de l"application Flask sans démarrer un serveur web complet. On peut ainsi tester le flux requête -> route -> service -> réponse.
   * Base de Données de Test : Une base de données PostgreSQL distincte (ou un schéma distinct) est utilisée pour les tests d"intégration. Elle peut être gérée via Docker (un conteneur PostgreSQL dédié aux tests). Avant chaque test (ou série de tests), la base de données est généralement réinitialisée à un état connu (soit en recréant les tables via les migrations Alembic/Flask-Migrate, soit en restaurant un dump, soit en utilisant des transactions annulées après chaque test).
   * Fixtures Pytest : Des fixtures Pytest sont utilisées pour configurer l"environnement de test, par exemple, pour initialiser l"application Flask en mode test, créer le client de test, configurer la base de données de test, ou insérer des données initiales nécessaires au test (ex: un utilisateur de test, des styles prédéfinis).
* Exemple Générique (Test d"un endpoint API avec BDD) :


# dans tests/integration/test_generation_api.py


import pytest


from app.models import User, Style # Importer les modèles


# Fixture pour créer un utilisateur de test (suppose une fixture db_session qui gère la session BDD)


@pytest.fixture


def test_user(db_session):


    user = User(nom_utilisateur=\"testuser\", email=\"test@example.com\", role_id=1) # Supposons role_id 1 = EMPLOYE


    # Hacher le mot de passe...


    user.set_password(\"password\")


    db_session.add(user)


    db_session.commit()


    return user


# Fixture pour créer un style de test


@pytest.fixture


def test_style(db_session):


    style = Style(nom_style=\"Test Style\", parametres=\"{}\", est_predefini=False)


    db_session.add(style)


    db_session.commit()


    return style


# Test de l\"endpoint de génération (suppose une fixture \"client\" pour le client de test Flask et \"auth_headers\" pour l\"authentification)


def test_create_generation_success(client, auth_headers, test_user, test_style):


    payload = {


        \"latitude\": 48.85, \"longitude\": 2.35, \"rayon\": 1000, \"style_id\": test_style.style_id


    }


    response = client.post(\"/api/generations\", json=payload, headers=auth_headers(test_user))


    assert response.status_code == 201 # Vérifie le code de statut HTTP (Created)


    json_data = response.get_json()


    assert \"id\" in json_data


    assert \"svg_preview\" in json_data # Ou autre champ attendu


    # Vérifier potentiellement en base de données que la génération a été créée


    from app.models import Generation


    gen = Generation.query.filter_by(id=json_data[\"id\"]).first()


    assert gen is not None


    assert gen.auteur_id == test_user.utilisateur_id


    assert gen.parametres[\"rayon\"] == 1000


def test_create_generation_invalid_payload(client, auth_headers, test_user):


    payload = {\"latitude\": \"invalid\", \"longitude\": 2.35} # Payload invalide


    response = client.post(\"/api/generations\", json=payload, headers=auth_headers(test_user))


    assert response.status_code == 400 # Bad Request


def test_create_generation_unauthorized(client):


    payload = {\"latitude\": 48.85, \"longitude\": 2.35, \"rayon\": 1000, \"style_id\": 1}


    response = client.post(\"/api/generations\", json=payload) # Pas d\"authentification


    assert response.status_code == 401 # Unauthorized


* Couverture : Ces tests couvrent les flux principaux de l"API, y compris les cas de succès, les erreurs de validation, les erreurs d"authentification/autorisation, et vérifient l"intégration avec la base de données.


Frontend (Svelte avec Vitest et Mock Service Worker) :


* Objectif : Tester l"interaction entre les composants Svelte et les appels API mockés, simulant ainsi l"intégration avec le backend sans dépendre de sa disponibilité réelle.
* Mocking des API : La librairie msw (Mock Service Worker) est particulièrement adaptée. Elle intercepte les requêtes fetch (ou axios) au niveau réseau et permet de définir des réponses mockées pour des endpoints spécifiques. Cela permet de tester le comportement complet du frontend (ex: affichage des données, gestion des états de chargement/erreur) en réponse à différents scénarios d"API.
* Exemple Générique (Test d"un composant qui fetch des données) :


// dans components/HistoryPage.svelte


<script>


  import { onMount } from \"svelte\";


  import { fetchGenerations } from \"$lib/api\"; // Fonction qui appelle l\"API


  let generations = [];


  let isLoading = true;


  let error = null;


  onMount(async () => {


    try {


      generations = await fetchGenerations();


    } catch (err) {


      error = err.message;


    } finally {


      isLoading = false;


    }


  });


</script>


{#if isLoading}


  <p>Chargement...</p>


{:else if error}


  <p class=\"error\">Erreur: {error}</p>


{:else}


  <ul>


    {#each generations as gen (gen.id)}


      <li>{gen.id} - {new Date(gen.date_creation).toLocaleDateString()}</li>


    {/each}


  </ul>


{/if}


// dans tests/components/HistoryPage.test.js


import { render, screen, waitFor } from \"@testing-library/svelte\";


import HistoryPage from \"$lib/components/HistoryPage.svelte\";


import { setupServer } from \"msw/node\";


import { rest } from \"msw\";


import { describe, it, expect, beforeAll, afterEach, afterAll } from \"vitest\";


// Configuration du serveur MSW


const server = setupServer(


  rest.get(\"/api/generations\", (req, res, ctx) => {


    // Simule une réponse succès de l\"API


    return res(ctx.json([


      { id: 1, date_creation: \"2023-01-01T10:00:00Z\" },


      { id: 2, date_creation: \"2023-01-02T11:00:00Z\" },


    ]));


  })


);


beforeAll(() => server.listen());


afterEach(() => server.resetHandlers());


afterAll(() => server.close());


describe(\"HistoryPage\", () => {


  it(\"displays loading state initially\", () => {


    render(HistoryPage);


    expect(screen.getByText(\"Chargement...\")).toBeInTheDocument();


  });


  it(\"displays generations after successful fetch\", async () => {


    render(HistoryPage);


    // Attend que l\"état de chargement disparaisse et que les éléments apparaissent


    await waitFor(() => {


      expect(screen.queryByText(\"Chargement...\")).not.toBeInTheDocument();


    });


    expect(screen.getByText(\"1 - 01/01/2023\")).toBeInTheDocument(); // Format dépend de la locale


    expect(screen.getByText(\"2 - 02/01/2023\")).toBeInTheDocument();


  });


  it(\"displays error message on fetch failure\", async () => {


    // Surcharge le handler pour simuler une erreur


    server.use(


      rest.get(\"/api/generations\", (req, res, ctx) => {


        return res(ctx.status(500), ctx.json({ message: \"Internal Server Error\" }));


      })


    );


    render(HistoryPage);


    await waitFor(() => {


      expect(screen.queryByText(\"Chargement...\")).not.toBeInTheDocument();


    });


    expect(screen.getByText(/Erreur: Internal Server Error/)).toBeInTheDocument();


  });


});


Les tests d"intégration sont cruciaux pour s"assurer que les différentes parties de l"application communiquent et fonctionnent correctement ensemble, offrant un niveau de confiance supérieur à celui des tests unitaires seuls.
Tests de Sécurité
La sécurité étant une préoccupation majeure pour toute application web, des tests spécifiques sont nécessaires pour identifier et corriger les vulnérabilités potentielles dans ActivMap. Ces tests complètent les bonnes pratiques de sécurité mises en œuvre pendant le développement (décrites dans la section Architecture et Développement).


Approche Basée sur les Risques et l"OWASP Top 10 :


L"approche des tests de sécurité se concentre sur les risques les plus probables et les plus impactants, en s"inspirant notamment du Top 10 de l"OWASP (Open Web Application Security Project), qui recense les vulnérabilités web les plus critiques.


1. Contrôle d"Accès Défaillant (Broken Access Control - OWASP A1:2021) :


* Tests :
   * Tenter d"accéder à des ressources ou fonctionnalités réservées à un rôle supérieur (ex: un EMPLOYE essayant d"accéder aux endpoints d"administration /api/admin/...).
   * Tenter d"accéder ou de modifier des données appartenant à un autre utilisateur (ex: voir l"historique d"un autre utilisateur, modifier un style qui ne lui appartient pas) en manipulant les ID dans les URL ou les payloads.
   * Vérifier que les tokens JWT sont correctement validés et que les informations de rôle qu"ils contiennent ne peuvent pas être falsifiées côté client.
* Outils : Tests d"intégration automatisés (en simulant des requêtes avec des authentifications de différents rôles), tests manuels avec des outils de proxy comme OWASP ZAP ou Burp Suite pour intercepter et modifier les requêtes.


2. Failles Cryptographiques (Cryptographic Failures - OWASP A2:2021) :


* Tests :
   * Vérifier que toutes les communications sensibles (login, échanges de données) se font exclusivement via HTTPS (vérification de la configuration Nginx et des redirections).
   * S"assurer que les mots de passe ne sont jamais stockés en clair, mais correctement hachés (bcrypt) avec un sel unique par utilisateur.
   * Vérifier que les clés secrètes (ex: clé secrète Flask pour signer les sessions/cookies, clé secrète JWT) sont suffisamment fortes et ne sont pas exposées dans le code source ou les configurations publiques.
* Outils : Analyse de code, vérification de la configuration serveur (Nginx, Flask), outils d"analyse de trafic réseau (Wireshark en local), scanners SSL/TLS (ex: SSL Labs).


3. Injection (Injection - OWASP A3:2021) :


* Tests :
   * Injection SQL : Bien que l"utilisation de l"ORM SQLAlchemy réduise considérablement ce risque, vérifier qu"aucune requête SQL brute n"est construite par concaténation de chaînes non validées. Tester les endpoints qui prennent des paramètres de filtrage ou de recherche.
   * Injection de Commandes OS : Si l"application interagit avec le système d"exploitation (ex: pour lancer des processus externes, ce qui ne semble pas être le cas ici), vérifier que les entrées utilisateur ne peuvent pas être utilisées pour injecter des commandes malveillantes.
   * Cross-Site Scripting (XSS) :
      * Reflected XSS : Injecter des scripts dans les paramètres d"URL ou les champs de formulaire et vérifier s"ils sont exécutés dans le navigateur de l"utilisateur (ex: via un message d"erreur qui reflète l"entrée).
      * Stored XSS : Injecter des scripts dans les données persistantes (ex: nom d"utilisateur, nom de style) et vérifier s"ils sont exécutés lorsqu"ils sont affichés à d"autres utilisateurs.
* Outils : Scanners de vulnérabilités automatisés (OWASP ZAP, Burp Suite), tests manuels ciblés, revue de code (pour SQL et OS Command Injection), vérification que Svelte (ou le framework frontend) échappe correctement les données affichées (ce qui est généralement le cas par défaut).


4. Conception Non Sécurisée (Insecure Design - OWASP A4:2021) :


* Tests : Il s"agit moins de tests techniques que d"une revue de la conception globale pour identifier les failles logiques ou les hypothèses de sécurité incorrectes (ex: processus de réinitialisation de mot de passe non sécurisé, logique de contrôle d"accès insuffisante).
* Outils : Revue de la documentation de conception, modélisation des menaces (Threat Modeling).


5. Mauvaise Configuration de Sécurité (Security Misconfiguration - OWASP A5:2021) :


* Tests :
   * Vérifier que le mode debug de Flask n"est pas activé en production.
   * Vérifier que les messages d"erreur détaillés ne sont pas exposés aux utilisateurs finaux en production.
   * Scanner les en-têtes de sécurité HTTP (CSP, HSTS, X-Frame-Options, etc.) et vérifier leur présence et leur configuration correcte.
   * Vérifier les permissions des fichiers et des répertoires sur le serveur.
   * S"assurer que les services Docker ne sont pas exposés inutilement sur l"hôte ou sur internet.
* Outils : Scanners de configuration (ex: outils intégrés aux plateformes cloud, scanners de ports), vérification manuelle des fichiers de configuration (Flask, Nginx, Docker), outils d"analyse d"en-têtes HTTP (ex: Security Headers).


6. Composants Vulnérables et Obsolètes (Vulnerable and Outdated Components - OWASP A6:2021) :


* Tests/Processus :
   * Utiliser des outils d"analyse de composition logicielle (SCA - Software Composition Analysis) pour scanner les dépendances (Python via pip, Node.js via npm) et identifier les bibliothèques avec des vulnérabilités connues (CVE).
   * Mettre en place un processus régulier de mise à jour des dépendances.
* Outils : npm audit, pip-audit, OWASP Dependency-Check, Snyk, GitHub Dependabot.


7. Failles d"Identification et d"Authentification (Identification and Authentication Failures - OWASP A7:2021) :


* Tests :
   * Tester la robustesse de la politique de mots de passe (si applicable).
   * Vérifier l"absence de mécanismes permettant le bourrage d"identifiants (Credential Stuffing) ou les attaques par force brute (mise en place de rate limiting sur le login).
   * S"assurer que les tokens JWT ont une durée de vie limitée et sont invalidés à la déconnexion (si utilisation de blacklist/mécanisme de révocation).
* Outils : Tests manuels, outils d"attaque par force brute (Hydra, mais avec précaution sur les environnements), revue de la logique d"authentification.


Autres Tests Pertinents :


* Validation des Redirections et Forwards : S"assurer que les redirections ne peuvent pas être manipulées pour rediriger vers des sites malveillants (Open Redirect).
* Tests de Fuzzing : Envoyer des données inattendues ou malformées aux endpoints API pour tester leur robustesse.


Intégration des Tests de Sécurité :


* Automatisation : Intégrer des scanners de sécurité (SCA, SAST - Static Application Security Testing) dans le pipeline de CI.
* Tests Manuels Périodiques : Effectuer des tests d"intrusion manuels ou utiliser des outils comme OWASP ZAP de manière plus approfondie avant des mises en production majeures.
* Sensibilisation : Former les développeurs aux bonnes pratiques de codage sécurisé.


En combinant des outils automatisés, des tests manuels ciblés et une revue de la conception et du code, ActivMap peut atteindre un niveau de sécurité adéquat pour ses besoins.
Tests d’Acceptation Utilisateur (UAT - User Acceptance Testing)
Les tests d’acceptation utilisateur sont la dernière phase de test avant la mise en production (ou la livraison finale dans le cadre de ce projet). Ils visent à s’assurer que l’application ActivMap répond bien aux besoins et aux attentes des utilisateurs finaux (les employés de FeelObject) et qu’elle est utilisable dans un contexte réaliste.


Objectif :


* Valider que l’application développée correspond aux exigences fonctionnelles définies dans le cahier des charges et les User Stories.
* Confirmer que l’application est intuitive, facile à utiliser et répond aux besoins opérationnels des utilisateurs.
* Identifier les derniers bugs ou problèmes d’utilisabilité avant le déploiement.
* Obtenir l’approbation formelle des utilisateurs (ou du représentant métier) pour la mise en production.


Processus :


1. Préparation :


   * Environnement UAT : Mettre en place un environnement de test dédié qui reflète le plus fidèlement possible l’environnement de production (serveur VPS, configuration Docker identique à la production, base de données avec des données réalistes mais anonymisées si nécessaire).
   * Scénarios de Test UAT : Définir des scénarios de test basés sur les User Stories et les processus métier réels des utilisateurs de FeelObject. Ces scénarios doivent couvrir les fonctionnalités clés de bout en bout.
      * Exemple de scénario : "En tant qu’EMPLOYE, je veux générer une carte pour une zone donnée avec le style ‘Standard’, prévisualiser le résultat, puis l’exporter en SVG."
      * Exemple de scénario (ADMIN) : "En tant qu’ADMIN, je veux créer un nouvel utilisateur EMPLOYE, puis vérifier qu’il peut se connecter et générer une carte."
   * Jeu de Données : Préparer un jeu de données pertinent pour les tests (exemples de coordonnées, styles personnalisés si applicable).
   * Participants : Identifier les utilisateurs clés de FeelObject (représentant différents rôles : EMPLOYE, CHEF, ADMIN) qui participeront aux tests.
   * Documentation/Support : Fournir aux testeurs un guide simple d’utilisation ou une brève formation si nécessaire, ainsi qu’un moyen de remonter les problèmes (ex: formulaire, outil de suivi simple).


2. Exécution :


   * Les utilisateurs désignés exécutent les scénarios de test définis sur l’environnement UAT.
   * Ils utilisent l’application comme ils le feraient dans leur travail quotidien.
   * Ils sont encouragés à tester également les cas limites ou à explorer l’application au-delà des scénarios stricts (tests exploratoires).
   * Ils documentent les résultats de chaque scénario (Succès/Échec) et signalent tout bug, problème d’utilisabilité ou écart par rapport aux attentes.


3. Analyse et Correction :


   * Les retours des utilisateurs sont collectés et analysés.
   * Les bugs confirmés sont priorisés et corrigés par le développeur.
   * Les problèmes d’utilisabilité ou les demandes de modification mineures sont évalués (certains peuvent être reportés à une version ultérieure).
   * Une nouvelle version corrigée est déployée sur l’environnement UAT pour re-test (tests de régression).


4. Validation :


   * Le processus d’exécution et de correction est répété jusqu’à ce que les utilisateurs valident que l’application répond aux exigences et est prête pour la production.
   * Une approbation formelle (ex: signature d’un PV de recette) peut être demandée.


Critères d’Acceptation :


Les critères d’acceptation sont définis en amont et basés sur les exigences fonctionnelles et non fonctionnelles. L’application est généralement acceptée si :


* Toutes les fonctionnalités critiques (priorité haute) fonctionnent conformément aux spécifications.
* Aucun bug bloquant n’est présent.
* Les bugs majeurs non bloquants sont corrigés ou un plan de correction est accepté.
* L’application est jugée suffisamment stable et performante pour une utilisation en production.
* L’application répond aux principaux besoins des utilisateurs pour lesquels elle a été conçue.


Bien que le contexte du projet de certification puisse simplifier ce processus (le développeur jouant parfois le rôle de l’utilisateur testeur), la démarche UAT reste importante pour valider la pertinence et la qualité de l’application développée par rapport aux objectifs initiaux.
Plans de Tests
La préparation de plans de tests formels est une étape clé de la compétence CP9. Ces plans documentent en détail comment les tests (unitaires, d"intégration, d"acceptation) seront exécutés, quelles sont les conditions préalables, les étapes à suivre, les résultats attendus et les critères de succès/échec. Même pour un projet individuel, esquisser ces plans aide à structurer la démarche de test et à assurer une couverture adéquate.


Structure Générale d"un Plan de Test (Exemple) :


Chaque plan de test (qu"il soit pour un module, une fonctionnalité ou un scénario UAT) devrait idéalement contenir les informations suivantes :


1. Identifiant Unique du Test : Ex: TU_AUTH_01, TI_GEN_03, UAT_EXPORT_SVG
2. Objectif du Test : Description concise de ce que le test vise à vérifier. Ex: "Vérifier que la fonction de hachage de mot de passe utilise bcrypt et produit un hash valide.", "Vérifier que l"endpoint /api/generations crée une nouvelle génération en base de données avec des paramètres valides.", "Vérifier qu"un EMPLOYE peut exporter une carte générée au format SVG."
3. Prérequis / Conditions Initiales : État nécessaire avant de lancer le test. Ex: "Base de données de test initialisée.", "Utilisateur 'test_admin' existant en base.", "Mock de l"API Overpass configuré pour retourner des données valides.", "Utilisateur connecté avec le rôle EMPLOYE."
4. Étapes du Test : Description séquentielle des actions à effectuer. Ex:
   * Pour un TU : "Appeler la fonction hash_password(\"password123\").".
   * Pour un TI : "1. Authentifier l"utilisateur 'test_user'. 2. Envoyer une requête POST à /api/generations avec le payload {…}."
   * Pour un UAT : "1. Se connecter avec l"utilisateur 'employe_test'. 2. Accéder à la page de génération. 3. Entrer les coordonnées X, Y et le rayon Z. 4. Sélectionner le style 'Standard'. 5. Cliquer sur 'Générer'. 6. Attendre l"affichage de la prévisualisation. 7. Cliquer sur 'Exporter SVG'."
5. Données de Test : Valeurs spécifiques utilisées pour les entrées. Ex: latitude=48.85, rayon=500, email=\"invalid-email\", password=\"short\".
6. Résultat Attendu : Description précise de ce qui doit se passer si le test réussit. Ex: "La fonction retourne une chaîne de caractères commençant par $2b$. ", "La réponse HTTP a un statut 201 et contient un ID de génération.", "La base de données contient une nouvelle ligne dans la table generations_cartes.", "Un fichier nommé activmap_export.svg est téléchargé par le navigateur."
7. Critères de Succès/Échec : Conditions claires pour déterminer si le test a réussi ou échoué (souvent implicites dans le résultat attendu).
8. Résultat Obtenu (lors de l"exécution) : Succès / Échec.
9. Commentaires / Anomalies (si échec) : Description du problème rencontré, message d"erreur, etc.


Exemples de Plans de Tests pour ActivMap :


* Plan de Tests Unitaires (Module auth_utils.py) :
   * TU_AUTH_01: Vérifier hash_password avec une chaîne valide.
   * TU_AUTH_02: Vérifier check_password avec mot de passe correct.
   * TU_AUTH_03: Vérifier check_password avec mot de passe incorrect.
   * TU_AUTH_04: Vérifier la génération de token JWT avec des données utilisateur valides (mock de jwt.encode).
   * TU_AUTH_05: Vérifier la validation de token JWT valide (mock de jwt.decode).
   * TU_AUTH_06: Vérifier l"échec de validation de token JWT invalide/expiré.
* Plan de Tests d"Intégration (API /api/styles) :
   * TI_STYLE_01: GET /api/styles (non authentifié) - Attendu: 401 Unauthorized.
   * TI_STYLE_02: GET /api/styles (authentifié EMPLOYE) - Attendu: 200 OK avec liste des styles (prédéfinis + ceux de l"utilisateur).
   * TI_STYLE_03: POST /api/styles (authentifié EMPLOYE, payload valide) - Attendu: 201 Created, vérification en BDD.
   * TI_STYLE_04: POST /api/styles (authentifié EMPLOYE, payload invalide) - Attendu: 400 Bad Request.
   * TI_STYLE_05: GET /api/styles/{id} (authentifié EMPLOYE, style existant appartenant à l"utilisateur) - Attendu: 200 OK.
   * TI_STYLE_06: GET /api/styles/{id} (authentifié EMPLOYE, style existant n"appartenant pas à l"utilisateur) - Attendu: 403 Forbidden ou 404 Not Found.
   * TI_STYLE_07: PUT /api/styles/{id} (authentifié EMPLOYE, payload valide, style appartenant à l"utilisateur) - Attendu: 200 OK, vérification en BDD.
   * TI_STYLE_08: DELETE /api/styles/{id} (authentifié EMPLOYE, style appartenant à l"utilisateur) - Attendu: 204 No Content, vérification en BDD.
   * TI_STYLE_09: DELETE /api/styles/{id} (authentifié EMPLOYE, style prédéfini) - Attendu: 403 Forbidden.
* Plan de Tests d"Acceptation Utilisateur (Scénario : Génération et Export) :
   * UAT_GEN_EXPORT_01: Scénario nominal EMPLOYE (Connexion -> Génération -> Prévisualisation -> Export SVG) - Attendu: Succès, fichier SVG téléchargé et correct.
   * UAT_GEN_EXPORT_02: Scénario nominal EMPLOYE (Export PNG) - Attendu: Succès, fichier PNG téléchargé et correct.
   * UAT_GEN_EXPORT_03: Test avec coordonnées invalides - Attendu: Message d"erreur clair dans l"UI, pas de génération.
   * UAT_GEN_EXPORT_04: Test avec rayon hors limites - Attendu: Message d"erreur clair dans l"UI.
   * UAT_GEN_EXPORT_05: Test avec style personnalisé - Attendu: Succès, export utilise le style personnalisé.


Gestion des Plans de Tests :


Ces plans peuvent être gérés de différentes manières :


* Dans le Code : Pour les tests automatisés (TU, TI), le code de test lui-même sert de plan de test. Les noms de fonctions de test descriptifs (test_login_with_valid_credentials) et les assertions claires documentent l"objectif et le résultat attendu.
* Outils de Gestion de Tests : Pour des projets plus importants ou des tests manuels (UAT), des outils dédiés comme TestRail, Xray (plugin Jira), ou même des tableurs partagés peuvent être utilisés pour documenter les plans, assigner les exécutions et suivre les résultats.
* Documentation : Inclure un résumé de la stratégie et des principaux plans de tests dans la documentation du projet (ex: TESTING.md ou une section dédiée dans le dossier projet).


La préparation et l"exécution rigoureuse de ces plans de tests, même de manière simplifiée, sont essentielles pour valider que les composants développés fonctionnent comme prévu, individuellement et ensemble, et répondent aux exigences définies.
Déploiement
Le déploiement de l"application ActivMap en production est une étape critique qui vise à rendre l"application accessible aux utilisateurs finaux (les employés de FeelObject) de manière fiable, sécurisée et performante. Cette section couvre les compétences CP10 (Déployer une application) et CP11 (Accompagner l"utilisateur dans la prise en main de l"application) de l"activité type AT3.
AT3 : Élaborer et mettre en œuvre les composants dans une application de gestion
CP10 : Déployer une application
Le déploiement d"ActivMap repose fortement sur la conteneurisation avec Docker et Docker Compose, ce qui simplifie et standardise le processus sur un serveur cible (probablement un VPS Linux).


1. Mise en Place de Docker (Dockerfiles, docker-compose.yml) :


Comme détaillé dans les sections précédentes (Choix Technologiques, Développement CP1), Docker est au cœur de l"architecture et du déploiement.


* Dockerfiles :
   * Un Dockerfile est créé pour le service backend (Flask). Il part d"une image Python officielle (ex: python:3.10-slim), copie le code source de l"application, installe les dépendances Python via pip install -r requirements.txt, expose le port utilisé par Gunicorn/uWSGI (ex: 5000), et définit la commande pour lancer le serveur WSGI en mode production (CMD [\"gunicorn\", \"-w\", \"4\", \"-b\", \"0.0.0.0:5000\", \"wsgi:app\"]). Des optimisations comme les builds multi-étapes peuvent être utilisées pour réduire la taille de l"image finale.
   * Un Dockerfile est créé pour le service frontend (Svelte). Il utilise généralement un build multi-étapes : une première étape avec une image Node.js pour installer les dépendances (npm install) et builder l"application Svelte en fichiers statiques optimisés (npm run build) ; une seconde étape qui copie ces fichiers statiques buildés dans une image légère de serveur web (comme nginx:alpine) configurée pour servir ces fichiers.
* docker-compose.yml : Le fichier docker-compose.yml (ou un fichier spécifique à la production, ex: docker-compose.prod.yml) définit l"ensemble des services nécessaires en production :
   * backend: Utilise l"image construite à partir du Dockerfile backend.
   * frontend: Utilise l"image construite à partir du Dockerfile frontend (contenant Nginx pour servir les fichiers statiques).
   * db: Utilise une image officielle postgres:14-alpine (ou une version plus récente), configure les variables d"environnement pour l"utilisateur/mot de passe/nom de la base, et monte un volume nommé (postgres_data) pour la persistance des données.
   * redis: Utilise une image officielle redis:alpine, monte un volume nommé (redis_data) pour la persistance (si nécessaire).
   * proxy: Utilise une image officielle nginx:alpine, monte le fichier de configuration Nginx spécifique à la production (nginx.prod.conf), monte les certificats SSL/TLS (obtenus via Let"s Encrypt/Certbot), et expose les ports 80 et 443 sur l"hôte.
* Gestion des Images : Les images Docker pour le backend et le frontend sont construites (via docker-compose build ou docker build) soit directement sur le serveur de production, soit, de préférence, dans un pipeline de CI/CD et poussées vers un registre d"images Docker (comme Docker Hub, GitHub Container Registry, ou un registre privé). Le serveur de production tire ensuite ces images depuis le registre.


2. Configuration Nginx (Reverse Proxy, HTTPS) :


Le conteneur proxy Nginx agit comme point d"entrée unique pour l"application.


* Fichier de Configuration Nginx (nginx.prod.conf) :
   * Définit un serveur écoutant sur le port 80 qui redirige systématiquement tout le trafic vers HTTPS.
   * Définit un serveur écoutant sur le port 443 (HTTPS).
   * Configure les chemins vers les certificats SSL/TLS (ssl_certificate et ssl_certificate_key) montés dans le conteneur.
   * Configure les paramètres SSL/TLS recommandés pour la sécurité (protocoles, ciphers, HSTS).
   * Définit les location pour router les requêtes :
      * location /api/ { ... } : Utilise proxy_pass http://backend:5000; pour transmettre les requêtes API au conteneur backend (en utilisant le nom de service défini dans docker-compose.yml). Configure les en-têtes nécessaires (Host, X-Forwarded-For, X-Forwarded-Proto).
      * location / { ... } : Utilise proxy_pass http://frontend:80; (ou le port exposé par le Nginx du conteneur frontend) pour transmettre toutes les autres requêtes au conteneur frontend qui sert l"application Svelte statique. Alternativement, si le conteneur frontend est juste Nginx servant des fichiers, cette section peut directement pointer vers les fichiers statiques.
   * Configure potentiellement la mise en cache, la compression Gzip, les logs, et les en-têtes de sécurité HTTP.
* Gestion des Certificats SSL/TLS :
   * Utilisation de Certbot (éventuellement dans un conteneur Docker séparé ou directement sur l"hôte) pour obtenir et renouveler automatiquement les certificats Let"s Encrypt pour le nom de domaine associé à l"application.
   * Les certificats obtenus sont montés en volume dans le conteneur Nginx proxy.


3. Déploiement sur Serveur VPS :


Le déploiement effectif sur le serveur de production (VPS Linux) implique les étapes suivantes :


* Prérequis Serveur : Installer Docker et Docker Compose sur le VPS.
* Configuration Pare-feu : Configurer le pare-feu du serveur (ex: ufw) pour autoriser le trafic entrant uniquement sur les ports nécessaires (typiquement 80 pour la redirection HTTP et la validation Certbot, 443 pour HTTPS, et 22 pour SSH).
* Récupération du Code/Configuration : Cloner le dépôt Git contenant les Dockerfiles et le fichier docker-compose.prod.yml sur le serveur, ou mettre en place un système de déploiement automatisé.
* Variables d"Environnement : Créer un fichier .env sur le serveur contenant les variables d"environnement spécifiques à la production (clés secrètes, mots de passe de base de données, configuration de l"email, etc.). Ce fichier doit être sécurisé et non versionné.
* Obtention des Certificats SSL : Exécuter Certbot pour obtenir les certificats initiaux.
* Lancement de l"Application : Exécuter docker-compose -f docker-compose.prod.yml up -d pour télécharger/construire les images et démarrer tous les conteneurs en arrière-plan (-d).
* Migrations de Base de Données : Si c"est le premier déploiement ou une mise à jour nécessitant des changements de schéma, exécuter les migrations de base de données (ex: docker-compose -f docker-compose.prod.yml exec backend flask db upgrade).
* Vérification : Accéder à l"application via HTTPS dans un navigateur et effectuer quelques vérifications de base pour s"assurer que tout fonctionne correctement.


Mises à Jour :


Les mises à jour de l"application suivent un processus similaire :


1. Mettre à jour le code source sur le serveur (via git pull).
2. Reconstruire les images modifiées (docker-compose -f docker-compose.prod.yml build backend frontend). Ou, si utilisation d"un registre, tirer les nouvelles images (docker-compose -f docker-compose.prod.yml pull).
3. Exécuter les migrations de base de données si nécessaire (docker-compose -f docker-compose.prod.yml exec backend flask db upgrade).
4. Redémarrer les services mis à jour (docker-compose -f docker-compose.prod.yml up -d --no-deps backend frontend). Docker Compose recrée intelligemment uniquement les conteneurs dont l"image ou la configuration a changé, minimisant les interruptions.


Ce processus de déploiement basé sur Docker et Nginx offre une méthode robuste, reproductible et relativement simple pour mettre en production et maintenir l"application ActivMap.


4. Pipeline CI/CD (Intégration Continue / Déploiement Continu) :


Bien qu'un pipeline CI/CD complet n'ait peut-être pas été entièrement mis en œuvre pour ce projet spécifique (surtout s'il est développé seul), sa mise en place est une bonne pratique essentielle pour automatiser les tests et les déploiements, réduire les erreurs manuelles et accélérer le cycle de livraison.


* Concept :
   * Intégration Continue (CI) : À chaque push sur le dépôt Git (ou lors de la création/mise à jour d'une Pull Request), un processus automatisé est déclenché. Ce processus typiquement :
      1. Récupère la dernière version du code.
      2. Installe les dépendances (Python, Node.js).
      3. Exécute les linters et les formateurs de code (Flake8, Black, ESLint, Prettier) pour vérifier la qualité du code.
      4. Exécute les tests unitaires (Pytest, Vitest).
      5. Exécute les tests d'intégration (avec une base de données de test).
      6. Construit les images Docker pour le backend et le frontend.
      7. (Optionnel) Pousse les images vers un registre Docker. Le développeur est notifié si une étape échoue, empêchant l'intégration de code défectueux.
   * Déploiement Continu (CD) : Si les étapes de CI réussissent (en particulier sur la branche principale ou une branche de release), une étape supplémentaire peut être déclenchée pour déployer automatiquement l'application sur un environnement de staging ou même de production.
      1. Se connecte au serveur cible (VPS).
      2. Tire les dernières images Docker depuis le registre.
      3. Exécute les migrations de base de données.
      4. Redémarre les services via docker-compose up -d.
* Outils :
   * GitHub Actions : Intégré à GitHub, permet de définir des workflows CI/CD via des fichiers YAML directement dans le dépôt. C'est un choix courant et pratique.
   * GitLab CI/CD : Solution intégrée si le projet était hébergé sur GitLab.
   * Jenkins : Serveur d'automatisation open-source plus traditionnel et très flexible.
* Avantages pour ActivMap : Même pour un petit projet, un pipeline CI simple (tests + build d'images) assure que le code sur la branche principale est toujours testé et que les images Docker sont prêtes à être déployées. Un pipeline CD complet automatiserait le déploiement sur le VPS, rendant les mises à jour plus rapides et moins risquées.


5. Gestion des Certificats TLS (Certbot/Let's Encrypt) :


La sécurisation des communications via HTTPS est non négociable. Let's Encrypt fournit des certificats SSL/TLS gratuits, et Certbot est l'outil standard pour les obtenir et les renouveler automatiquement.


* Processus :
   1. Installation de Certbot : Installer Certbot sur le serveur VPS (ou utiliser une image Docker Certbot).
   2. Obtention Initiale : Utiliser Certbot en mode "standalone" ou avec le plugin Nginx/webroot pour prouver la propriété du nom de domaine (ex: activmap.feelobject.com) et obtenir le premier certificat. Certbot configure généralement Nginx automatiquement s'il détecte une configuration existante ou crée les fichiers de configuration nécessaires.
   3. Configuration Nginx : S'assurer que la configuration Nginx (dans le conteneur proxy) pointe vers les fichiers de certificat et de clé privée générés par Certbot (généralement dans /etc/letsencrypt/live/yourdomain.com/). Ces fichiers doivent être montés en volume dans le conteneur Nginx.
   4. Renouvellement Automatique : Certbot configure une tâche planifiée (cron job ou timer systemd) pour vérifier régulièrement l'expiration des certificats et les renouveler automatiquement avant qu'ils n'expirent (généralement tous les 60 jours pour des certificats valides 90 jours). Le serveur Nginx doit être rechargé après le renouvellement pour prendre en compte les nouveaux certificats (docker-compose exec proxy nginx -s reload).
* Intégration Docker : Une approche courante consiste à gérer Certbot sur l'hôte ou dans un conteneur dédié, et de monter le répertoire /etc/letsencrypt en volume dans le conteneur Nginx proxy pour qu'il puisse accéder aux certificats.


6. Déploiement sur VPS (OVH) :


Le choix d'un VPS OVH (ou autre fournisseur) comme serveur de production est courant. Le processus de déploiement effectif a été décrit précédemment, mais il implique :


* La configuration initiale du serveur (sécurité de base, installation Docker/Compose, pare-feu).
* Le déploiement du code et de la configuration docker-compose.prod.yml.
* La gestion des variables d'environnement de production via un fichier .env sécurisé.
* L'obtention des certificats SSL via Certbot.
* Le lancement initial des conteneurs via docker-compose up -d.
* L'exécution des migrations de base de données.


7. Surveillance et Maintenance :


Une fois déployée, l'application nécessite une surveillance et une maintenance continues.


* Logging :
   * Configurer les services (Flask, Nginx, Svelte via SSR si utilisé) pour générer des logs pertinents (erreurs, requêtes, événements importants).
   * Utiliser le système de logging de Docker (docker-compose logs -f [service]) pour consulter les logs en temps réel ou a posteriori.
   * Pour une solution plus robuste, centraliser les logs via des outils comme le stack ELK (Elasticsearch, Logstash, Kibana) ou Grafana Loki, bien que cela puisse être surdimensionné pour ce projet.
* Monitoring :
   * Surveiller l'état des conteneurs (docker ps).
   * Surveiller l'utilisation des ressources du serveur (CPU, RAM, disque) via des outils système (htop, df) ou des solutions de monitoring dédiées (Prometheus + Grafana, Datadog).
   * Mettre en place des vérifications de santé (health checks) pour les services critiques (backend, base de données).
* Sauvegardes :
   * Mettre en place une stratégie de sauvegarde régulière et automatisée pour les données critiques, en particulier la base de données PostgreSQL (via pg_dump exécuté périodiquement, par exemple via une tâche cron sur l'hôte ou dans un conteneur dédié) et les volumes persistants importants.
   * Stocker les sauvegardes dans un emplacement sécurisé et distinct du serveur de production (ex: stockage objet S3, autre serveur).
   * Tester régulièrement le processus de restauration des sauvegardes.
* Mises à Jour :
   * Planifier les mises à jour régulières du système d'exploitation du VPS, de Docker, et des dépendances de l'application (en testant au préalable en staging si possible).


Ces différentes étapes assurent un déploiement maîtrisé et une exploitation fiable de l'application ActivMap en production.


8. Contribution à la mise en production (Démarche DevOps) :


La mise en production réussie d"ActivMap ne se limite pas au simple déploiement technique. Elle s"inscrit dans une démarche plus globale, inspirée des principes DevOps, visant à assurer une transition fluide du développement à l"exploitation et à garantir la fiabilité et la maintenabilité de l"application sur le long terme.


* Automatisation : L"utilisation de Docker, Docker Compose, et potentiellement d"un pipeline CI/CD (même simple) contribue à automatiser les processus de build, de test et de déploiement, réduisant les erreurs manuelles et accélérant les mises à jour.
* Infrastructure as Code (IaC) : Les Dockerfile et docker-compose.yml décrivent l"infrastructure applicative sous forme de code, la rendant versionnable, reproductible et plus facile à gérer.
* Collaboration (Dev & Ops) : Bien que le projet soit individuel, la démarche adoptée (conteneurisation, configuration Nginx, gestion des logs, planification des sauvegardes) prépare le terrain pour une collaboration efficace entre les développeurs (Dev) et les responsables de l"exploitation (Ops) dans un contexte d"équipe plus large. Le développeur a ici anticipé les besoins de l"exploitation.
* Monitoring et Feedback : La mise en place d"une surveillance (logs, ressources serveur) permet d"obtenir un retour rapide sur le comportement de l"application en production et de réagir proactivement aux problèmes.
* Sécurité Intégrée : La sécurité n"est pas une réflexion après coup mais est intégrée dès la conception (architecture), le développement (bonnes pratiques, tests de sécurité) et le déploiement (HTTPS, pare-feu, configuration sécurisée).


Cette approche globale, même appliquée à une échelle individuelle, démontre une compréhension des enjeux liés à la mise en production et à l"exploitation d"une application moderne.
CP11 : Accompagner l’utilisateur dans la prise en main de l’application
Une fois l"application déployée, il est crucial d"accompagner les utilisateurs finaux (employés de FeelObject) pour qu"ils puissent l"utiliser efficacement et en tirer le maximum de valeur. Cet accompagnement prend principalement la forme de documentation et de support.


1. Documentation Utilisateur :


Une documentation claire et accessible est essentielle pour guider les utilisateurs.


* Guide de Démarrage Rapide : Un document concis expliquant comment accéder à l"application, se connecter pour la première fois, et réaliser les tâches les plus courantes (ex: générer une première carte, comprendre l"interface principale).
* Manuel Utilisateur Détaillé : Un guide plus complet décrivant chaque fonctionnalité en détail :
   * Interface de génération : signification de chaque champ, limites éventuelles.
   * Gestion des styles : comment créer, modifier, supprimer un style personnalisé (si applicable), signification des paramètres de style.
   * Gestion de l"historique : comment consulter, recharger les paramètres.
   * Fonctionnalités d"export : formats disponibles, options.
   * Gestion du compte : modification du mot de passe.
   * Fonctionnalités spécifiques aux rôles (CHEF, ADMIN) : gestion des utilisateurs, gestion des styles d"équipe (si applicable).
   * Ce manuel peut inclure des captures d"écran pour illustrer les propos.
* FAQ (Foire Aux Questions) : Une section regroupant les questions fréquemment posées et leurs réponses (ex: "Que faire si la génération échoue ?", "Comment interpréter les messages d"erreur courants ?", "Quelles sont les limites de l"API Overpass ?").
* Format et Accès : La documentation peut être fournie sous différents formats : document PDF, pages web intégrées à l"application (section "Aide"), ou un Wiki interne à FeelObject. L"important est qu"elle soit facilement accessible par tous les utilisateurs.


2. Support Utilisateur :


Même avec une bonne documentation, les utilisateurs peuvent rencontrer des problèmes ou avoir des questions.


* Canal de Communication : Définir un canal clair pour le support : adresse email dédiée, système de ticketing interne, contact référent (le développeur initial ou une personne désignée chez FeelObject).
* Procédure de Remontée de Bugs : Expliquer aux utilisateurs comment signaler un bug de manière efficace : description du problème, étapes pour le reproduire, captures d"écran si possible, informations sur leur navigateur/système.
* Réactivité : Assurer un suivi et une réponse aux demandes de support dans des délais raisonnables.
* Mise à Jour de la Documentation : Utiliser les retours du support pour améliorer la documentation existante et la FAQ.


3. Formation (Optionnel) :


Pour une prise en main plus rapide ou pour des fonctionnalités complexes, une courte session de formation (présentation en direct ou enregistrée) peut être organisée pour les utilisateurs clés ou l"ensemble des utilisateurs.


En fournissant une documentation adéquate et un support réactif, on facilite l"adoption de l"application ActivMap par les utilisateurs de FeelObject et on maximise son utilité au sein de l"entreprise.
Bilan et Conclusion
Le développement du projet ActivMap, de l"analyse initiale des besoins à son déploiement potentiel, a constitué une expérience d"apprentissage riche et complète, permettant de mettre en pratique et de consolider l"ensemble des compétences visées par le titre RNCP Concepteur Développeur d"Applications.
1. Retour d"Expérience Personnel
Ce projet a été l"occasion de traverser toutes les phases du cycle de vie d"une application web moderne, en partant d"une problématique métier concrète exprimée par FeelObject. La nécessité de créer un outil interne pour générer des cartes tactiles personnalisées à partir de données OpenStreetMap a offert un cadre stimulant pour appliquer des concepts variés.


Apprentissages Techniques :


* Architecture Full-Stack : La mise en œuvre d"une architecture complète avec un frontend Svelte, un backend Python/Flask, une base de données PostgreSQL/PostGIS, et une infrastructure conteneurisée avec Docker et Nginx a permis de comprendre les interactions complexes entre ces différentes briques. Le choix de Svelte a été particulièrement intéressant pour sa réactivité et son approche par compilation. Flask s"est révélé un choix pragmatique pour sa simplicité et la richesse de l"écosystème Python.
* Manipulation de Données Géospatiales : L"interaction avec l"API Overpass pour récupérer des données OSM et la perspective d"utiliser PostGIS pour des fonctionnalités futures ont constitué une introduction pratique au domaine de la géomatique appliquée au web.
* Conteneurisation et Déploiement : L"utilisation intensive de Docker et Docker Compose, depuis l"environnement de développement jusqu"à la simulation du déploiement en production, a été un apprentissage majeur. Comprendre comment configurer Nginx en tant que reverse proxy, gérer HTTPS avec Let"s Encrypt, et orchestrer les différents services est une compétence clé dans le développement web actuel.
* Sécurité et Tests : La prise en compte de la sécurité à différents niveaux (authentification JWT, rôles, protection OWASP, HTTPS) et la mise en place d"une stratégie de tests multi-niveaux (TU, TI, Sécurité, UAT) ont souligné l"importance de ces aspects pour la robustesse et la fiabilité d"une application.


Gestion de Projet et Compétences Transverses :


* Autonomie et Organisation : Mener ce projet de bout en bout a nécessité une grande autonomie dans la recherche de solutions techniques, la planification des tâches et le suivi de l"avancement.
* Analyse et Conception : La phase initiale d"analyse des besoins, la rédaction du cahier des charges, la création des User Stories et la conception des modèles de données et de l"architecture ont été des étapes cruciales pour structurer le projet.
* Documentation : La rédaction de ce dossier, ainsi que la documentation potentielle du code (README.md, commentaires, docstrings) et la documentation utilisateur, a mis en évidence l"importance de communiquer clairement sur le travail réalisé.
* Résolution de Problèmes : Comme tout projet de développement, ActivMap a présenté son lot de défis techniques (configuration Docker, interaction API, gestion des dépendances, etc.) dont la résolution a été formatrice.


Ce projet représente une synthèse concrète des compétences acquises durant la formation. Il démontre la capacité à concevoir, développer, tester et préparer le déploiement d"une application web complexe répondant à un besoin métier spécifique, tout en respectant les bonnes pratiques en termes d"architecture, de sécurité et de qualité logicielle.
2. Points Forts du Projet / Difficultés Rencontrées
Points Forts :


* Réponse à un Besoin Réel : Le projet ActivMap répond à une problématique concrète et spécifique de l"entreprise FeelObject, ce qui lui confère une pertinence métier immédiate.
* Architecture Moderne et Robuste : L"adoption d"une architecture découplée (frontend/backend), l"utilisation de technologies modernes (Svelte, Flask) et la conteneurisation avec Docker constituent une base solide, évolutive et maintenable.
* Automatisation via Docker : L"utilisation de Docker et Docker Compose simplifie grandement la gestion de l"environnement de développement, les tests d"intégration et le processus de déploiement, assurant la cohérence entre les environnements.
* Prise en Compte de la Sécurité : Des mesures de sécurité ont été intégrées à plusieurs niveaux (authentification JWT, rôles, HTTPS, configuration Nginx, bonnes pratiques OWASP), ce qui est essentiel pour une application professionnelle.
* Potentiel d"Évolution : L"architecture modulaire et l"utilisation de PostGIS ouvrent la voie à de nombreuses améliorations et nouvelles fonctionnalités (analyses spatiales, gestion avancée des styles, etc.).


Difficultés Rencontrées :


* Complexité de l"API Overpass : Comprendre la syntaxe du langage de requête Overpass QL et gérer les limitations potentielles de l"API (temps de réponse, volume de données) peut représenter un défi initial.
* Configuration Docker et Nginx : Bien que puissants, la configuration initiale de Docker Compose pour la production et surtout la configuration fine de Nginx (reverse proxy, HTTPS, en-têtes de sécurité) peuvent être complexes et nécessiter des ajustements précis.
* Gestion des Données Géospatiales : La manipulation et le rendu de données géographiques (GeoJSON) nécessitent des connaissances spécifiques, notamment pour l"optimisation de l"affichage et l"interaction avec les bibliothèques cartographiques (Leaflet, MapLibre GL JS).
* Tests Exhaustifs : Mettre en place une couverture de tests réellement complète, en particulier pour les tests d"intégration impliquant la base de données et les tests E2E, demande un investissement en temps conséquent.
* Gestion du Temps (Projet Individuel) : Couvrir toutes les phases du projet (analyse, conception, développement frontend/backend, tests, déploiement, documentation) en autonomie demande une bonne organisation et une gestion rigoureuse du temps.


Ces difficultés, bien que réelles, ont toutes été des opportunités d"apprentissage et de montée en compétence.
3. Améliorations Possibles / Perspectives d"Évolution
ActivMap, dans sa version actuelle, constitue une base fonctionnelle solide. Cependant, plusieurs pistes d"amélioration et d"évolution peuvent être envisagées pour enrichir l"application et répondre à des besoins futurs :


* Interface de Création/Édition de Styles Visuelle : Actuellement, la gestion des styles (si implémentée au-delà des styles prédéfinis) repose probablement sur la manipulation directe de paramètres (ex: JSON). Une interface graphique conviviale permettant aux utilisateurs (notamment CHEF ou ADMIN) de créer et modifier visuellement les styles (couleurs, épaisseurs de trait, icônes, motifs de remplissage) rendrait cette fonctionnalité beaucoup plus accessible.
* Intégration de Données Supplémentaires : Explorer l"intégration d"autres sources de données géographiques pertinentes pour FeelObject, en plus d"OpenStreetMap (ex: données cadastrales, données métier internes géolocalisées).
* Fonctionnalités d"Analyse Spatiale : Tirer parti de PostGIS pour implémenter des fonctionnalités d"analyse spatiale plus avancées : calcul de zones tampon, requêtes de proximité, superposition de couches, etc., si pertinent pour le besoin métier.
* Gestion Affinée des Rôles et Permissions : Mettre en place un système de permissions plus granulaire, permettant par exemple de partager des styles spécifiques avec certains utilisateurs ou équipes.
* Mode Collaboratif : Permettre à plusieurs utilisateurs de travailler simultanément sur la définition d"une zone ou d"un style (potentiellement via WebSockets).
* Optimisation des Performances : Pour des zones très denses ou étendues, optimiser les requêtes Overpass, le traitement des données GeoJSON, et le rendu SVG/PNG (ex: simplification des géométries, mise en cache plus agressive côté backend ou frontend).
* Amélioration de l"Accessibilité (RGAA) : Poursuivre l"audit et l"amélioration de l"accessibilité de l"interface utilisateur pour atteindre une conformité RGAA plus poussée.
* Tests E2E Automatisés : Mettre en place une suite de tests End-to-End automatisés (avec Playwright ou Cypress) pour couvrir les parcours utilisateurs critiques et détecter les régressions au niveau de l"interface.
* Déploiement Multi-environnements : Formaliser la gestion de plusieurs environnements (développement, staging, production) avec des configurations distinctes et un processus de déploiement clair entre eux (via le pipeline CI/CD).
* Interface d"Administration Plus Riche : Développer une interface d"administration plus complète pour la gestion des utilisateurs, des styles globaux, la consultation des logs, et le monitoring de l"application.
* Export Vers d"Autres Formats : Ajouter la possibilité d"exporter les cartes vers d"autres formats utiles pour FeelObject (ex: PDF haute résolution, formats spécifiques aux machines de fabrication si applicable).


Ces perspectives montrent que le projet ActivMap a un potentiel d"évolution significatif et peut continuer à s"adapter aux besoins changeants de FeelObject.
4. Conclusion Générale
En conclusion, le projet ActivMap a permis de démontrer la capacité à mener à bien un projet de conception et de développement d"application web de A à Z, en réponse à une problématique métier concrète. En mobilisant des compétences variées couvrant l"analyse des besoins, la conception architecturale et fonctionnelle, le développement full-stack avec des technologies modernes, la mise en œuvre de tests rigoureux, et la préparation du déploiement dans le respect des bonnes pratiques, ce projet illustre l"atteinte des objectifs pédagogiques et des compétences requises par le titre RNCP Concepteur Développeur d"Applications. ActivMap n"est pas seulement une solution technique pour FeelObject, mais aussi une réalisation concrète témoignant de la maîtrise du processus de développement logiciel.